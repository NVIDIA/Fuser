{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bd40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lightning-thunder/thunder/executors/transformer_engineex.py:56: UserWarning: transformer_engine failed to import with exception argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'\n",
      "  warnings.warn(f\"transformer_engine failed to import with exception {ex}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import thunder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adab902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.executors.nvfuserex import nvfuserex\n",
    "from thunder.benchmarks import NanoGPTBlockBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1465dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = NanoGPTBlockBenchmark(\n",
    "        config=\"gpt2\", device=\"cuda:0\", dtype=thunder.bfloat16, requires_grad=True\n",
    "    )\n",
    "args, kwargs = bench.make_batch()\n",
    "\n",
    "jfn = thunder.jit(\n",
    "  bench.fn(), executors=[nvfuserex], \n",
    "  nv_enable_sdpa=True, \n",
    "  nv_enable_matmul=True, \n",
    "  nv_enable_linear=True,\n",
    "  disable_replace_uniform=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc746df",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = jfn(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc04612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_traces = thunder.last_traces(jfn)[-1].python_ctx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13fd1e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "def nvfuser_fusion_id0(fd : FusionDefinition) -> None :\n",
       "    T0 = fd.define_tensor(shape=[16, 128, 768], contiguity=[True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[2, 1, 0])\n",
       "    T1 = fd.define_tensor(shape=[768], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T2 = fd.define_tensor(shape=[768], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T3 = fd.define_tensor(shape=[2304, 768], contiguity=[True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[1, 0])\n",
       "    T4 = fd.define_tensor(shape=[2304], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T5 = fd.define_tensor(shape=[768, 768], contiguity=[True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[1, 0])\n",
       "    T6 = fd.define_tensor(shape=[768], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T7 = fd.define_tensor(shape=[768], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T8 = fd.define_tensor(shape=[768], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T9 = fd.define_tensor(shape=[3072, 768], contiguity=[True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[1, 0])\n",
       "    T10 = fd.define_tensor(shape=[3072], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T11 = fd.define_tensor(shape=[768, 3072], contiguity=[True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[1, 0])\n",
       "    T12 = fd.define_tensor(shape=[768], contiguity=[True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[0])\n",
       "    T13 = fd.ops.cast(T0, dtype=DataType.Float)\n",
       "    T14, T15 = fd.ops.var_mean(T13, dims=[2], correction=0, keepdim=False)\n",
       "    T20 = fd.ops.broadcast_in_dim(T14, shape=[16, 128, 1], broadcast_dims=[0, 1])\n",
       "    T25 = fd.ops.broadcast_in_dim(T15, shape=[16, 128, 1], broadcast_dims=[0, 1])\n",
       "    S26 = fd.define_scalar(1.00000e-05, dtype=DataType.Double)\n",
       "    T27 = fd.ops.add(T20, S26)\n",
       "    T28 = fd.ops.rsqrt(T27)\n",
       "    T33 = fd.ops.broadcast_in_dim(T25, shape=[16, 128, 768], broadcast_dims=[0, 1, 2])\n",
       "    T34 = fd.ops.sub(T13, T33)\n",
       "    T39 = fd.ops.broadcast_in_dim(T28, shape=[16, 128, 768], broadcast_dims=[0, 1, 2])\n",
       "    T40 = fd.ops.mul(T34, T39)\n",
       "    T45 = fd.ops.broadcast_in_dim(T1, shape=[16, 128, 768], broadcast_dims=[2])\n",
       "    T46 = fd.ops.cast(T45, dtype=DataType.Float)\n",
       "    T47 = fd.ops.mul(T40, T46)\n",
       "    T52 = fd.ops.broadcast_in_dim(T2, shape=[16, 128, 768], broadcast_dims=[2])\n",
       "    T53 = fd.ops.cast(T52, dtype=DataType.Float)\n",
       "    T54 = fd.ops.add(T47, T53)\n",
       "    T55 = fd.ops.cast(T54, dtype=DataType.BFloat16)\n",
       "    T56 = fd.ops.linear(T55, T3, T4)\n",
       "    T69 = fd.ops.slice(T56, start_indices=[0, 0, 0], end_indices=[16, 128, 768], strides=[1, 1, 1], manual_normalization=0)\n",
       "    T82 = fd.ops.slice(T56, start_indices=[0, 0, 768], end_indices=[16, 128, 1536], strides=[1, 1, 1], manual_normalization=0)\n",
       "    T95 = fd.ops.slice(T56, start_indices=[0, 0, 1536], end_indices=[16, 128, 2304], strides=[1, 1, 1], manual_normalization=0)\n",
       "    T101 = fd.ops.reshape(T82, new_shape=[16, 128, 12, 64])\n",
       "    T102 = fd.ops.permute(T101, dims=[0, 2, 1, 3])\n",
       "    T108 = fd.ops.reshape(T69, new_shape=[16, 128, 12, 64])\n",
       "    T109 = fd.ops.permute(T108, dims=[0, 2, 1, 3])\n",
       "    T115 = fd.ops.reshape(T95, new_shape=[16, 128, 12, 64])\n",
       "    T116 = fd.ops.permute(T115, dims=[0, 2, 1, 3])\n",
       "    S117 = fd.define_scalar(0.100000, dtype=DataType.Double)\n",
       "    S118 = fd.define_scalar(True, dtype=DataType.Bool)\n",
       "    T119, T120, T121, T122 = fd.ops.sdpfa_fwd(T109, T102, T116, S117, S118, None)\n",
       "    T123 = fd.ops.permute(T119, dims=[0, 2, 1, 3])\n",
       "    T124 = fd.ops.stride_order(T123, stride_order=[3, 2, 1, 0])\n",
       "    T129 = fd.ops.reshape(T124, new_shape=[16, 128, 768])\n",
       "    T130 = fd.ops.linear(T129, T5, T6)\n",
       "    S131 = fd.define_scalar(0.00000, dtype=DataType.Double)\n",
       "    S132 = fd.define_scalar(1.00000, dtype=DataType.Double)\n",
       "    S133 = fd.define_scalar(16, dtype=DataType.Int)\n",
       "    S134 = fd.define_scalar(128, dtype=DataType.Int)\n",
       "    S135 = fd.define_scalar(768, dtype=DataType.Int)\n",
       "    T137 = fd.ops.uniform(S131, S132, shape=[S133, S134, S135], dtype=DataType.BFloat16)\n",
       "    S138 = fd.define_scalar(0.900000, dtype=DataType.Double)\n",
       "    T139 = fd.ops.lt(T137, S138)\n",
       "    T140 = fd.ops.cast(T130, dtype=DataType.Float)\n",
       "    T141 = fd.ops.cast(T139, dtype=DataType.Float)\n",
       "    T142 = fd.ops.mul(T140, T141)\n",
       "    S143 = fd.define_scalar(1.11111, dtype=DataType.Double)\n",
       "    T144 = fd.ops.mul(T142, S143)\n",
       "    T145 = fd.ops.add(T13, T144)\n",
       "    T146, T147 = fd.ops.var_mean(T145, dims=[2], correction=0, keepdim=False)\n",
       "    T152 = fd.ops.broadcast_in_dim(T146, shape=[16, 128, 1], broadcast_dims=[0, 1])\n",
       "    T157 = fd.ops.broadcast_in_dim(T147, shape=[16, 128, 1], broadcast_dims=[0, 1])\n",
       "    S158 = fd.define_scalar(1.00000e-05, dtype=DataType.Double)\n",
       "    T159 = fd.ops.add(T152, S158)\n",
       "    T160 = fd.ops.rsqrt(T159)\n",
       "    T165 = fd.ops.broadcast_in_dim(T157, shape=[16, 128, 768], broadcast_dims=[0, 1, 2])\n",
       "    T166 = fd.ops.sub(T145, T165)\n",
       "    T171 = fd.ops.broadcast_in_dim(T160, shape=[16, 128, 768], broadcast_dims=[0, 1, 2])\n",
       "    T172 = fd.ops.mul(T166, T171)\n",
       "    T177 = fd.ops.broadcast_in_dim(T7, shape=[16, 128, 768], broadcast_dims=[2])\n",
       "    T178 = fd.ops.cast(T177, dtype=DataType.Float)\n",
       "    T179 = fd.ops.mul(T172, T178)\n",
       "    T184 = fd.ops.broadcast_in_dim(T8, shape=[16, 128, 768], broadcast_dims=[2])\n",
       "    T185 = fd.ops.cast(T184, dtype=DataType.Float)\n",
       "    T186 = fd.ops.add(T179, T185)\n",
       "    T187 = fd.ops.cast(T186, dtype=DataType.BFloat16)\n",
       "    T188 = fd.ops.linear(T187, T9, T10)\n",
       "    T189 = fd.ops.cast(T188, dtype=DataType.Float)\n",
       "    T190 = fd.ops.mul(T189, T189)\n",
       "    T191 = fd.ops.mul(T190, T189)\n",
       "    S192 = fd.define_scalar(0.500000, dtype=DataType.Double)\n",
       "    T193 = fd.ops.mul(S192, T189)\n",
       "    S194 = fd.define_scalar(0.0447150, dtype=DataType.Double)\n",
       "    T195 = fd.ops.mul(S194, T191)\n",
       "    T196 = fd.ops.add(T189, T195)\n",
       "    S197 = fd.define_scalar(0.797885, dtype=DataType.Double)\n",
       "    T198 = fd.ops.mul(S197, T196)\n",
       "    T199 = fd.ops.tanh(T198)\n",
       "    S200 = fd.define_scalar(1.00000, dtype=DataType.Double)\n",
       "    T201 = fd.ops.add(S200, T199)\n",
       "    T202 = fd.ops.mul(T193, T201)\n",
       "    T203 = fd.ops.cast(T202, dtype=DataType.BFloat16)\n",
       "    T204 = fd.ops.linear(T203, T11, T12)\n",
       "    S205 = fd.define_scalar(0.00000, dtype=DataType.Double)\n",
       "    S206 = fd.define_scalar(1.00000, dtype=DataType.Double)\n",
       "    S207 = fd.define_scalar(16, dtype=DataType.Int)\n",
       "    S208 = fd.define_scalar(128, dtype=DataType.Int)\n",
       "    S209 = fd.define_scalar(768, dtype=DataType.Int)\n",
       "    T211 = fd.ops.uniform(S205, S206, shape=[S207, S208, S209], dtype=DataType.BFloat16)\n",
       "    S212 = fd.define_scalar(0.900000, dtype=DataType.Double)\n",
       "    T213 = fd.ops.lt(T211, S212)\n",
       "    T214 = fd.ops.cast(T204, dtype=DataType.Float)\n",
       "    T215 = fd.ops.cast(T213, dtype=DataType.Float)\n",
       "    T216 = fd.ops.mul(T214, T215)\n",
       "    S217 = fd.define_scalar(1.11111, dtype=DataType.Double)\n",
       "    T218 = fd.ops.mul(T216, S217)\n",
       "    T219 = fd.ops.add(T145, T218)\n",
       "    T220 = fd.ops.cast(T219, dtype=DataType.BFloat16)\n",
       "    fd.add_output(T15)\n",
       "    fd.add_output(T28)\n",
       "    fd.add_output(T56)\n",
       "    fd.add_output(T119)\n",
       "    fd.add_output(T120)\n",
       "    fd.add_output(T121)\n",
       "    fd.add_output(T122)\n",
       "    fd.add_output(T130)\n",
       "    fd.add_output(T139)\n",
       "    fd.add_output(T147)\n",
       "    fd.add_output(T160)\n",
       "    fd.add_output(T188)\n",
       "    fd.add_output(T213)\n",
       "    fd.add_output(T220)\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_traces['nvFusion0'].last_used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
