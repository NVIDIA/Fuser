============================================================================================= test session starts =============================================================================================
platform linux -- Python 3.12.3, pytest-8.3.5, pluggy-1.6.0
Test order randomisation NOT enabled. Enable with --random-order or --random-order-bucket=<bucket_type>
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /opt/pytorch/nvfuser
plugins: timeout-2.4.0, xdist-3.7.0, random-order-1.2.0, cov-6.2.1, timestamper-0.0.10, shard-0.1.2, benchmark-5.1.0, hypothesis-6.136.6, mpi-0.6
collecting ... collecting 5 items                                                                                                                                                                                            collected 5 items / 4 deselected / 1 selected                                                                                                                                                                 
Running 1 items in this shard

tests/python/multidevice/test_transformer.py Segment the fusion (Original Fusion Un-modified): 
Inputs:
  T0_g___bfloat[ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128}] (DeviceMesh{0 1})
  T1_g___bfloat[ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128}] (DeviceMesh{0 1})
  T2_g___bfloat[ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128}] (DeviceMesh{0 1})
Outputs:
  T11_g___bfloat[ideviceIdx.x72{2}, iS73{18432}] (DeviceMesh{0 1})
  T13_g___bfloat[ideviceIdx.x76{2}, iS48{2048}, iS77{18432}] (DeviceMesh{0 1})
  T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1})

%kernel_math {
T3_l___bfloat[ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf] (DeviceMesh{0 1})
   = pad( T0_g___bfloat[ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, 0, 256} )
i43 = 0 + 128;
T4_l___bfloat[ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1})
   = pad( T1_g___bfloat[ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i43, 128} )
i66 = i43 + 128;
T5_l___bfloat[ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1})
   = pad( T2_g___bfloat[ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i66, 0} )
T6_l___bfloat[ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384}] (DeviceMesh{0 1})
   = cat( T3_l___bfloat[ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf] (DeviceMesh{0 1}), T4_l___bfloat[ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1}), T5_l___bfloat[ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1}), 3 )
T7_l___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}) = view( T6_l___bfloat[ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384}] (DeviceMesh{0 1}) )
T8_l_float[ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432}] (DeviceMesh{0 1})
   = __bfloat2float(T7_l___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}));
T9_l_float[ideviceIdx.x68{2}, iS41{2048}, iS69{18432}] (DeviceMesh{0 1})
   = squeeze( T8_l_float[ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432}] (DeviceMesh{0 1}), flags = {true, false, false} )
T10_l_float[ideviceIdx.x70{2}, rS43{2048}, iS71{18432}] (DeviceMesh{0 1})
   = reduction( T9_l_float[ideviceIdx.x68{2}, iS41{2048}, iS69{18432}] (DeviceMesh{0 1}), op = add, initial value = float(0), allreduce = false )
T11_g___bfloat[ideviceIdx.x72{2}, iS73{18432}] (DeviceMesh{0 1})
   = __float2bfloat(T10_l_float[ideviceIdx.x70{2}, rS43{2048}, iS71{18432}] (DeviceMesh{0 1}));
T14_l___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1})
   = SegmenterSet( T7_l___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}) )
T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1})
   = squeeze( T14_l___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1}), flags = {true, false, false} )
T13_g___bfloat[ideviceIdx.x76{2}, iS48{2048}, iS77{18432}] (DeviceMesh{0 1})
   = Set.Permute( T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1}), cache_op=Streaming )
} // %kernel_math 

Segmented_Fusion Dump: -- Re-written complete fusion:{
Inputs:
  T0_g___bfloat[ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128}] (DeviceMesh{0 1})
  T1_g___bfloat[ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128}] (DeviceMesh{0 1})
  T2_g___bfloat[ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128}] (DeviceMesh{0 1})
Outputs:
  T11_g___bfloat[ideviceIdx.x72{2}, iS73{18432}] (DeviceMesh{0 1})
  T13_g___bfloat[ideviceIdx.x76{2}, iS48{2048}, iS77{18432}] (DeviceMesh{0 1})
  T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1})

%kernel_math {
T3_l___bfloat[ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf] (DeviceMesh{0 1})
   = pad( T0_g___bfloat[ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, 0, 256} )
i43 = 0 + 128;
T4_l___bfloat[ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1})
   = pad( T1_g___bfloat[ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i43, 128} )
i66 = i43 + 128;
T5_l___bfloat[ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1})
   = pad( T2_g___bfloat[ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i66, 0} )
T6_g___bfloat[ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384}] (DeviceMesh{0 1})
   = cat( T3_l___bfloat[ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf] (DeviceMesh{0 1}), T4_l___bfloat[ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1}), T5_l___bfloat[ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1}), 3 )
T7_g___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}) = view( T6_g___bfloat[ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384}] (DeviceMesh{0 1}) )
T8_l_float[ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432}] (DeviceMesh{0 1})
   = __bfloat2float(T7_g___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}));
T9_l_float[ideviceIdx.x68{2}, iS41{2048}, iS69{18432}] (DeviceMesh{0 1})
   = squeeze( T8_l_float[ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432}] (DeviceMesh{0 1}), flags = {true, false, false} )
T10_g_float[ideviceIdx.x70{2}, rS43{2048}, iS71{18432}] (DeviceMesh{0 1})
   = reduction( T9_l_float[ideviceIdx.x68{2}, iS41{2048}, iS69{18432}] (DeviceMesh{0 1}), op = add, initial value = float(0), allreduce = false )
T11_g___bfloat[ideviceIdx.x72{2}, iS73{18432}] (DeviceMesh{0 1})
   = __float2bfloat(T10_g_float[ideviceIdx.x70{2}, rS43{2048}, iS71{18432}] (DeviceMesh{0 1}));
T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1})
   = SegmenterSet( T7_g___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}) )
T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1})
   = squeeze( T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1}), flags = {true, false, false} )
T13_g___bfloat[ideviceIdx.x76{2}, iS48{2048}, iS77{18432}] (DeviceMesh{0 1})
   = Set.Permute( T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1}), cache_op=Streaming )
} // %kernel_math 

} // {Re-written complete fusion}
Segmented_Fusion Dump: -- fusion segments:
Segmented_Fusion{ 
groups: 
  reduction{1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 624}
  expr_eval{19, 626}
edges: 
  e{ reduction{1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 624} -> expr_eval{19, 626}(T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1})) }

group details:
g{(reduction)
group id: 0
inputs:
  T0_g___bfloat[ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128}] (DeviceMesh{0 1}) __bfloat
  T1_g___bfloat[ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128}] (DeviceMesh{0 1}) __bfloat
  T2_g___bfloat[ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128}] (DeviceMesh{0 1}) __bfloat
outputs:
  T11_g___bfloat[ideviceIdx.x72{2}, iS73{18432}] (DeviceMesh{0 1}) __bfloat
  T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1}) __bfloat


T3_l___bfloat[ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf] (DeviceMesh{0 1})
   = pad( T0_g___bfloat[ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, 0, 256} )
(1)
i43 = 0 + 128;
(2)
T4_l___bfloat[ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1})
   = pad( T1_g___bfloat[ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i43, 128} )
(6)
i66 = i43 + 128;
(7)
T5_l___bfloat[ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1})
   = pad( T2_g___bfloat[ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i66, 0} )
(10)
T6_g___bfloat[ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384}] (DeviceMesh{0 1})
   = cat( T3_l___bfloat[ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf] (DeviceMesh{0 1}), T4_l___bfloat[ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1}), T5_l___bfloat[ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf] (DeviceMesh{0 1}), 3 )
(11)
T7_g___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}) = view( T6_g___bfloat[ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384}] (DeviceMesh{0 1}) )
(13)
T8_l_float[ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432}] (DeviceMesh{0 1})
   = __bfloat2float(T7_g___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}));
(14)
T9_l_float[ideviceIdx.x68{2}, iS41{2048}, iS69{18432}] (DeviceMesh{0 1})
   = squeeze( T8_l_float[ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432}] (DeviceMesh{0 1}), flags = {true, false, false} )
(15)
T10_g_float[ideviceIdx.x70{2}, rS43{2048}, iS71{18432}] (DeviceMesh{0 1})
   = reduction( T9_l_float[ideviceIdx.x68{2}, iS41{2048}, iS69{18432}] (DeviceMesh{0 1}), op = add, initial value = float(0), allreduce = false )
(16)
T11_g___bfloat[ideviceIdx.x72{2}, iS73{18432}] (DeviceMesh{0 1})
   = __float2bfloat(T10_g_float[ideviceIdx.x70{2}, rS43{2048}, iS71{18432}] (DeviceMesh{0 1}));
(17)
T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1})
   = SegmenterSet( T7_g___bfloat[ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432}] (DeviceMesh{0 1}) )
(624)
i84 = i66 + 128;
(8)
i61 = i43 + 128;
(3)
i64 = i61 + 128;
(4)
}

g{(expr_eval)
group id: 1
inputs:
  T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1}) __bfloat
outputs:
  T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1}) __bfloat
  T13_g___bfloat[ideviceIdx.x76{2}, iS48{2048}, iS77{18432}] (DeviceMesh{0 1}) __bfloat


T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1})
   = squeeze( T14_g___bfloat[ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432}] (DeviceMesh{0 1}), flags = {true, false, false} )
(626)
T13_g___bfloat[ideviceIdx.x76{2}, iS48{2048}, iS77{18432}] (DeviceMesh{0 1})
   = Set.Permute( T12_g___bfloat[ideviceIdx.x74{2}, iS46{2048}, iS75{18432}] (DeviceMesh{0 1}), cache_op=Streaming )
(19)
}

} //Segmented_Fusion


===== Outer Reduction Stats ========
total_reduction_numel: 2048
total_iteration_numel: 36864
vectorize_factor: 8
redu_unroll_factor: 4
grid(72, 15, 1)
block(64, 8, 1)


===== Reduction Parameters ========

Red On Slow Dim
Circular buffer: not used

Iteration Domain: blockIdx.x / threadIdx.x / multiple reductions per block / vectorize / factor 8
Inner Reduction Domain: cross block - threadIdx.y / cross grid - blockIdx.y / split grid dim / split grid dimension / unroll / factor 4
Launch Parameters: BlockDim.x = 64, BlockDim.y = 8, BlockDim.z = -1, GridDim.x = -1, GridDim.y = 15, GridDim.z = -1, Smem Size = 0
Compile Parameters: index_type = NotSet, maxrregcount = 128, enable_magic_zero = 1, enable_ptxas_verbose = 0, include_paths = 

====================================

F

================================================================================================== FAILURES ===================================================================================================
_____________________________________________________________________________________________ test_cat_reduction ______________________________________________________________________________________________

multidevice_test = <conftest.MultideviceTest object at 0x7b5ff5067500>

    @pytest.mark.mpi
    def test_cat_reduction(multidevice_test):
      d = multidevice_test.size
      mesh = nvfuser.DeviceMesh(range(d))
      class CatReduction(FusionDefinition):
        def definition(self):
          self.inp0 = self.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
          self.inp1 = self.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
          self.inp2 = self.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
          S3 = self.define_scalar(0.00000, dtype=DataType.BFloat16)
          S4 = self.define_scalar(0, dtype=DataType.Int)
          S5 = self.define_scalar(0, dtype=DataType.Int)
          S6 = self.define_scalar(0, dtype=DataType.Int)
          S7 = self.define_scalar(0, dtype=DataType.Int)
          S8 = self.define_scalar(0, dtype=DataType.Int)
          S9 = self.define_scalar(0, dtype=DataType.Int)
          S10 = self.define_scalar(0, dtype=DataType.Int)
          S11 = self.define_scalar(256, dtype=DataType.Int)
          V13 = self.define_vector([S10, S11, S8, S9, S6, S7, S4, S5], dtype=DataType.Int)
          T12 = self.ops.pad(self.inp0, V13, S3)
          S14 = self.define_scalar(0, dtype=DataType.Int)
          S15 = self.ops.size(self.inp1, dim=3)
          S16 = self.ops.add(S14, S15)
          S17 = self.define_scalar(0.00000, dtype=DataType.BFloat16)
          S18 = self.define_scalar(0, dtype=DataType.Int)
          S19 = self.define_scalar(0, dtype=DataType.Int)
          S20 = self.define_scalar(0, dtype=DataType.Int)
          S21 = self.define_scalar(0, dtype=DataType.Int)
          S22 = self.define_scalar(0, dtype=DataType.Int)
          S23 = self.define_scalar(0, dtype=DataType.Int)
          S24 = self.define_scalar(128, dtype=DataType.Int)
          V26 = self.define_vector([S16, S24, S22, S23, S20, S21, S18, S19], dtype=DataType.Int)
          T25 = self.ops.pad(self.inp1, V26, S17)
          S27 = self.ops.add(S16, S15)
          S28 = self.define_scalar(0.00000, dtype=DataType.BFloat16)
          S29 = self.define_scalar(0, dtype=DataType.Int)
          S30 = self.define_scalar(0, dtype=DataType.Int)
          S31 = self.define_scalar(0, dtype=DataType.Int)
          S32 = self.define_scalar(0, dtype=DataType.Int)
          S33 = self.define_scalar(0, dtype=DataType.Int)
          S34 = self.define_scalar(0, dtype=DataType.Int)
          S35 = self.define_scalar(0, dtype=DataType.Int)
          V37 = self.define_vector([S27, S35, S33, S34, S31, S32, S29, S30], dtype=DataType.Int)
          T36 = self.ops.pad(self.inp2, V37, S28)
          T38 = self.ops.cat([T12, T25, T36], dim=3, manual_padding=1)
          S39 = self.ops.size(T36, dim=0)
          S40 = self.ops.size(T36, dim=1)
          S41 = self.define_scalar(36864, dtype=DataType.Int)
          V42 = self.define_vector([S39, S40, S41], dtype=DataType.Int)
          T43 = self.ops.reshape(T38, new_shape=V42)
          T44 = self.ops.cast(T43, dtype=DataType.Float)
          T45 = self.ops.squeeze(T44, dims=[0], squeeze_expanded=True)
          T46 = self.ops.sum(T45, dims=[0], keepdim=False, dtype=DataType.Float)
          T47 = self.ops.cast(T46, dtype=DataType.BFloat16)
          T48 = self.ops.squeeze(T43, dims=[0], squeeze_expanded=True)
          T49 = self.ops.permute(T48, dims=[1, 0])
          self.add_output(T47)
          self.add_output(T49, stride_order=[0, 1])
          self.add_output(T48)
    
        def multidevice_schedule(self):
          for t in [self.inp0, self.inp1, self.inp2]:
            self.sched._set_device_mesh(t, mesh)
            self.sched.split(t, 2, d, False)
            self.sched.parallelize(t, 2, nvfuser.ParallelType.mesh_x)
    
      mesh = nvfuser.DeviceMesh(range(d))
      inp0 = torch.randn(1, 2048, 96, 128, dtype=torch.bfloat16, device="cpu")
      inp1 = torch.randn(1, 2048, 96, 128, dtype=torch.bfloat16, device="cpu")
      inp2 = torch.randn(1, 2048, 96, 128, dtype=torch.bfloat16, device="cpu")
      sharded_inp0 = multidevice_test.shard_tensor(inp0, 2, mesh).transpose(1, 2).contiguous().transpose(1, 2)
      sharded_inp1 = multidevice_test.shard_tensor(inp1, 2, mesh).transpose(1, 2).contiguous().transpose(1, 2)
      sharded_inp2 = multidevice_test.shard_tensor(inp2, 2, mesh).transpose(1, 2).contiguous().transpose(1, 2)
      fd = CatReduction()
>     _, _ = fd.execute([sharded_inp0, sharded_inp1, sharded_inp2])

tests/python/multidevice/test_transformer.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = 
def nvfuser_fusion_id0(fd : FusionDefinition) -> None :
    T0 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguit...s.permute(T48, dims=[1, 0])
    fd.add_output(T47)
    fd.add_output(T49, stride_order=[0, 1])
    fd.add_output(T48)


inputs = [tensor([[[[ 1.5442e-02, -7.5781e-01,  7.2266e-02,  ..., -4.1016e-01,
           -4.0430e-01, -1.3281e+00],
          ...5e+00, -1.2266e+00,  ...,  5.1953e-01,
           -2.9102e-01, -1.5781e+00]]]], device='cuda:1', dtype=torch.bfloat16)]

    def execute(
        self,
        inputs,
        *,
        device=None,
        override_user_schedule=False,
        capture_debug_output=False,
        print_repro=False,
        profile=False,
        save_repro_inputs=False,
        _enable_options: list[str] = [],
        _disable_options: list[str] = [],
    ) -> list[torch.Tensor] | tuple[list[torch.Tensor], list[Sharding]]:
        """
        Executes an nvFuser set of kernels for a given Fusion
    
        The FusionDefinition will be executed on a single CUDA device.
        Typically, which device to run on is determined by the devices where
        the input tensors reside. However, if the Fusion is defined such that
        none of the inputs are tensors, we are not able to infer a device from
        the inputs. For example, the following FusionDefinition will be unable
        to unambiguously infer the device of its output:
    
            with FusionDefinition() as fd:
                tv1 = fd.ops.full([5])
                fd.add_output(tv1)
    
        In that case, we default to selecting the first CUDA
        device, i.e. `torch.device("cuda:0")`. This method enables selecting an
        alternative preferred device.
    
        Args:
            inputs (List[Union[Tensor, Scalar]]): A list of inputs to fusion.
    
        Kwargs:
            device (Optional[Union[int, str, torch.device]]): This is a hint to run
                the Fusion on the given CUDA device. This is not typically
                necessary, as the device is usually inferred from the locations
                of input tensors. However, for some fusion definitions, no
                tensors will be input (for example when all tensors are
                generated with `full` or `uniform` ops). In these cases, we
                must either tell NVFuser where to run the resulting kernel, or
                let it default to 0. Note that passing this option providing
                and input tensors that lie on another device is an error.
            override_user_schedule (bool): For a user defined schedule,
                override with auto-generated schedule (default: False)
            capture_debug_output (bool): Whether to capture any printed
                debugging information as a string. If True, the string can be
                retrieved after execution using :meth:`get_debug_output`. If False,
                then that method will return None when called.
            print_repro (bool): Prints a reproduction script to stdout.
            profile (bool): Captures a CUPTI based profile of a fusion.
            save_repro_inputs (bool): Saves the inputs for last_repro_script() to
                provide a provide a reproduction script.
            _enable_options/_disable_options (list): NVFUSER_ENABLE/DISABLE options to use.
                This is an alternative to environment variables.
                Note: Currently, we do not cache/store these options in the FusionCache which makes it
                    plausible to reuse kernels when executing the same fusion definition with different sets of options.
                    Reset the FusionCache manually to avoid inadvertent kernel reuse when between different sets of options.
    
        Returns:
            A list of output tensors and, if multidevice_schedule is defined, a
            list of output shardings. The latter is important to pack the outputs
            into DTensors for framework integration.
        """
        self.profiled = profile
    
        if not isinstance(device, int) and device is not None:
            if not isinstance(device, torch.device):
                device = torch.device(device)
            assert (
                device.type == "cuda"
            ), "If device argument is passed it must be a CUDA device"
            device = device.index
    
        # if definition is not defined by a context manager, try a child class
        defined_multidevice_schedule = hasattr(self, "multidevice_schedule")
        if self.id() is None:
            self._setup_definition()
            self.definition()
            self._finalize_definition()
    
            defined_schedule = hasattr(self, "schedule") and isinstance(
                self.schedule, Callable
            )
            assert not (
                defined_multidevice_schedule and defined_schedule
            ), "I haven't tested what if both are defined. We don't plan to support this use case although it may just work."
    
            if defined_multidevice_schedule:
                # Unlike `schedule`, `multidevice_schedule` is designed for inter-device
                # scheduling, The scheduling is done before concretization and therefore
                # before pre-segmentation. `schedule` however assumes the FusionDefinition
                # has been concretized and pre-segmented, and therefore requires
                # `_setup_schedule` and `_finalize_schedule` to be called before and after.
                #
                # Note: there's a plan to embed multidevice schedules into FusionDefinition
                # as annotating nodes. This may eventually replace `multidevice_schedule`.
                self._setup_multidevice_schedule()
                self.multidevice_schedule()
                self._finalize_multidevice_schedule()
    
            # If schedule is defined by child class and schedule is not defined for
            # inputs, make a schedule.
            if defined_schedule:
                # Schedule fusion if it does not exist yet or profiling fusion
                if profile or not self._exist_schedule(inputs):
                    self._setup_schedule(inputs, overwrite_existing_schedule=profile)
                    self.schedule()
                    self._finalize_schedule(inputs)
    
        if save_repro_inputs:
            from torch._subclasses.fake_tensor import FakeTensorMode
    
            fake_mode = FakeTensorMode()
            self.fake_inputs = [fake_mode.from_tensor(inp) for inp in inputs]
    
        if hasattr(self, "segments") and len(self.segments) > 0:
            return self._execute_segments(inputs, device=device, profile=profile)
    
        try:
            if print_repro:
                print(self.repro_script_for(inputs))
            if len(_enable_options) or len(_disable_options):
                warnings.warn(
                    "Reset the FusionCache manually to avoid reusing kernels when re-executing the fusion definition with different options."
                )
    
>           out_tensors, out_shardings = self._execute(
                inputs,
                device=device,
                override_user_schedule=override_user_schedule,
                capture_debug_output=capture_debug_output,
                profile=profile,
                _enable_options=_enable_options,
                _disable_options=_disable_options,
            )
E           RuntimeError:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp":465, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. Detected exception while compiling fusion segments in parallel. Error messages from all threads are printed below.
E           
E           Error from segmentation group 0:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp":178, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. 
E           // Codegen generated code
E           __global__ void nvfuser_reduction_f0_c1_r0_g0(Tensor<__bfloat, 4, 5> T0, Tensor<__bfloat, 4, 5> T1, Tensor<__bfloat, 4, 5> T2, Tensor<__bfloat, 1, 2> T11, Tensor<__bfloat, 3, 4> T14, Tensor<float, 1, 1> T18, Tensor<int64_t, 1, 1> T19) {
E             alignas(16) extern __shared__ char array[];
E             void* shared_mem = array;
E             NVFUSER_DEFINE_MAGIC_ZERO;
E             nvfuser_index_t i0;
E             i0 = ceilDiv((ceilDiv((ceilDiv(2048, ((nvfuser_index_t)blockDim.y))), 4)), ((nvfuser_index_t)gridDim.y));
E             nvfuser_index_t i1;
E             i1 = ((nvfuser_index_t)threadIdx.x) + (((nvfuser_index_t)blockDim.x) * ((nvfuser_index_t)blockIdx.x));
E             nvfuser_index_t i2;
E             i2 = ((nvfuser_index_t)blockDim.y) * 512;
E             nvfuser_index_t i3;
E             i3 = 8 * (i1 % 48);
E             nvfuser_index_t i4;
E             i4 = 128 * ((nvfuser_index_t)threadIdx.y);
E             nvfuser_index_t i5;
E             i5 = (i2 * i0) * ((nvfuser_index_t)blockIdx.y);
E             nvfuser_index_t i6;
E             i6 = 262144 * (i1 / 48);
E             nvfuser_index_t i7;
E             i7 = ((i4 + i5) + i6) + i3;
E             nvfuser_index_t i8;
E             i8 = 128 * ((nvfuser_index_t)blockDim.y);
E             nvfuser_index_t i9;
E             i9 = -128 + i3;
E             nvfuser_index_t i10;
E             i10 = (((-256 + i4) + i5) + i6) + i3;
E             nvfuser_index_t i11;
E             i11 = -256 + i3;
E             nvfuser_index_t i12;
E             i12 = (((-128 + i4) + i5) + i6) + i3;
E             nvfuser_index_t i13;
E             i13 = ((nvfuser_index_t)blockDim.y) * 73728;
E             nvfuser_index_t i14;
E             i14 = 8 * ((nvfuser_index_t)threadIdx.x);
E             nvfuser_index_t i15;
E             i15 = (8 * ((nvfuser_index_t)blockDim.x)) * ((nvfuser_index_t)blockIdx.x);
E             nvfuser_index_t i16;
E             i16 = (((18432 * ((nvfuser_index_t)threadIdx.y)) + ((i13 * i0) * ((nvfuser_index_t)blockIdx.y))) + i14) + i15;
E             nvfuser_index_t i17;
E             i17 = 18432 * ((nvfuser_index_t)blockDim.y);
E             nvfuser_index_t i18;
E             i18 = i14 + i15;
E             nvfuser_index_t i19;
E             i19 = (7 + i14) + i15;
E             bool b20;
E             b20 = (i19 < 36864) && (i19 < 18432);
E             nvfuser_index_t i21;
E             i21 = ((nvfuser_index_t)blockDim.y) * 4;
E             nvfuser_index_t i22;
E             i22 = (((i21 * ((nvfuser_index_t)blockIdx.y)) * i0) + (((nvfuser_index_t)blockDim.y) * 3)) + ((nvfuser_index_t)threadIdx.y);
E             nvfuser_index_t i23;
E             i23 = (-36864 + i14) + i15;
E             nvfuser_index_t i24;
E             i24 = (-18432 + i14) + i15;
E             nvfuser_index_t i25;
E             i25 = (-2048 + ((nvfuser_index_t)threadIdx.y)) + ((i21 * i0) * ((nvfuser_index_t)blockIdx.y));
E             bool b26;
E             b26 = (((nvfuser_index_t)blockIdx.y) == (((nvfuser_index_t)gridDim.y) + -1)) && (((nvfuser_index_t)threadIdx.y) == 0);
E             nvfuser_index_t i27;
E             i27 = 0LL + 128;
E             nvfuser_index_t i28;
E             i28 = i27 + 128;
E             // Allocate global tensor T18
E             // Allocate global tensor T19
E             Array<float, 8, 8> T17;
E             #pragma unroll
E             for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
E               T17[i29] = 0.000000000e+00f;
E             }
E             NVFUSER_UPDATE_MAGIC_ZERO;
E             #pragma unroll 1
E             for(nvfuser_index_t i30 = 0; i30 < i0; ++i30) {
E               nvfuser_index_t i31;
E               i31 = i2 * i30;
E               nvfuser_index_t i32;
E               i32 = i7 + i31;
E               nvfuser_index_t i33;
E               i33 = i10 + i31;
E               nvfuser_index_t i34;
E               i34 = i12 + i31;
E               nvfuser_index_t i35;
E               i35 = i16 + (i13 * i30);
E               nvfuser_index_t i36;
E               i36 = i21 * i30;
E               nvfuser_index_t i37;
E               i37 = i25 + i36;
E               if ((b20 && ((i22 + i36) < 2048))) {
E                 #pragma unroll
E                 for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
E                   nvfuser_index_t i38;
E                   i38 = i32 + i29;
E                   nvfuser_index_t i39;
E                   i39 = -i29;
E                   bool b40;
E                   b40 = i9 < i39;
E                   nvfuser_index_t i41;
E                   i41 = i33 + i29;
E                   bool b42;
E                   b42 = i11 >= i39;
E                   nvfuser_index_t i43;
E                   i43 = i34 + i29;
E                   bool b44;
E                   b44 = (i9 >= i39) && (i11 < i39);
E                   nvfuser_index_t i45;
E                   i45 = i35 + i29;
E                   #pragma unroll
E                   for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
E                     nvfuser_index_t i47;
E                     i47 = i46 + nvfuser_zero;
E                     nvfuser_index_t i48;
E                     i48 = i8 * i47;
E                     Array<__bfloat, 1, 1> T3;
E                     T3[0]
E                        = b40 ? T0[(i38 + i48)] : 0.0000e+00f;
E                     Array<__bfloat, 1, 1> T5;
E                     T5[0]
E                        = b42 ? T2[(i41 + i48)] : 0.0000e+00f;
E                     Array<__bfloat, 1, 1> T4;
E                     T4[0]
E                        = b44 ? T1[(i43 + i48)] : 0.0000e+00f;
E                     Array<__bfloat, 1, 1> T6;
E                     T6[0]
E                       = (T3[0] | T4[0])
E                       | T5[0];
E                     Array<__bfloat, 1, 1> T7;
E                     T7[0]
E                        = T6[0];
E                     Array<float, 1, 1> T8;
E                     T8[0]
E                        = __bfloat2float(T7[0]);
E                     Array<__bfloat, 1, 1> T16;
E                     T16[0]
E                        = T7[0];
E                     T14[(i45 + (i17 * i47))]
E                        = T16[0];
E                     Array<float, 1, 1> T9;
E                     T9[0]
E                        = T8[0];
E                     T17[i29]
E                       = T17[i29]
E                       + T9[0];
E                   }
E                 }
E                 NVFUSER_UPDATE_MAGIC_ZERO;
E               } else {
E                 #pragma unroll
E                 for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
E                   nvfuser_index_t i49;
E                   i49 = i32 + i29;
E                   nvfuser_index_t i50;
E                   i50 = -i29;
E                   bool b51;
E                   b51 = i9 < i50;
E                   nvfuser_index_t i52;
E                   i52 = i33 + i29;
E                   bool b53;
E                   b53 = i11 >= i50;
E                   nvfuser_index_t i54;
E                   i54 = i34 + i29;
E                   bool b55;
E                   b55 = (i9 >= i50) && (i11 < i50);
E                   nvfuser_index_t i56;
E                   i56 = i35 + i29;
E                   nvfuser_index_t i57;
E                   i57 = -(i29 + nvfuser_zero);
E                   bool b58;
E                   b58 = (i23 < i57) && (i24 < i57);
E                   #pragma unroll
E                   for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
E                     nvfuser_index_t i59;
E                     i59 = i46 + nvfuser_zero;
E                     nvfuser_index_t i60;
E                     i60 = i8 * i59;
E                     bool b61;
E                     b61 = b58 && (i37 < (-(((nvfuser_index_t)blockDim.y) * i59)));
E                     Array<__bfloat, 1, 1> T3;
E                     if (b61) {
E                       T3[0]
E                          = b51 ? T0[(i49 + i60)] : 0.0000e+00f;
E                     }
E                     Array<__bfloat, 1, 1> T5;
E                     if (b61) {
E                       T5[0]
E                          = b53 ? T2[(i52 + i60)] : 0.0000e+00f;
E                     }
E                     Array<__bfloat, 1, 1> T4;
E                     if (b61) {
E                       T4[0]
E                          = b55 ? T1[(i54 + i60)] : 0.0000e+00f;
E                     }
E                     Array<__bfloat, 1, 1> T6;
E                     if (b61) {
E                       T6[0]
E                         = (T3[0] | T4[0])
E                         | T5[0];
E                     }
E                     Array<__bfloat, 1, 1> T7;
E                     if (b61) {
E                       T7[0]
E                          = T6[0];
E                     }
E                     Array<float, 1, 1> T8;
E                     if (b61) {
E                       T8[0]
E                          = __bfloat2float(T7[0]);
E                     }
E                     Array<__bfloat, 1, 1> T16;
E                     if (b61) {
E                       T16[0]
E                          = T7[0];
E                     }
E                     if (b61) {
E                       T14[(i56 + (i17 * i59))]
E                          = T16[0];
E                     }
E                     Array<float, 1, 1> T9;
E                     if (b61) {
E                       T9[0]
E                          = T8[0];
E                     }
E                     if (b61) {
E                       T17[i29]
E                         = T17[i29]
E                         + T9[0];
E                     }
E                   }
E                 }
E                 NVFUSER_UPDATE_MAGIC_ZERO;
E               }
E             }
E             if (b20) {
E               Array<float, 8, 1> T10;
E               #pragma unroll
E               for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
E                 T10[i62] = 0.000000000e+00f;
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
E                 T10.array,
E                 T17.array,
E                 [](float &a, float b) { a = a + b; },
E                 &T18[0],
E                 &T19[0],
E                 static_cast<float*>(shared_mem),
E                 true,
E                 true,
E                 float(0.000000000e+00f),
E                 DefaultBlockDim());
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               #pragma unroll
E               for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
E                 Array<__bfloat, 1, 1> T15;
E                 if (b26) {
E                   T15[0]
E                      = __float2bfloat(T10[i63]);
E                 }
E                 if (b26) {
E                   T11[(i18 + (i63 + nvfuser_zero))]
E                      = T15[0];
E                 }
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E             } else {
E               Array<float, 8, 1> T10;
E               #pragma unroll
E               for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
E                 T10[i62] = 0.000000000e+00f;
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
E                 T10.array,
E                 T17.array,
E                 [](float &a, float b) { a = a + b; },
E                 &T18[0],
E                 &T19[0],
E                 static_cast<float*>(shared_mem),
E                 ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
E                 ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
E                 float(0.000000000e+00f),
E                 DefaultBlockDim());
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               #pragma unroll
E               for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
E                 nvfuser_index_t i64;
E                 i64 = i63 + nvfuser_zero;
E                 nvfuser_index_t i65;
E                 i65 = -i64;
E                 bool b66;
E                 b66 = i23 < i65;
E                 bool b67;
E                 b67 = i24 < i65;
E                 Array<__bfloat, 1, 1> T15;
E                 if ((b66 && b67)) {
E                   T15[0]
E                      = __float2bfloat(T10[i63]);
E                 }
E                 if (((b26 && b66) && b67)) {
E                   T11[(i18 + i64)]
E                      = T15[0];
E                 }
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E             }
E           }
E           
E           } // namespace nvf
E           
E           CUDA NVRTC compile error: __tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12953): error: identifier "i62" is undefined
E                   ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
E                              ^
E           
E           __tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12737): warning #550-D: variable "i28" was set but never used
E               nvfuser_index_t i28;
E                               ^
E           
E           Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"
E           
E           1 error detected in the compilation of "__tmp_nvfuser_reduction_f0_c1_r0_g0.cu".
E           
E           Exception raised from invoke at /opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp:178 (most recent call first):
E           frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x7b6018e3d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x7b6018e3dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #2: <unknown function> + 0x103f9b2 (0x7b601944f9b2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #3: <unknown function> + 0x1043ff0 (0x7b6019453ff0 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #4: <unknown function> + 0x1044c99 (0x7b6019454c99 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #5: nvfuser::CompiledKernel::compile(nvfuser::LaunchParams const&) + 0xd04 (0x7b6019458dc4 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #6: nvfuser::KernelExecutor::compile(nvfuser::Fusion*, nvfuser::KernelArgumentHolder const&, nvfuser::LaunchParams const&, nvfuser::CompileParams, nvfuser::SchedulerType) + 0x832 (0x7b6019474946 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #7: <unknown function> + 0x1082c8a (0x7b6019492c8a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #8: <unknown function> + 0x10e5ca6 (0x7b60194f5ca6 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #9: <unknown function> + 0x10e279a (0x7b60194f279a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #10: <unknown function> + 0x10e729a (0x7b60194f729a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #11: <unknown function> + 0x10e6eb2 (0x7b60194f6eb2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #12: <unknown function> + 0x10e6c8d (0x7b60194f6c8d in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #13: c10::ThreadPool::main_loop(unsigned long) + 0x2ad (0x7b615688b5ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
E           frame #14: <unknown function> + 0xecdb4 (0x7b6155f7bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
E           frame #15: <unknown function> + 0x9caa4 (0x7b6197c37aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           frame #16: <unknown function> + 0x129c3c (0x7b6197cc4c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           
E           
E           Use NVFUSER_DISABLE=parallel_compile to simplify error message.
E           Exception raised from compileFusionParallel at /opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp:465 (most recent call first):
E           frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x7b6018e3d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x7b6018e3dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #2: nvfuser::FusionKernelRuntime::compileFusionParallel(nvfuser::KernelArgumentHolder) + 0x61d (0x7b60194f2fd7 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #3: nvfuser::FusionExecutorCache::runFusionWithInputs(nvfuser::KernelArgumentHolder, std::optional<nvfuser::PrimDataType>, std::optional<signed char>) + 0x13f (0x7b60194dac71 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #4: nvfuser::python_frontend::FusionDefinition::execute(nvfuser::KernelArgumentHolder, std::optional<signed char>, bool, bool, bool, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) const + 0x790 (0x7b601986de1e in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #5: <unknown function> + 0x246f74 (0x7b6018656f74 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #6: <unknown function> + 0x37dd85 (0x7b601878dd85 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #7: <unknown function> + 0x36f08f (0x7b601877f08f in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #8: <unknown function> + 0x3153fd (0x7b60187253fd in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #9: <unknown function> + 0x3154ec (0x7b60187254ec in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #10: <unknown function> + 0x205d90 (0x7b6018615d90 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #11: /usr/bin/python3() [0x581d4f]
E           frame #12: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #13: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #14: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #15: /usr/bin/python3() [0x5a3148]
E           frame #16: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #17: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #18: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #19: /usr/bin/python3() [0x5a3148]
E           frame #20: PyObject_Call + 0x9c (0x54b13c in /usr/bin/python3)
E           frame #21: _PyEval_EvalFrameDefault + 0x4cc6 (0x5dad16 in /usr/bin/python3)
E           frame #22: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #23: /usr/bin/python3() [0x5a3148]
E           frame #24: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #25: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #26: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #27: /usr/bin/python3() [0x5a3148]
E           frame #28: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #29: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #30: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #31: /usr/bin/python3() [0x5a3148]
E           frame #32: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #33: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #34: PyEval_EvalCode + 0x15b (0x5d500b in /usr/bin/python3)
E           frame #35: /usr/bin/python3() [0x6081e2]
E           frame #36: /usr/bin/python3() [0x6b5033]
E           frame #37: _PyRun_SimpleFileObject + 0x1aa (0x6b4d9a in /usr/bin/python3)
E           frame #38: _PyRun_AnyFileObject + 0x4f (0x6b4bcf in /usr/bin/python3)
E           frame #39: Py_RunMain + 0x3b5 (0x6bcc35 in /usr/bin/python3)
E           frame #40: Py_BytesMain + 0x2d (0x6bc71d in /usr/bin/python3)
E           frame #41: <unknown function> + 0x2a1ca (0x7b6197bc51ca in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           frame #42: __libc_start_main + 0x8b (0x7b6197bc528b in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           frame #43: _start + 0x25 (0x6575a5 in /usr/bin/python3)

python/nvfuser/__init__.py:333: RuntimeError
---------------------------------------------------------------------------------------------- Captured log call ----------------------------------------------------------------------------------------------
ERROR    nvfuser:__init__.py:350 An error occurred while executing nvFuser FusionDefinition 0.
If you believe this is a bug or need assistance, please file an issue at https://github.com/NVIDIA/Fuser/issues/new
Here's a script to reproduce the error:
```python
# CUDA devices:
#  0: NVIDIA RTX 6000 Ada Generation
#  1: NVIDIA RTX 6000 Ada Generation
# torch version: 2.8.0a0+34c6371d24.nvInternal
# cuda version: 13.0
# nvfuser version: 0.2.28+gitf13308c
import torch
from nvfuser import FusionDefinition, DataType

def nvfuser_fusion_id0(fd : FusionDefinition) -> None :
    T0 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
    T1 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
    T2 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
    S3 = fd.define_scalar(0.00000, dtype=DataType.BFloat16)
    S4 = fd.define_scalar(0, dtype=DataType.Int)
    S5 = fd.define_scalar(0, dtype=DataType.Int)
    S6 = fd.define_scalar(0, dtype=DataType.Int)
    S7 = fd.define_scalar(0, dtype=DataType.Int)
    S8 = fd.define_scalar(0, dtype=DataType.Int)
    S9 = fd.define_scalar(0, dtype=DataType.Int)
    S10 = fd.define_scalar(0, dtype=DataType.Int)
    S11 = fd.define_scalar(256, dtype=DataType.Int)
    V12 = fd.define_vector([S10, S11, S8, S9, S6, S7, S4, S5], dtype=DataType.Int)
    T13 = fd.ops.pad(T0, V12, S3)
    S14 = fd.define_scalar(0, dtype=DataType.Int)
    S15 = fd.ops.size(T1, dim=3)
    S16 = fd.ops.add(S14, S15)
    S17 = fd.define_scalar(0.00000, dtype=DataType.BFloat16)
    S18 = fd.define_scalar(0, dtype=DataType.Int)
    S19 = fd.define_scalar(0, dtype=DataType.Int)
    S20 = fd.define_scalar(0, dtype=DataType.Int)
    S21 = fd.define_scalar(0, dtype=DataType.Int)
    S22 = fd.define_scalar(0, dtype=DataType.Int)
    S23 = fd.define_scalar(0, dtype=DataType.Int)
    S24 = fd.define_scalar(128, dtype=DataType.Int)
    V25 = fd.define_vector([S16, S24, S22, S23, S20, S21, S18, S19], dtype=DataType.Int)
    T26 = fd.ops.pad(T1, V25, S17)
    S27 = fd.ops.add(S16, S15)
    S28 = fd.define_scalar(0.00000, dtype=DataType.BFloat16)
    S29 = fd.define_scalar(0, dtype=DataType.Int)
    S30 = fd.define_scalar(0, dtype=DataType.Int)
    S31 = fd.define_scalar(0, dtype=DataType.Int)
    S32 = fd.define_scalar(0, dtype=DataType.Int)
    S33 = fd.define_scalar(0, dtype=DataType.Int)
    S34 = fd.define_scalar(0, dtype=DataType.Int)
    S35 = fd.define_scalar(0, dtype=DataType.Int)
    V36 = fd.define_vector([S27, S35, S33, S34, S31, S32, S29, S30], dtype=DataType.Int)
    T37 = fd.ops.pad(T2, V36, S28)
    T38 = fd.ops.cat([T13, T26, T37], dim=3, manual_padding=1)
    S39 = fd.ops.size(T37, dim=0)
    S40 = fd.ops.size(T37, dim=1)
    S41 = fd.define_scalar(36864, dtype=DataType.Int)
    V42 = fd.define_vector([S39, S40, S41], dtype=DataType.Int)
    T43 = fd.ops.reshape(T38, new_shape=V42)
    T44 = fd.ops.cast(T43, dtype=DataType.Float)
    T45 = fd.ops.squeeze(T44, dims=[0], squeeze_expanded=True)
    T46 = fd.ops.sum(T45, dims=[0], keepdim=False, dtype=DataType.Float)
    T47 = fd.ops.cast(T46, dtype=DataType.BFloat16)
    T48 = fd.ops.squeeze(T43, dims=[0], squeeze_expanded=True)
    T49 = fd.ops.permute(T48, dims=[1, 0])
    fd.add_output(T47)
    fd.add_output(T49, stride_order=[0, 1])
    fd.add_output(T48)

with FusionDefinition() as fd:
    nvfuser_fusion_id0(fd)

inputs = [
    torch.randn(12582912, dtype=torch.bfloat16, device='cuda:1').as_strided((1, 2048, 48, 128), (12582912, 128, 262144, 1)),
    torch.randn(12582912, dtype=torch.bfloat16, device='cuda:1').as_strided((1, 2048, 48, 128), (12582912, 128, 262144, 1)),
    torch.randn(12582912, dtype=torch.bfloat16, device='cuda:1').as_strided((1, 2048, 48, 128), (12582912, 128, 262144, 1)),
]
fd.execute(inputs)
```
Traceback (most recent call last):
  File "/opt/pytorch/nvfuser/python/nvfuser/__init__.py", line 333, in execute
    out_tensors, out_shardings = self._execute(
                                 ^^^^^^^^^^^^^^
RuntimeError:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp":465, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. Detected exception while compiling fusion segments in parallel. Error messages from all threads are printed below.

Error from segmentation group 0:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp":178, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. 
// Codegen generated code
__global__ void nvfuser_reduction_f0_c1_r0_g0(Tensor<__bfloat, 4, 5> T0, Tensor<__bfloat, 4, 5> T1, Tensor<__bfloat, 4, 5> T2, Tensor<__bfloat, 1, 2> T11, Tensor<__bfloat, 3, 4> T14, Tensor<float, 1, 1> T18, Tensor<int64_t, 1, 1> T19) {
  alignas(16) extern __shared__ char array[];
  void* shared_mem = array;
  NVFUSER_DEFINE_MAGIC_ZERO;
  nvfuser_index_t i0;
  i0 = ceilDiv((ceilDiv((ceilDiv(2048, ((nvfuser_index_t)blockDim.y))), 4)), ((nvfuser_index_t)gridDim.y));
  nvfuser_index_t i1;
  i1 = ((nvfuser_index_t)threadIdx.x) + (((nvfuser_index_t)blockDim.x) * ((nvfuser_index_t)blockIdx.x));
  nvfuser_index_t i2;
  i2 = ((nvfuser_index_t)blockDim.y) * 512;
  nvfuser_index_t i3;
  i3 = 8 * (i1 % 48);
  nvfuser_index_t i4;
  i4 = 128 * ((nvfuser_index_t)threadIdx.y);
  nvfuser_index_t i5;
  i5 = (i2 * i0) * ((nvfuser_index_t)blockIdx.y);
  nvfuser_index_t i6;
  i6 = 262144 * (i1 / 48);
  nvfuser_index_t i7;
  i7 = ((i4 + i5) + i6) + i3;
  nvfuser_index_t i8;
  i8 = 128 * ((nvfuser_index_t)blockDim.y);
  nvfuser_index_t i9;
  i9 = -128 + i3;
  nvfuser_index_t i10;
  i10 = (((-256 + i4) + i5) + i6) + i3;
  nvfuser_index_t i11;
  i11 = -256 + i3;
  nvfuser_index_t i12;
  i12 = (((-128 + i4) + i5) + i6) + i3;
  nvfuser_index_t i13;
  i13 = ((nvfuser_index_t)blockDim.y) * 73728;
  nvfuser_index_t i14;
  i14 = 8 * ((nvfuser_index_t)threadIdx.x);
  nvfuser_index_t i15;
  i15 = (8 * ((nvfuser_index_t)blockDim.x)) * ((nvfuser_index_t)blockIdx.x);
  nvfuser_index_t i16;
  i16 = (((18432 * ((nvfuser_index_t)threadIdx.y)) + ((i13 * i0) * ((nvfuser_index_t)blockIdx.y))) + i14) + i15;
  nvfuser_index_t i17;
  i17 = 18432 * ((nvfuser_index_t)blockDim.y);
  nvfuser_index_t i18;
  i18 = i14 + i15;
  nvfuser_index_t i19;
  i19 = (7 + i14) + i15;
  bool b20;
  b20 = (i19 < 36864) && (i19 < 18432);
  nvfuser_index_t i21;
  i21 = ((nvfuser_index_t)blockDim.y) * 4;
  nvfuser_index_t i22;
  i22 = (((i21 * ((nvfuser_index_t)blockIdx.y)) * i0) + (((nvfuser_index_t)blockDim.y) * 3)) + ((nvfuser_index_t)threadIdx.y);
  nvfuser_index_t i23;
  i23 = (-36864 + i14) + i15;
  nvfuser_index_t i24;
  i24 = (-18432 + i14) + i15;
  nvfuser_index_t i25;
  i25 = (-2048 + ((nvfuser_index_t)threadIdx.y)) + ((i21 * i0) * ((nvfuser_index_t)blockIdx.y));
  bool b26;
  b26 = (((nvfuser_index_t)blockIdx.y) == (((nvfuser_index_t)gridDim.y) + -1)) && (((nvfuser_index_t)threadIdx.y) == 0);
  nvfuser_index_t i27;
  i27 = 0LL + 128;
  nvfuser_index_t i28;
  i28 = i27 + 128;
  // Allocate global tensor T18
  // Allocate global tensor T19
  Array<float, 8, 8> T17;
  #pragma unroll
  for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
    T17[i29] = 0.000000000e+00f;
  }
  NVFUSER_UPDATE_MAGIC_ZERO;
  #pragma unroll 1
  for(nvfuser_index_t i30 = 0; i30 < i0; ++i30) {
    nvfuser_index_t i31;
    i31 = i2 * i30;
    nvfuser_index_t i32;
    i32 = i7 + i31;
    nvfuser_index_t i33;
    i33 = i10 + i31;
    nvfuser_index_t i34;
    i34 = i12 + i31;
    nvfuser_index_t i35;
    i35 = i16 + (i13 * i30);
    nvfuser_index_t i36;
    i36 = i21 * i30;
    nvfuser_index_t i37;
    i37 = i25 + i36;
    if ((b20 && ((i22 + i36) < 2048))) {
      #pragma unroll
      for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
        nvfuser_index_t i38;
        i38 = i32 + i29;
        nvfuser_index_t i39;
        i39 = -i29;
        bool b40;
        b40 = i9 < i39;
        nvfuser_index_t i41;
        i41 = i33 + i29;
        bool b42;
        b42 = i11 >= i39;
        nvfuser_index_t i43;
        i43 = i34 + i29;
        bool b44;
        b44 = (i9 >= i39) && (i11 < i39);
        nvfuser_index_t i45;
        i45 = i35 + i29;
        #pragma unroll
        for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
          nvfuser_index_t i47;
          i47 = i46 + nvfuser_zero;
          nvfuser_index_t i48;
          i48 = i8 * i47;
          Array<__bfloat, 1, 1> T3;
          T3[0]
             = b40 ? T0[(i38 + i48)] : 0.0000e+00f;
          Array<__bfloat, 1, 1> T5;
          T5[0]
             = b42 ? T2[(i41 + i48)] : 0.0000e+00f;
          Array<__bfloat, 1, 1> T4;
          T4[0]
             = b44 ? T1[(i43 + i48)] : 0.0000e+00f;
          Array<__bfloat, 1, 1> T6;
          T6[0]
            = (T3[0] | T4[0])
            | T5[0];
          Array<__bfloat, 1, 1> T7;
          T7[0]
             = T6[0];
          Array<float, 1, 1> T8;
          T8[0]
             = __bfloat2float(T7[0]);
          Array<__bfloat, 1, 1> T16;
          T16[0]
             = T7[0];
          T14[(i45 + (i17 * i47))]
             = T16[0];
          Array<float, 1, 1> T9;
          T9[0]
             = T8[0];
          T17[i29]
            = T17[i29]
            + T9[0];
        }
      }
      NVFUSER_UPDATE_MAGIC_ZERO;
    } else {
      #pragma unroll
      for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
        nvfuser_index_t i49;
        i49 = i32 + i29;
        nvfuser_index_t i50;
        i50 = -i29;
        bool b51;
        b51 = i9 < i50;
        nvfuser_index_t i52;
        i52 = i33 + i29;
        bool b53;
        b53 = i11 >= i50;
        nvfuser_index_t i54;
        i54 = i34 + i29;
        bool b55;
        b55 = (i9 >= i50) && (i11 < i50);
        nvfuser_index_t i56;
        i56 = i35 + i29;
        nvfuser_index_t i57;
        i57 = -(i29 + nvfuser_zero);
        bool b58;
        b58 = (i23 < i57) && (i24 < i57);
        #pragma unroll
        for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
          nvfuser_index_t i59;
          i59 = i46 + nvfuser_zero;
          nvfuser_index_t i60;
          i60 = i8 * i59;
          bool b61;
          b61 = b58 && (i37 < (-(((nvfuser_index_t)blockDim.y) * i59)));
          Array<__bfloat, 1, 1> T3;
          if (b61) {
            T3[0]
               = b51 ? T0[(i49 + i60)] : 0.0000e+00f;
          }
          Array<__bfloat, 1, 1> T5;
          if (b61) {
            T5[0]
               = b53 ? T2[(i52 + i60)] : 0.0000e+00f;
          }
          Array<__bfloat, 1, 1> T4;
          if (b61) {
            T4[0]
               = b55 ? T1[(i54 + i60)] : 0.0000e+00f;
          }
          Array<__bfloat, 1, 1> T6;
          if (b61) {
            T6[0]
              = (T3[0] | T4[0])
              | T5[0];
          }
          Array<__bfloat, 1, 1> T7;
          if (b61) {
            T7[0]
               = T6[0];
          }
          Array<float, 1, 1> T8;
          if (b61) {
            T8[0]
               = __bfloat2float(T7[0]);
          }
          Array<__bfloat, 1, 1> T16;
          if (b61) {
            T16[0]
               = T7[0];
          }
          if (b61) {
            T14[(i56 + (i17 * i59))]
               = T16[0];
          }
          Array<float, 1, 1> T9;
          if (b61) {
            T9[0]
               = T8[0];
          }
          if (b61) {
            T17[i29]
              = T17[i29]
              + T9[0];
          }
        }
      }
      NVFUSER_UPDATE_MAGIC_ZERO;
    }
  }
  if (b20) {
    Array<float, 8, 1> T10;
    #pragma unroll
    for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
      T10[i62] = 0.000000000e+00f;
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
    reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
      T10.array,
      T17.array,
      [](float &a, float b) { a = a + b; },
      &T18[0],
      &T19[0],
      static_cast<float*>(shared_mem),
      true,
      true,
      float(0.000000000e+00f),
      DefaultBlockDim());
    NVFUSER_UPDATE_MAGIC_ZERO;
    #pragma unroll
    for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
      Array<__bfloat, 1, 1> T15;
      if (b26) {
        T15[0]
           = __float2bfloat(T10[i63]);
      }
      if (b26) {
        T11[(i18 + (i63 + nvfuser_zero))]
           = T15[0];
      }
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
  } else {
    Array<float, 8, 1> T10;
    #pragma unroll
    for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
      T10[i62] = 0.000000000e+00f;
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
    reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
      T10.array,
      T17.array,
      [](float &a, float b) { a = a + b; },
      &T18[0],
      &T19[0],
      static_cast<float*>(shared_mem),
      ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
      ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
      float(0.000000000e+00f),
      DefaultBlockDim());
    NVFUSER_UPDATE_MAGIC_ZERO;
    #pragma unroll
    for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
      nvfuser_index_t i64;
      i64 = i63 + nvfuser_zero;
      nvfuser_index_t i65;
      i65 = -i64;
      bool b66;
      b66 = i23 < i65;
      bool b67;
      b67 = i24 < i65;
      Array<__bfloat, 1, 1> T15;
      if ((b66 && b67)) {
        T15[0]
           = __float2bfloat(T10[i63]);
      }
      if (((b26 && b66) && b67)) {
        T11[(i18 + i64)]
           = T15[0];
      }
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
  }
}

} // namespace nvf

CUDA NVRTC compile error: __tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12953): error: identifier "i62" is undefined
        ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
                   ^

__tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12737): warning #550-D: variable "i28" was set but never used
    nvfuser_index_t i28;
                    ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

1 error detected in the compilation of "__tmp_nvfuser_reduction_f0_c1_r0_g0.cu".

Exception raised from invoke at /opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp:178 (most recent call first):
frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x7b6018e3d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x7b6018e3dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #2: <unknown function> + 0x103f9b2 (0x7b601944f9b2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #3: <unknown function> + 0x1043ff0 (0x7b6019453ff0 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #4: <unknown function> + 0x1044c99 (0x7b6019454c99 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #5: nvfuser::CompiledKernel::compile(nvfuser::LaunchParams const&) + 0xd04 (0x7b6019458dc4 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #6: nvfuser::KernelExecutor::compile(nvfuser::Fusion*, nvfuser::KernelArgumentHolder const&, nvfuser::LaunchParams const&, nvfuser::CompileParams, nvfuser::SchedulerType) + 0x832 (0x7b6019474946 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #7: <unknown function> + 0x1082c8a (0x7b6019492c8a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #8: <unknown function> + 0x10e5ca6 (0x7b60194f5ca6 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #9: <unknown function> + 0x10e279a (0x7b60194f279a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #10: <unknown function> + 0x10e729a (0x7b60194f729a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #11: <unknown function> + 0x10e6eb2 (0x7b60194f6eb2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #12: <unknown function> + 0x10e6c8d (0x7b60194f6c8d in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #13: c10::ThreadPool::main_loop(unsigned long) + 0x2ad (0x7b615688b5ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #14: <unknown function> + 0xecdb4 (0x7b6155f7bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #15: <unknown function> + 0x9caa4 (0x7b6197c37aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #16: <unknown function> + 0x129c3c (0x7b6197cc4c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)


Use NVFUSER_DISABLE=parallel_compile to simplify error message.
Exception raised from compileFusionParallel at /opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp:465 (most recent call first):
frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x7b6018e3d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x7b6018e3dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #2: nvfuser::FusionKernelRuntime::compileFusionParallel(nvfuser::KernelArgumentHolder) + 0x61d (0x7b60194f2fd7 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #3: nvfuser::FusionExecutorCache::runFusionWithInputs(nvfuser::KernelArgumentHolder, std::optional<nvfuser::PrimDataType>, std::optional<signed char>) + 0x13f (0x7b60194dac71 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #4: nvfuser::python_frontend::FusionDefinition::execute(nvfuser::KernelArgumentHolder, std::optional<signed char>, bool, bool, bool, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) const + 0x790 (0x7b601986de1e in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #5: <unknown function> + 0x246f74 (0x7b6018656f74 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #6: <unknown function> + 0x37dd85 (0x7b601878dd85 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #7: <unknown function> + 0x36f08f (0x7b601877f08f in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #8: <unknown function> + 0x3153fd (0x7b60187253fd in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #9: <unknown function> + 0x3154ec (0x7b60187254ec in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #10: <unknown function> + 0x205d90 (0x7b6018615d90 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #11: /usr/bin/python3() [0x581d4f]
frame #12: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #13: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #14: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #15: /usr/bin/python3() [0x5a3148]
frame #16: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #17: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #18: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #19: /usr/bin/python3() [0x5a3148]
frame #20: PyObject_Call + 0x9c (0x54b13c in /usr/bin/python3)
frame #21: _PyEval_EvalFrameDefault + 0x4cc6 (0x5dad16 in /usr/bin/python3)
frame #22: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #23: /usr/bin/python3() [0x5a3148]
frame #24: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #25: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #26: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #27: /usr/bin/python3() [0x5a3148]
frame #28: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #29: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #30: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #31: /usr/bin/python3() [0x5a3148]
frame #32: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #33: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #34: PyEval_EvalCode + 0x15b (0x5d500b in /usr/bin/python3)
frame #35: /usr/bin/python3() [0x6081e2]
frame #36: /usr/bin/python3() [0x6b5033]
frame #37: _PyRun_SimpleFileObject + 0x1aa (0x6b4d9a in /usr/bin/python3)
frame #38: _PyRun_AnyFileObject + 0x4f (0x6b4bcf in /usr/bin/python3)
frame #39: Py_RunMain + 0x3b5 (0x6bcc35 in /usr/bin/python3)
frame #40: Py_BytesMain + 0x2d (0x6bc71d in /usr/bin/python3)
frame #41: <unknown function> + 0x2a1ca (0x7b6197bc51ca in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #42: __libc_start_main + 0x8b (0x7b6197bc528b in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #43: _start + 0x25 (0x6575a5 in /usr/bin/python3)
=============================================================================================== MPI Information ===============================================================================================
rank: 1
size: 2
MPI version: 3.1
MPI library version: Open MPI v4.1.9a1, package: Open MPI root@sharp-ci-02 Distribution, ident: 4.1.9a1, repo rev: v4.1.5-222-g92f9fca4eb, Unreleased developer copy 
MPI vendor: Open MPI 4.1.9
mpi4py rc: 
mpi4py config:
=========================================================================================== short test summary info ===========================================================================================
FAILED tests/python/multidevice/test_transformer.py::test_cat_reduction - RuntimeError:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp":465, please report a bug wi...
======================================================================================= 1 failed, 4 deselected in 6.15s =======================================================================================
