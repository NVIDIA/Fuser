===================================== test session starts ======================================
platform linux -- Python 3.12.3, pytest-8.3.5, pluggy-1.6.0
Test order randomisation NOT enabled. Enable with --random-order or --random-order-bucket=<bucket_type>
benchmark: 5.1.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /opt/pytorch/nvfuser
plugins: timeout-2.4.0, xdist-3.7.0, random-order-1.2.0, cov-6.2.1, timestamper-0.0.10, shard-0.1.2, benchmark-5.1.0, hypothesis-6.136.6, mpi-0.6
collecting ... collecting 5 items                                                                             collected 5 items / 4 deselected / 1 selected                                                  
Running 1 items in this shard

tests/python/multidevice/test_transformer.py Inputs:
  T0_g___bfloat[ideviceIdx.x128{2}, iS303{( ceilDiv(768, blockDim.x) )}, iS302{blockDim.x}, iS312{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS304{1}, iS300{8}, iS311{gridDim.y}, iS306{blockDim.y}, iS310{1}, iS308{4}, bS0{1}] (DeviceMesh{0 1})
  T1_g___bfloat[ideviceIdx.x122{2}, iS275{( ceilDiv(768, blockDim.x) )}, iS274{blockDim.x}, iS284{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS276{1}, iS272{8}, iS283{gridDim.y}, iS278{blockDim.y}, iS282{1}, iS280{4}, bS4{1}] (DeviceMesh{0 1})
  T2_g___bfloat[ideviceIdx.x116{2}, iS247{( ceilDiv(768, blockDim.x) )}, iS246{blockDim.x}, iS256{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS248{1}, iS244{8}, iS255{gridDim.y}, iS250{blockDim.y}, iS254{1}, iS252{4}, bS8{1}] (DeviceMesh{0 1})
Outputs:
  T11_g___bfloat[ideviceIdx.x102{2}, iblockIdx.x351{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x350{blockDim.x}, iUS352{1}, iS348{8}] ca_pos( 5 ) produce_pos( 5 ) (DeviceMesh{0 1})
  T14_g___bfloat[ideviceIdx.x107{2}, iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x330{blockDim.x}, iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS332{1}, iS328{8}, iblockIdx.y339{gridDim.y}, ithreadIdx.y334{blockDim.y}, iUS338{1}, iS336{4}, bS104{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})

%kernel {
T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1})
   = pad( T0_g___bfloat[ideviceIdx.x128{2}, iS303{( ceilDiv(768, blockDim.x) )}, iS302{blockDim.x}, iS312{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS304{1}, iS300{8}, iS311{gridDim.y}, iS306{blockDim.y}, iS310{1}, iS308{4}, bS0{1}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, 0, 256} )
i43 = 0 + 128;
T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x261{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1})
   = pad( T1_g___bfloat[ideviceIdx.x122{2}, iS275{( ceilDiv(768, blockDim.x) )}, iS274{blockDim.x}, iS284{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS276{1}, iS272{8}, iS283{gridDim.y}, iS278{blockDim.y}, iS282{1}, iS280{4}, bS4{1}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i43, 128} )
i66 = i43 + 128;
T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x233{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1})
   = pad( T2_g___bfloat[ideviceIdx.x116{2}, iS247{( ceilDiv(768, blockDim.x) )}, iS246{blockDim.x}, iS256{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS248{1}, iS244{8}, iS255{gridDim.y}, iS250{blockDim.y}, iS254{1}, iS252{4}, bS8{1}] (DeviceMesh{0 1}), {0, 0, 0, 0, 0, 0, i66, 0} )
T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
   = cat( T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1}), T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x261{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1}), T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x233{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1}), 3 )
T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = view( T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) )
T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
   = __bfloat2float(T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}));
T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
   = squeeze( T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), flags = {true, false, false} )
T17_l_float[ideviceIdx.x146{2}, iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, iUS153{1}, iS149{8}, iblockIdx.y160{gridDim.y}rf, ithreadIdx.y155{blockDim.y}rf, rUS159{1}rf, rS157{4}rf] ca_pos( 3 ) produce_pos( 10 ) (DeviceMesh{0 1})
   = reduction( T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), op = add, initial value = float(0), allreduce = false )
T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1})
   = reduction( T17_l_float[ideviceIdx.x146{2}, iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, iUS153{1}, iS149{8}, iblockIdx.y160{gridDim.y}rf, ithreadIdx.y155{blockDim.y}rf, rUS159{1}rf, rS157{4}rf] ca_pos( 3 ) produce_pos( 10 ) (DeviceMesh{0 1}), op = add, initial value = float(0), allreduce = false )
T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1})
   = __float2bfloat(T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1}));
T11_g___bfloat[ideviceIdx.x102{2}, iblockIdx.x351{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x350{blockDim.x}, iUS352{1}, iS348{8}] ca_pos( 5 ) produce_pos( 5 ) (DeviceMesh{0 1})
   = Set( T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1}), cache_op=Streaming )
T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
   = SegmenterSet( T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) )
T14_g___bfloat[ideviceIdx.x107{2}, iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x330{blockDim.x}, iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS332{1}, iS328{8}, iblockIdx.y339{gridDim.y}, ithreadIdx.y334{blockDim.y}, iUS338{1}, iS336{4}, bS104{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
   = Set( T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), cache_op=Streaming )

TransformPrinter : 
T0_g___bfloat[ideviceIdx.x128{2}, iS303{( ceilDiv(768, blockDim.x) )}, iS302{blockDim.x}, iS312{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS304{1}, iS300{8}, iS311{gridDim.y}, iS306{blockDim.y}, iS310{1}, iS308{4}, bS0{1}] (DeviceMesh{0 1})
 logical domain : (bS0{1}, iS1{2048}, iS2{96}, iS3{128})
 allocation domain : (ideviceIdx.x50{2}, bS0{1}, iS51{48}, iS1{2048}, iS3{128})
 contiguity: t n t t t
  Outer split: iS2{96} by factor 2 -> ideviceIdx.x50{2}, iS51{48}
  Merge: iS2{96} and iS3{128} -> iS127{12288}
  Split: iS1{2048} by factor blockDim.y -> iS305{( ceilDiv(2048, blockDim.y) )}, iS306{blockDim.y}
  Outer split: iS127{12288} by factor 2 -> ideviceIdx.x128{2}, iS129{6144}
  Split: iS305{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS307{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS308{4}
  Split: iS129{6144} by factor 8 -> iS299{768}, iS300{8}
  Split: iS307{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS309{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS310{1}
  Split: iS299{768} by factor blockDim.x -> iS301{( ceilDiv(768, blockDim.x) )}, iS302{blockDim.x}
  Outer split: iS309{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iS311{gridDim.y}, iS312{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS301{( ceilDiv(768, blockDim.x) )} by factor 1 -> iS303{( ceilDiv(768, blockDim.x) )}, iS304{1}
 loop domain : (ideviceIdx.x128{2}, iS303{( ceilDiv(768, blockDim.x) )}, iS302{blockDim.x}, iS312{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS304{1}, iS300{8}, iS311{gridDim.y}, iS306{blockDim.y}, iS310{1}, iS308{4}, bS0{1})
T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1})
 root domain : (bS12{1}, iS13{2048}, iS14{96}, iS15{128}rf)
  Resize: iS15{128}rf by 0 and 256 -> iS16{384}rf
 logical domain : (bS12{1}, iS13{2048}, iS14{96}, iS16{384}rf)
 allocation domain : (ideviceIdx.x56{2}, bS12{1}, iS13{2048}, iS57{48}, iS16{384}rf)
 contiguity: t n t t t
  Outer split: iS14{96} by factor 2 -> ideviceIdx.x56{2}, iS57{48}
  Split: iS13{2048} by factor blockDim.y -> iS291{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y292{blockDim.y}
  Split: iS291{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS293{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS294{4}
  Resize: iS15{128}rf by 0 and 256 -> iS16{384}rf
  Merge: iS14{96} and iS16{384}rf -> iS124{36864}
  Outer split: iS124{36864} by factor 2 -> ideviceIdx.x125{2}, iS126{18432}
  Split: iS293{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS295{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS296{1}
  Outer split: iS295{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y297{gridDim.y}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS126{18432} by factor 8 -> iS285{2304}, iS286{8}
  Split: iS285{2304} by factor blockDim.x -> iS287{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}
  Split: iS287{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, iUS290{1}
 loop domain : (ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1})
T1_g___bfloat[ideviceIdx.x122{2}, iS275{( ceilDiv(768, blockDim.x) )}, iS274{blockDim.x}, iS284{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS276{1}, iS272{8}, iS283{gridDim.y}, iS278{blockDim.y}, iS282{1}, iS280{4}, bS4{1}] (DeviceMesh{0 1})
 logical domain : (bS4{1}, iS5{2048}, iS6{96}, iS7{128})
 allocation domain : (ideviceIdx.x52{2}, bS4{1}, iS53{48}, iS5{2048}, iS7{128})
 contiguity: t n t t t
  Outer split: iS6{96} by factor 2 -> ideviceIdx.x52{2}, iS53{48}
  Merge: iS6{96} and iS7{128} -> iS121{12288}
  Split: iS5{2048} by factor blockDim.y -> iS277{( ceilDiv(2048, blockDim.y) )}, iS278{blockDim.y}
  Outer split: iS121{12288} by factor 2 -> ideviceIdx.x122{2}, iS123{6144}
  Split: iS277{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS279{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS280{4}
  Split: iS123{6144} by factor 8 -> iS271{768}, iS272{8}
  Split: iS279{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS281{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS282{1}
  Split: iS271{768} by factor blockDim.x -> iS273{( ceilDiv(768, blockDim.x) )}, iS274{blockDim.x}
  Outer split: iS281{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iS283{gridDim.y}, iS284{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS273{( ceilDiv(768, blockDim.x) )} by factor 1 -> iS275{( ceilDiv(768, blockDim.x) )}, iS276{1}
 loop domain : (ideviceIdx.x122{2}, iS275{( ceilDiv(768, blockDim.x) )}, iS274{blockDim.x}, iS284{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS276{1}, iS272{8}, iS283{gridDim.y}, iS278{blockDim.y}, iS282{1}, iS280{4}, bS4{1})
T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x261{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1})
 root domain : (bS17{1}, iS18{2048}, iS19{96}, iS20{128}rf)
  Resize: iS20{128}rf by ( 0 + 128 ) and 128 -> iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf
 logical domain : (bS17{1}, iS18{2048}, iS19{96}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf)
 allocation domain : (ideviceIdx.x58{2}, bS17{1}, iS18{2048}, iS59{48}, iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf)
 contiguity: t n t t t
  Outer split: iS19{96} by factor 2 -> ideviceIdx.x58{2}, iS59{48}
  Split: iS18{2048} by factor blockDim.y -> iS263{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y264{blockDim.y}
  Split: iS263{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS265{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS266{4}
  Resize: iS20{128}rf by ( 0 + 128 ) and 128 -> iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf
  Merge: iS19{96} and iS21{( ( ( 0 + 128 ) + 128 ) + 128 )}rf -> iS118{( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 )}
  Outer split: iS118{( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 )} by factor 2 -> ideviceIdx.x119{2}, iS120{( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) )}
  Split: iS265{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS267{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS268{1}
  Outer split: iS267{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y269{gridDim.y}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS120{( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) )} by factor 8 -> iS257{( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) )}, iS258{8}
  Split: iS257{( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) )} by factor blockDim.x -> iS259{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x260{blockDim.x}
  Split: iS259{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )} by factor 1 -> iblockIdx.x261{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, iUS262{1}
 loop domain : (ideviceIdx.x119{2}, iblockIdx.x261{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1})
T2_g___bfloat[ideviceIdx.x116{2}, iS247{( ceilDiv(768, blockDim.x) )}, iS246{blockDim.x}, iS256{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS248{1}, iS244{8}, iS255{gridDim.y}, iS250{blockDim.y}, iS254{1}, iS252{4}, bS8{1}] (DeviceMesh{0 1})
 logical domain : (bS8{1}, iS9{2048}, iS10{96}, iS11{128})
 allocation domain : (ideviceIdx.x54{2}, bS8{1}, iS55{48}, iS9{2048}, iS11{128})
 contiguity: t n t t t
  Outer split: iS10{96} by factor 2 -> ideviceIdx.x54{2}, iS55{48}
  Merge: iS10{96} and iS11{128} -> iS115{12288}
  Split: iS9{2048} by factor blockDim.y -> iS249{( ceilDiv(2048, blockDim.y) )}, iS250{blockDim.y}
  Outer split: iS115{12288} by factor 2 -> ideviceIdx.x116{2}, iS117{6144}
  Split: iS249{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS251{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS252{4}
  Split: iS117{6144} by factor 8 -> iS243{768}, iS244{8}
  Split: iS251{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS253{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS254{1}
  Split: iS243{768} by factor blockDim.x -> iS245{( ceilDiv(768, blockDim.x) )}, iS246{blockDim.x}
  Outer split: iS253{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iS255{gridDim.y}, iS256{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS245{( ceilDiv(768, blockDim.x) )} by factor 1 -> iS247{( ceilDiv(768, blockDim.x) )}, iS248{1}
 loop domain : (ideviceIdx.x116{2}, iS247{( ceilDiv(768, blockDim.x) )}, iS246{blockDim.x}, iS256{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS248{1}, iS244{8}, iS255{gridDim.y}, iS250{blockDim.y}, iS254{1}, iS252{4}, bS8{1})
T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x233{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1})
 root domain : (bS22{1}, iS23{2048}, iS24{96}, iS25{128}rf)
  Resize: iS25{128}rf by ( ( 0 + 128 ) + 128 ) and 0 -> iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf
 logical domain : (bS22{1}, iS23{2048}, iS24{96}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf)
 allocation domain : (ideviceIdx.x60{2}, bS22{1}, iS23{2048}, iS61{48}, iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf)
 contiguity: t n t t t
  Outer split: iS24{96} by factor 2 -> ideviceIdx.x60{2}, iS61{48}
  Split: iS23{2048} by factor blockDim.y -> iS235{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y236{blockDim.y}
  Split: iS235{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS237{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS238{4}
  Resize: iS25{128}rf by ( ( 0 + 128 ) + 128 ) and 0 -> iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf
  Merge: iS24{96} and iS26{( ( ( 0 + 128 ) + 128 ) + 128 )}rf -> iS112{( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 )}
  Outer split: iS112{( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 )} by factor 2 -> ideviceIdx.x113{2}, iS114{( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) )}
  Split: iS237{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS239{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS240{1}
  Outer split: iS239{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y241{gridDim.y}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS114{( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) )} by factor 8 -> iS229{( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) )}, iS230{8}
  Split: iS229{( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) )} by factor blockDim.x -> iS231{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x232{blockDim.x}
  Split: iS231{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )} by factor 1 -> iblockIdx.x233{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, iUS234{1}
 loop domain : (ideviceIdx.x113{2}, iblockIdx.x233{( ceilDiv(( ceilDiv(( ceilDiv(( ( ( ( 0 + 128 ) + 128 ) + 128 ) * 96 ), 2) ), 8) ), blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1})
T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
 logical domain : (bS27{1}, iS28{2048}, iS29{96}, iS30{384})
 allocation domain : (ideviceIdx.x62{2}, bS27{1}, iS28{2048}, iS63{48}, iS30{384})
 contiguity: t n t t t
  Outer split: iS29{96} by factor 2 -> ideviceIdx.x62{2}, iS63{48}
  Merge: iS29{96} and iS30{384} -> iS109{36864}
  Split: iS28{2048} by factor blockDim.y -> iS221{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y222{blockDim.y}
  Outer split: iS109{36864} by factor 2 -> ideviceIdx.x110{2}, iS111{18432}
  Split: iS221{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS223{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS224{4}
  Split: iS111{18432} by factor 8 -> iS215{2304}, iS216{8}
  Split: iS223{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS225{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS226{1}
  Split: iS215{2304} by factor blockDim.x -> iS217{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}
  Outer split: iS225{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y227{gridDim.y}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
  Split: iS217{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, iUS220{1}
 loop domain : (ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1})
T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
 root domain : (bS31{1}, iS32{2048}, iS35{96}rf, iS36{384}rf)
  Merge: iS35{96}rf and iS36{384}rf -> iS37{36864}rf
 logical domain : (bS31{1}, iS32{2048}, iS37{36864}rf)
 allocation domain : (ideviceIdx.x64{2}, bS31{1}, iS32{2048}, iS65{18432})
 contiguity: t n t t
  Split: iS32{2048} by factor blockDim.y -> iS207{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y208{blockDim.y}
  Split: iS207{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS209{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS210{4}
  Merge: iS35{96}rf and iS36{384}rf -> iS37{36864}rf
  Outer split: iS37{36864}rf by factor 2 -> ideviceIdx.x64{2}, iS65{18432}
  Split: iS65{18432} by factor 8 -> iS201{2304}, iS202{8}
  Split: iS201{2304} by factor blockDim.x -> iS203{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}
  Split: iS209{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS211{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS212{1}
  Split: iS203{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, iUS206{1}
  Outer split: iS211{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y213{gridDim.y}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
 loop domain : (ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1})
T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
 logical domain : (bS38{1}, iS39{2048}, iS40{36864})
 allocation domain : (ideviceIdx.x66{2}, bS38{1}, iS39{2048}, iS67{18432})
 contiguity: t n t t
  Outer split: iS40{36864} by factor 2 -> ideviceIdx.x66{2}, iS67{18432}
  Split: iS67{18432} by factor 8 -> iS187{2304}, iS188{8}
  Split: iS39{2048} by factor blockDim.y -> iS193{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y194{blockDim.y}
  Split: iS187{2304} by factor blockDim.x -> iS189{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}
  Split: iS193{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS195{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS196{4}
  Split: iS189{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, iUS192{1}
  Split: iS195{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS197{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS198{1}
  Outer split: iS197{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y199{gridDim.y}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
 loop domain : (ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1})
T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
 logical domain : (iS41{2048}, iS42{36864})
 allocation domain : (ideviceIdx.x68{2}, iS41{2048}, iS69{18432})
 contiguity: t t t
  Outer split: iS42{36864} by factor 2 -> ideviceIdx.x68{2}, iS69{18432}
  Split: iS69{18432} by factor 8 -> iS173{2304}, iS174{8}
  Split: iS41{2048} by factor blockDim.y -> iS179{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y180{blockDim.y}
  Split: iS173{2304} by factor blockDim.x -> iS175{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}
  Split: iS179{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS181{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS182{4}
  Split: iS175{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, iUS178{1}
  Split: iS181{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS183{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS184{1}
  Outer split: iS183{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y185{gridDim.y}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
 loop domain : (ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4})
T17_l_float[ideviceIdx.x146{2}, iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, iUS153{1}, iS149{8}, iblockIdx.y160{gridDim.y}rf, ithreadIdx.y155{blockDim.y}rf, rUS159{1}rf, rS157{4}rf] ca_pos( 3 ) produce_pos( 10 ) (DeviceMesh{0 1})
 root domain : (rS144{2048}rf, iS145{36864})
  Split: rS144{2048}rf by factor blockDim.y -> rS154{( ceilDiv(2048, blockDim.y) )}rf, ithreadIdx.y155{blockDim.y}rf
  Split: rS154{( ceilDiv(2048, blockDim.y) )}rf by factor 4 -> rS156{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf, rS157{4}rf
  Split: rS156{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf by factor 1 -> rS158{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf, rUS159{1}rf
  Outer split: rS158{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf by factor gridDim.y -> iblockIdx.y160{gridDim.y}rf, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf
 logical domain : (iblockIdx.y160{gridDim.y}rf, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, rUS159{1}rf, rS157{4}rf, ithreadIdx.y155{blockDim.y}rf, iS145{36864})
 contiguity: t n n n t t
  Outer split: iS145{36864} by factor 2 -> ideviceIdx.x146{2}, iS147{18432}
  Split: rS144{2048}rf by factor blockDim.y -> rS154{( ceilDiv(2048, blockDim.y) )}rf, ithreadIdx.y155{blockDim.y}rf
  Split: iS147{18432} by factor 8 -> iS148{2304}, iS149{8}
  Split: rS154{( ceilDiv(2048, blockDim.y) )}rf by factor 4 -> rS156{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf, rS157{4}rf
  Split: iS148{2304} by factor blockDim.x -> iS150{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}
  Split: rS156{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf by factor 1 -> rS158{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf, rUS159{1}rf
  Split: iS150{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, iUS153{1}
  Outer split: rS158{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}rf by factor gridDim.y -> iblockIdx.y160{gridDim.y}rf, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf
 loop domain : (ideviceIdx.x146{2}, iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, iUS153{1}, iS149{8}, iblockIdx.y160{gridDim.y}rf, ithreadIdx.y155{blockDim.y}rf, rUS159{1}rf, rS157{4}rf)
T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1})
 logical domain : (rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}, iS164{36864})
 contiguity: n n t
  Outer split: iS164{36864} by factor 2 -> ideviceIdx.x165{2}, iS166{18432}
  Split: iS166{18432} by factor 8 -> iS167{2304}, iG168{8}
  Split: iS167{2304} by factor blockDim.x -> iS169{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}
  Split: iS169{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, iUS172{1}
 loop domain : (ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y})
T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1})
 logical domain : (iS45{36864})
 allocation domain : (ideviceIdx.x72{2}, iS73{18432})
 contiguity: t t
  Outer split: iS45{36864} by factor 2 -> ideviceIdx.x72{2}, iS73{18432}
  Split: iS73{18432} by factor 8 -> iS341{2304}, iS342{8}
  Split: iS341{2304} by factor blockDim.x -> iS343{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}
  Split: iS343{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, iUS346{1}
 loop domain : (ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8})
T11_g___bfloat[ideviceIdx.x102{2}, iblockIdx.x351{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x350{blockDim.x}, iUS352{1}, iS348{8}] ca_pos( 5 ) produce_pos( 5 ) (DeviceMesh{0 1})
 logical domain : (iS101{36864})
 allocation domain : (ideviceIdx.x102{2}, iS103{18432})
 contiguity: t t
  Outer split: iS101{36864} by factor 2 -> ideviceIdx.x102{2}, iS103{18432}
  Split: iS103{18432} by factor 8 -> iS347{2304}, iS348{8}
  Split: iS347{2304} by factor blockDim.x -> iS349{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x350{blockDim.x}
  Split: iS349{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x351{( ceilDiv(2304, blockDim.x) )}, iUS352{1}
 loop domain : (ideviceIdx.x102{2}, iblockIdx.x351{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x350{blockDim.x}, iUS352{1}, iS348{8})
T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
 logical domain : (bS78{1}, iS79{2048}, iS80{36864})
 allocation domain : (ideviceIdx.x81{2}, bS78{1}, iS79{2048}, iS82{18432})
 contiguity: t n t t
  Outer split: iS80{36864} by factor 2 -> ideviceIdx.x81{2}, iS82{18432}
  Split: iS82{18432} by factor 8 -> iS313{2304}, iS314{8}
  Split: iS79{2048} by factor blockDim.y -> iS319{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y320{blockDim.y}
  Split: iS313{2304} by factor blockDim.x -> iS315{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}
  Split: iS319{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS321{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS322{4}
  Split: iS315{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, iUS318{1}
  Split: iS321{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS323{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS324{1}
  Outer split: iS323{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y325{gridDim.y}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
 loop domain : (ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1})
T14_g___bfloat[ideviceIdx.x107{2}, iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x330{blockDim.x}, iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS332{1}, iS328{8}, iblockIdx.y339{gridDim.y}, ithreadIdx.y334{blockDim.y}, iUS338{1}, iS336{4}, bS104{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})
 logical domain : (bS104{1}, iS105{2048}, iS106{36864})
 allocation domain : (ideviceIdx.x107{2}, bS104{1}, iS105{2048}, iS108{18432})
 contiguity: t n t t
  Outer split: iS106{36864} by factor 2 -> ideviceIdx.x107{2}, iS108{18432}
  Split: iS108{18432} by factor 8 -> iS327{2304}, iS328{8}
  Split: iS105{2048} by factor blockDim.y -> iS333{( ceilDiv(2048, blockDim.y) )}, ithreadIdx.y334{blockDim.y}
  Split: iS327{2304} by factor blockDim.x -> iS329{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x330{blockDim.x}
  Split: iS333{( ceilDiv(2048, blockDim.y) )} by factor 4 -> iS335{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iS336{4}
  Split: iS329{( ceilDiv(2304, blockDim.x) )} by factor 1 -> iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}, iUS332{1}
  Split: iS335{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor 1 -> iS337{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )}, iUS338{1}
  Outer split: iS337{( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) )} by factor gridDim.y -> iblockIdx.y339{gridDim.y}, iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}
 loop domain : (ideviceIdx.x107{2}, iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x330{blockDim.x}, iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS332{1}, iS328{8}, iblockIdx.y339{gridDim.y}, ithreadIdx.y334{blockDim.y}, iUS338{1}, iS336{4}, bS104{1})
} // %kernel

%Kernel { (T0_g___bfloat[ideviceIdx.x128{2}, iS303{( ceilDiv(768, blockDim.x) )}, iS302{blockDim.x}, iS312{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS304{1}, iS300{8}, iS311{gridDim.y}, iS306{blockDim.y}, iS310{1}, iS308{4}, bS0{1}] (DeviceMesh{0 1}), T1_g___bfloat[ideviceIdx.x122{2}, iS275{( ceilDiv(768, blockDim.x) )}, iS274{blockDim.x}, iS284{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS276{1}, iS272{8}, iS283{gridDim.y}, iS278{blockDim.y}, iS282{1}, iS280{4}, bS4{1}] (DeviceMesh{0 1}), T2_g___bfloat[ideviceIdx.x116{2}, iS247{( ceilDiv(768, blockDim.x) )}, iS246{blockDim.x}, iS256{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iS248{1}, iS244{8}, iS255{gridDim.y}, iS250{blockDim.y}, iS254{1}, iS252{4}, bS8{1}] (DeviceMesh{0 1})) -> (T11_g___bfloat[ideviceIdx.x102{2}, iblockIdx.x351{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x350{blockDim.x}, iUS352{1}, iS348{8}] ca_pos( 5 ) produce_pos( 5 ) (DeviceMesh{0 1}), T14_g___bfloat[ideviceIdx.x107{2}, iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x330{blockDim.x}, iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS332{1}, iS328{8}, iblockIdx.y339{gridDim.y}, ithreadIdx.y334{blockDim.y}, iUS338{1}, iS336{4}, bS104{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1})) :
NVFUSER_DEFINE_MAGIC_ZERO;
i12292 = ALLOCATE(buffer=i12292, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i12292 = ceilDiv(i12288, gridDim.y);
i14396 = ALLOCATE(buffer=i14396, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14396 = threadIdx.x + i14394;
i14386 = ALLOCATE(buffer=i14386, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14386 = blockDim.y * 512;
i14427 = ALLOCATE(buffer=i14427, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14427 = 8 * i14426;
i14384 = ALLOCATE(buffer=i14384, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14384 = 128 * threadIdx.y;
i14390 = ALLOCATE(buffer=i14390, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14390 = i14388 * blockIdx.y;
i14399 = ALLOCATE(buffer=i14399, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14399 = 262144 * i14398;
i14428 = ALLOCATE(buffer=i14428, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14428 = i14401 + i14427;
i14420 = ALLOCATE(buffer=i14420, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14420 = 128 * blockDim.y;
i14795 = ALLOCATE(buffer=i14795, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i14795 = -128 + i14427;
i15680 = ALLOCATE(buffer=i15680, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i15680 = i15679 + i14427;
i16037 = ALLOCATE(buffer=i16037, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i16037 = -256 + i14427;
i16922 = ALLOCATE(buffer=i16922, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i16922 = i16921 + i14427;
i17934 = ALLOCATE(buffer=i17934, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i17934 = blockDim.y * 73728;
i17942 = ALLOCATE(buffer=i17942, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i17942 = 8 * threadIdx.x;
i17948 = ALLOCATE(buffer=i17948, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i17948 = i17946 * blockIdx.x;
i17950 = ALLOCATE(buffer=i17950, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i17950 = i17944 + i17948;
i17960 = ALLOCATE(buffer=i17960, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i17960 = 18432 * blockDim.y;
i22824 = ALLOCATE(buffer=i22824, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i22824 = i17942 + i17948;
i24192 = ALLOCATE(buffer=i24192, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i24192 = i24191 + i17948;
b24195 = ALLOCATE(buffer=b24195, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
b24195 = b24193 && b24194;
i24170 = ALLOCATE(buffer=i24170, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i24170 = blockDim.y * 4;
i24180 = ALLOCATE(buffer=i24180, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i24180 = i24178 + threadIdx.y;
i24881 = ALLOCATE(buffer=i24881, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i24881 = i24880 + i17948;
i24884 = ALLOCATE(buffer=i24884, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i24884 = i24883 + i17948;
i24889 = ALLOCATE(buffer=i24889, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i24889 = i24858 + i24888;
b29549 = ALLOCATE(buffer=b29549, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
b29549 = b29548 && b13310;
i43 = ALLOCATE(buffer=i43, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i43 = 0 + 128;
i66 = ALLOCATE(buffer=i66, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
i66 = i43 + 128;
T18_g_float[iS358{( ( ( gridDim.x * gridDim.y ) * blockDim.x ) * 8 )}] = ALLOCATE(buffer=T18_g_float[iS358{( ( ( gridDim.x * gridDim.y ) * blockDim.x ) * 8 )}], mem_type=global, size=( ( ( gridDim.x * gridDim.y ) * blockDim.x ) * 8 ), zero_init=false, resets_to_zero=false)
T19_g_int64_t[iS359{( gridDim.x * 8 )}] = ALLOCATE(buffer=T19_g_int64_t[iS359{( gridDim.x * 8 )}], mem_type=global, size=( gridDim.x * 8 ), zero_init=true, resets_to_zero=false)
FOR 0 in ideviceIdx.x107{2}:
  FOR blockIdx.x in iblockIdx.x331{( ceilDiv(2304, blockDim.x) )}:
    FOR threadIdx.x in ithreadIdx.x330{blockDim.x}:
      T17_l_float[ideviceIdx.x146{2}, iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, iUS153{1}, iS149{8}, iblockIdx.y160{gridDim.y}rf, ithreadIdx.y155{blockDim.y}rf, rUS159{1}rf, rS157{4}rf] ca_pos( 3 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T17_l_float[ideviceIdx.x146{2}, iblockIdx.x152{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x151{blockDim.x}, rS161{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}rf, iUS153{1}, iS149{8}, iblockIdx.y160{gridDim.y}rf, ithreadIdx.y155{blockDim.y}rf, rUS159{1}rf, rS157{4}rf] ca_pos( 3 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=8, zero_init=false, resets_to_zero=false)
      IF Unswitch true:
        FOR 0 in iUS332{1}:
          FOR i12577 in iS328{8}:
            FOR blockIdx.y in iblockIdx.y339{gridDim.y}:
              FOR threadIdx.y in ithreadIdx.y334{blockDim.y}:
                IF Manual true:
                  T17_l[i12577] view( T17 )
                     = Set.Permute( float(0), cache_op=Streaming )
          NVFUSER_UPDATE_MAGIC_ZERO;
      FOR i12576 in iS340{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}:
        i14429 = ALLOCATE(buffer=i14429, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i14429 = i14386 * i12576;
        i14430 = ALLOCATE(buffer=i14430, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i14430 = i14428 + i14429;
        i15681 = ALLOCATE(buffer=i15681, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i15681 = i15680 + i14429;
        i16923 = ALLOCATE(buffer=i16923, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i16923 = i16922 + i14429;
        i17967 = ALLOCATE(buffer=i17967, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i17967 = i17950 + i17966;
        i24196 = ALLOCATE(buffer=i24196, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i24196 = i24170 * i12576;
        i24890 = ALLOCATE(buffer=i24890, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
        i24890 = i24889 + i24196;
        IF Unswitch ( ( ( ( ( 7 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < 36864 ) && ( ( ( 7 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < 18432 ) ) && ( ( ( ( ( ( ( blockDim.y * 4 ) * blockIdx.y ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) + ( blockDim.y * 3 ) ) + threadIdx.y ) + ( ( blockDim.y * 4 ) * i12576 ) ) < 2048 ) ):
          FOR 0 in iUS332{1}:
            FOR i12577 in iS328{8}:
              i14431 = ALLOCATE(buffer=i14431, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i14431 = i14430 + i12577;
              i14730 = ALLOCATE(buffer=i14730, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i14730 = -i12577;
              b14796 = ALLOCATE(buffer=b14796, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b14796 = i14795 < i14730;
              i15682 = ALLOCATE(buffer=i15682, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i15682 = i15681 + i12577;
              b16038 = ALLOCATE(buffer=b16038, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b16038 = i16037 >= i14730;
              i16924 = ALLOCATE(buffer=i16924, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i16924 = i16923 + i12577;
              b17496 = ALLOCATE(buffer=b17496, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b17496 = b17494 && b17495;
              i17968 = ALLOCATE(buffer=i17968, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i17968 = i17967 + i12577;
              FOR blockIdx.y in iblockIdx.y339{gridDim.y}:
                FOR threadIdx.y in ithreadIdx.y334{blockDim.y}:
                  FOR 0 in iUS338{1}:
                    FOR i12578 in iS336{4}:
                      i13575 = ALLOCATE(buffer=i13575, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      i13575 = i12578 + nvfuser_zero;
                      i14422 = ALLOCATE(buffer=i14422, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      i14422 = i14420 * i13575;
                      T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS12{1}:
                        IF Manual true:
                          T3_l[0] view( T3 )
                             = where(b14796
                            , T0_g[( ( ( ( ( ( ( 128 * threadIdx.y ) + ( ( ( blockDim.y * 512 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 262144 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) / 48 ) ) ) + ( 8 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) % 48 ) ) ) + ( ( blockDim.y * 512 ) * i12576 ) ) + i12577 ) + ( ( 128 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T0 )
                            , __bfloat(0));
                      T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x356{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x356{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS22{1}:
                        IF Manual true:
                          T5_l[0] view( T5 )
                             = where(b16038
                            , T2_g[( ( ( ( ( ( ( -256 + ( 128 * threadIdx.y ) ) + ( ( ( blockDim.y * 512 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 262144 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) / 48 ) ) ) + ( 8 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) % 48 ) ) ) + ( ( blockDim.y * 512 ) * i12576 ) ) + i12577 ) + ( ( 128 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T2 )
                            , __bfloat(0));
                      T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x354{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x354{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS17{1}:
                        IF Manual true:
                          T4_l[0] view( T4 )
                             = where(b17496
                            , T1_g[( ( ( ( ( ( ( -128 + ( 128 * threadIdx.y ) ) + ( ( ( blockDim.y * 512 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 262144 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) / 48 ) ) ) + ( 8 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) % 48 ) ) ) + ( ( blockDim.y * 512 ) * i12576 ) ) + i12577 ) + ( ( 128 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T1 )
                            , __bfloat(0));
                      T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS27{1}:
                        IF Manual true:
                          T6_l[0] view( T6 )
                             = f17565
                             | T5_l[0] view( T5 );
                      T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS31{1}:
                        IF Manual true:
                          T7_l[0] view( T7 )
                             = Set.Permute( T6_l[0] view( T6 ), cache_op=Streaming )
                      T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS38{1}:
                        IF Manual true:
                          T8_l[0] view( T8 )
                             = __bfloat2float(T7_l[0] view( T7 ));
                      T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS78{1}:
                        IF Manual true:
                          T16_l[0] view( T16 )
                             = Set( T7_l[0] view( T7 ), cache_op=Streaming )
                      FOR 0 in bS104{1}:
                        IF Manual true:
                          T14_g[( ( ( ( ( ( ( 18432 * threadIdx.y ) + ( ( ( blockDim.y * 73728 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) + ( ( blockDim.y * 73728 ) * i12576 ) ) + i12577 ) + ( ( 18432 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T14 )
                             = Set( T16_l[0] view( T16 ), cache_op=Streaming )
                      T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      IF Manual true:
                        T9_l[0] view( T9 )
                           = Set( T8_l[0] view( T8 ), cache_op=Streaming )
                      IF Manual true:
                        T17_l[i12577] view( T17 )
                           = T17_l[i12577] view( T17 )
                           + T9_l[0] view( T9 );
            NVFUSER_UPDATE_MAGIC_ZERO;
        ELSE:
          FOR 0 in iUS332{1}:
            FOR i12577 in iS328{8}:
              i18976 = ALLOCATE(buffer=i18976, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i18976 = i14430 + i12577;
              i19276 = ALLOCATE(buffer=i19276, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i19276 = -i12577;
              b19341 = ALLOCATE(buffer=b19341, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b19341 = i14795 < i19276;
              i20222 = ALLOCATE(buffer=i20222, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i20222 = i15681 + i12577;
              b20577 = ALLOCATE(buffer=b20577, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b20577 = i16037 >= i19276;
              i21458 = ALLOCATE(buffer=i21458, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i21458 = i16923 + i12577;
              b22030 = ALLOCATE(buffer=b22030, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b22030 = b22028 && b22029;
              i22500 = ALLOCATE(buffer=i22500, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i22500 = i17967 + i12577;
              i24783 = ALLOCATE(buffer=i24783, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              i24783 = -i24490;
              b24886 = ALLOCATE(buffer=b24886, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
              b24886 = b24882 && b24885;
              FOR blockIdx.y in iblockIdx.y339{gridDim.y}:
                FOR threadIdx.y in ithreadIdx.y334{blockDim.y}:
                  FOR 0 in iUS338{1}:
                    FOR i12578 in iS336{4}:
                      i18137 = ALLOCATE(buffer=i18137, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      i18137 = i12578 + nvfuser_zero;
                      i18977 = ALLOCATE(buffer=i18977, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      i18977 = i14420 * i18137;
                      b24894 = ALLOCATE(buffer=b24894, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      b24894 = b24886 && b24893;
                      T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T3_l___bfloat[ideviceIdx.x125{2}, iblockIdx.x289{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x288{blockDim.x}, iS298{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS290{1}, iS286{8}, iblockIdx.y297{gridDim.y}, ithreadIdx.y292{blockDim.y}, iUS296{1}, iS294{4}, bS12{1}] ca_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS12{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T3_l[0] view( T3 )
                             = where(b19341
                            , T0_g[( ( ( ( ( ( ( 128 * threadIdx.y ) + ( ( ( blockDim.y * 512 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 262144 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) / 48 ) ) ) + ( 8 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) % 48 ) ) ) + ( ( blockDim.y * 512 ) * i12576 ) ) + i12577 ) + ( ( 128 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T0 )
                            , __bfloat(0));
                      T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x356{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T5_l___bfloat[ideviceIdx.x113{2}, iblockIdx.x356{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x232{blockDim.x}, iS242{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS234{1}, iS230{8}, iblockIdx.y241{gridDim.y}, ithreadIdx.y236{blockDim.y}, iUS240{1}, iS238{4}, bS22{1}] ca_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS22{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T5_l[0] view( T5 )
                             = where(b20577
                            , T2_g[( ( ( ( ( ( ( -256 + ( 128 * threadIdx.y ) ) + ( ( ( blockDim.y * 512 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 262144 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) / 48 ) ) ) + ( 8 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) % 48 ) ) ) + ( ( blockDim.y * 512 ) * i12576 ) ) + i12577 ) + ( ( 128 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T2 )
                            , __bfloat(0));
                      T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x354{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T4_l___bfloat[ideviceIdx.x119{2}, iblockIdx.x354{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x260{blockDim.x}, iS270{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS262{1}, iS258{8}, iblockIdx.y269{gridDim.y}, ithreadIdx.y264{blockDim.y}, iUS268{1}, iS266{4}, bS17{1}] ca_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS17{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T4_l[0] view( T4 )
                             = where(b22030
                            , T1_g[( ( ( ( ( ( ( -128 + ( 128 * threadIdx.y ) ) + ( ( ( blockDim.y * 512 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 262144 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) / 48 ) ) ) + ( 8 * ( ( threadIdx.x + ( blockDim.x * blockIdx.x ) ) % 48 ) ) ) + ( ( blockDim.y * 512 ) * i12576 ) ) + i12577 ) + ( ( 128 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T1 )
                            , __bfloat(0));
                      T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T6_l___bfloat[ideviceIdx.x110{2}, iblockIdx.x219{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x218{blockDim.x}, iS228{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS220{1}, iS216{8}, iblockIdx.y227{gridDim.y}, ithreadIdx.y222{blockDim.y}, iUS226{1}, iS224{4}, bS27{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS27{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T6_l[0] view( T6 )
                             = f22099
                             | T5_l[0] view( T5 );
                      T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T7_l___bfloat[ideviceIdx.x64{2}, iblockIdx.x205{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x204{blockDim.x}, iS214{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS206{1}, iS202{8}, iblockIdx.y213{gridDim.y}, ithreadIdx.y208{blockDim.y}, iUS212{1}, iS210{4}, bS31{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS31{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T7_l[0] view( T7 )
                             = Set.Permute( T6_l[0] view( T6 ), cache_op=Streaming )
                      T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T8_l_float[ideviceIdx.x66{2}, iblockIdx.x191{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x190{blockDim.x}, iS200{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS192{1}, iS188{8}, iblockIdx.y199{gridDim.y}, ithreadIdx.y194{blockDim.y}, iUS198{1}, iS196{4}, bS38{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS38{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T8_l[0] view( T8 )
                             = __bfloat2float(T7_l[0] view( T7 ));
                      T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T16_l___bfloat[ideviceIdx.x81{2}, iblockIdx.x317{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x316{blockDim.x}, iS326{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS318{1}, iS314{8}, iblockIdx.y325{gridDim.y}, ithreadIdx.y320{blockDim.y}, iUS324{1}, iS322{4}, bS78{1}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      FOR 0 in bS78{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T16_l[0] view( T16 )
                             = Set( T7_l[0] view( T7 ), cache_op=Streaming )
                      FOR 0 in bS104{1}:
                        IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                          T14_g[( ( ( ( ( ( ( 18432 * threadIdx.y ) + ( ( ( blockDim.y * 73728 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) + ( ( blockDim.y * 73728 ) * i12576 ) ) + i12577 ) + ( ( 18432 * blockDim.y ) * ( i12578 + nvfuser_zero ) ) )] view( T14 )
                             = Set( T16_l[0] view( T16 ), cache_op=Streaming )
                      T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T9_l_float[ideviceIdx.x68{2}, iblockIdx.x177{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x176{blockDim.x}, iS186{( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) )}, iUS178{1}, iS174{8}, iblockIdx.y185{gridDim.y}, ithreadIdx.y180{blockDim.y}, iUS184{1}, iS182{4}] ca_pos( 10 ) produce_pos( 10 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
                      IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                        T9_l[0] view( T9 )
                           = Set( T8_l[0] view( T8 ), cache_op=Streaming )
                      IF Inline ( ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12577 + nvfuser_zero ) ) ) ) && ( ( ( ( -2048 + threadIdx.y ) + ( ( ( blockDim.y * 4 ) * ( ceilDiv(( ceilDiv(( ceilDiv(2048, blockDim.y) ), 4) ), gridDim.y) ) ) * blockIdx.y ) ) + ( ( blockDim.y * 4 ) * i12576 ) ) < ( -( blockDim.y * ( i12578 + nvfuser_zero ) ) ) ) ):
                        T17_l[i12577] view( T17 )
                           = T17_l[i12577] view( T17 )
                           + T9_l[0] view( T9 );
            NVFUSER_UPDATE_MAGIC_ZERO;
      IF Unswitch ( ( ( ( 7 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < 36864 ) && ( ( ( 7 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < 18432 ) ):
        FOR 0 in iUS352{1}:
          T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1}), mem_type=register, size=8, zero_init=false, resets_to_zero=false)
          FOR i12420 in iG168{8}:
            IF Manual true:
              T10_l[i12420] view( T10 )
                 = Set( float(0), cache_op=Streaming )
          NVFUSER_UPDATE_MAGIC_ZERO;
          FOR i12420 in iG168{8}:
            FOR blockIdx.y in rblockIdx.y162{gridDim.y}:
              FOR threadIdx.y in rthreadIdx.y163{blockDim.y}:
                GroupedGridReduction(
                  T10_l[i12420] view( T10 ) = reduction( T17_l[i12420] view( T17 ), op = add, initial value = float(0), reduction buffer = T18_g_float[iS358{( ( ( gridDim.x * gridDim.y ) * blockDim.x ) * 8 )}] )
                  sync buffer = T19_g_int64_t[iS359{( gridDim.x * 8 )}],
                  read predicate = Manual true,
                  write predicate = Manual true,
                  thread predicate = (),
                  allreduce = false )
          NVFUSER_UPDATE_MAGIC_ZERO;
          FOR i12553 in iS348{8}:
            T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
            IF Manual ( ( blockIdx.y == ( gridDim.y + -1 ) ) && ( threadIdx.y == 0 ) ):
              T15_l[0] view( T15 )
                 = __float2bfloat(T10_l[i12553] view( T10 ));
            IF Manual ( ( blockIdx.y == ( gridDim.y + -1 ) ) && ( threadIdx.y == 0 ) ):
              T11_g[( ( ( 8 * threadIdx.x ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) + ( i12553 + nvfuser_zero ) )] view( T11 )
                 = Set( T15_l[0] view( T15 ), cache_op=Streaming )
          NVFUSER_UPDATE_MAGIC_ZERO;
      ELSE:
        FOR 0 in iUS352{1}:
          T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T10_l_float[ideviceIdx.x165{2}, iblockIdx.x171{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x170{blockDim.x}, iUS172{1}, iG168{8}, rblockIdx.y162{gridDim.y}, rthreadIdx.y163{blockDim.y}] ca_pos( 4 ) produce_pos( 3 ) (DeviceMesh{0 1}), mem_type=register, size=8, zero_init=false, resets_to_zero=false)
          FOR i12420 in iG168{8}:
            IF Inline true:
              T10_l[i12420] view( T10 )
                 = Set( float(0), cache_op=Streaming )
          NVFUSER_UPDATE_MAGIC_ZERO;
          FOR i12420 in iG168{8}:
            FOR blockIdx.y in rblockIdx.y162{gridDim.y}:
              FOR threadIdx.y in rthreadIdx.y163{blockDim.y}:
                GroupedGridReduction(
                  T10_l[i12420] view( T10 ) = reduction( T17_l[i12420] view( T17 ), op = add, initial value = float(0), reduction buffer = T18_g_float[iS358{( ( ( gridDim.x * gridDim.y ) * blockDim.x ) * 8 )}] )
                  sync buffer = T19_g_int64_t[iS359{( gridDim.x * 8 )}],
                  read predicate = Inline ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12420 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12420 + nvfuser_zero ) ) ) ),
                  write predicate = ReductionWrite ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12420 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12420 + nvfuser_zero ) ) ) ),
                  thread predicate = (),
                  allreduce = false )
          NVFUSER_UPDATE_MAGIC_ZERO;
          FOR i12553 in iS348{8}:
            i22986 = ALLOCATE(buffer=i22986, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
            i22986 = i12553 + nvfuser_zero;
            i30354 = ALLOCATE(buffer=i30354, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
            i30354 = -i22986;
            b30355 = ALLOCATE(buffer=b30355, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
            b30355 = i24881 < i30354;
            b30356 = ALLOCATE(buffer=b30356, mem_type=register, size=1, zero_init=false, resets_to_zero=false)
            b30356 = i24884 < i30354;
            T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1}) = ALLOCATE(buffer=T15_l___bfloat[ideviceIdx.x72{2}, iblockIdx.x345{( ceilDiv(2304, blockDim.x) )}, ithreadIdx.x344{blockDim.x}, iUS346{1}, iS342{8}] ca_pos( 5 ) produce_pos( 4 ) (DeviceMesh{0 1}), mem_type=register, size=1, zero_init=false, resets_to_zero=false)
            IF Inline ( ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12553 + nvfuser_zero ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12553 + nvfuser_zero ) ) ) ):
              T15_l[0] view( T15 )
                 = __float2bfloat(T10_l[i12553] view( T10 ));
            IF Inline ( ( ( ( blockIdx.y == ( gridDim.y + -1 ) ) && ( threadIdx.y == 0 ) ) && ( ( ( -36864 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12553 + nvfuser_zero ) ) ) ) && ( ( ( -18432 + ( 8 * threadIdx.x ) ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) < ( -( i12553 + nvfuser_zero ) ) ) ):
              T11_g[( ( ( 8 * threadIdx.x ) + ( ( 8 * blockDim.x ) * blockIdx.x ) ) + ( i12553 + nvfuser_zero ) )] view( T11 )
                 = Set( T15_l[0] view( T15 ), cache_op=Streaming )
          NVFUSER_UPDATE_MAGIC_ZERO;

} // %Kernel.

PRINTING: __tmp_nvfuser_reduction_f0_c1_r0_g0.cu
F

=========================================== FAILURES ===========================================
______________________________________ test_cat_reduction ______________________________________

multidevice_test = <conftest.MultideviceTest object at 0x72dbb506b3b0>

    @pytest.mark.mpi
    def test_cat_reduction(multidevice_test):
      d = multidevice_test.size
      mesh = nvfuser.DeviceMesh(range(d))
      class CatReduction(FusionDefinition):
        def definition(self):
          self.inp0 = self.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
          self.inp1 = self.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
          self.inp2 = self.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
          S3 = self.define_scalar(0.00000, dtype=DataType.BFloat16)
          S4 = self.define_scalar(0, dtype=DataType.Int)
          S5 = self.define_scalar(0, dtype=DataType.Int)
          S6 = self.define_scalar(0, dtype=DataType.Int)
          S7 = self.define_scalar(0, dtype=DataType.Int)
          S8 = self.define_scalar(0, dtype=DataType.Int)
          S9 = self.define_scalar(0, dtype=DataType.Int)
          S10 = self.define_scalar(0, dtype=DataType.Int)
          S11 = self.define_scalar(256, dtype=DataType.Int)
          V13 = self.define_vector([S10, S11, S8, S9, S6, S7, S4, S5], dtype=DataType.Int)
          T12 = self.ops.pad(self.inp0, V13, S3)
          S14 = self.define_scalar(0, dtype=DataType.Int)
          S15 = self.ops.size(self.inp1, dim=3)
          S16 = self.ops.add(S14, S15)
          S17 = self.define_scalar(0.00000, dtype=DataType.BFloat16)
          S18 = self.define_scalar(0, dtype=DataType.Int)
          S19 = self.define_scalar(0, dtype=DataType.Int)
          S20 = self.define_scalar(0, dtype=DataType.Int)
          S21 = self.define_scalar(0, dtype=DataType.Int)
          S22 = self.define_scalar(0, dtype=DataType.Int)
          S23 = self.define_scalar(0, dtype=DataType.Int)
          S24 = self.define_scalar(128, dtype=DataType.Int)
          V26 = self.define_vector([S16, S24, S22, S23, S20, S21, S18, S19], dtype=DataType.Int)
          T25 = self.ops.pad(self.inp1, V26, S17)
          S27 = self.ops.add(S16, S15)
          S28 = self.define_scalar(0.00000, dtype=DataType.BFloat16)
          S29 = self.define_scalar(0, dtype=DataType.Int)
          S30 = self.define_scalar(0, dtype=DataType.Int)
          S31 = self.define_scalar(0, dtype=DataType.Int)
          S32 = self.define_scalar(0, dtype=DataType.Int)
          S33 = self.define_scalar(0, dtype=DataType.Int)
          S34 = self.define_scalar(0, dtype=DataType.Int)
          S35 = self.define_scalar(0, dtype=DataType.Int)
          V37 = self.define_vector([S27, S35, S33, S34, S31, S32, S29, S30], dtype=DataType.Int)
          T36 = self.ops.pad(self.inp2, V37, S28)
          T38 = self.ops.cat([T12, T25, T36], dim=3, manual_padding=1)
          S39 = self.ops.size(T36, dim=0)
          S40 = self.ops.size(T36, dim=1)
          S41 = self.define_scalar(36864, dtype=DataType.Int)
          V42 = self.define_vector([S39, S40, S41], dtype=DataType.Int)
          T43 = self.ops.reshape(T38, new_shape=V42)
          T44 = self.ops.cast(T43, dtype=DataType.Float)
          T45 = self.ops.squeeze(T44, dims=[0], squeeze_expanded=True)
          T46 = self.ops.sum(T45, dims=[0], keepdim=False, dtype=DataType.Float)
          T47 = self.ops.cast(T46, dtype=DataType.BFloat16)
          T48 = self.ops.squeeze(T43, dims=[0], squeeze_expanded=True)
          T49 = self.ops.permute(T48, dims=[1, 0])
          self.add_output(T47)
          self.add_output(T49, stride_order=[0, 1])
          self.add_output(T48)
    
        def multidevice_schedule(self):
          for t in [self.inp0, self.inp1, self.inp2]:
            self.sched._set_device_mesh(t, mesh)
            self.sched.split(t, 2, d, False)
            self.sched.parallelize(t, 2, nvfuser.ParallelType.mesh_x)
    
      mesh = nvfuser.DeviceMesh(range(d))
      inp0 = torch.randn(1, 2048, 96, 128, dtype=torch.bfloat16, device="cpu")
      inp1 = torch.randn(1, 2048, 96, 128, dtype=torch.bfloat16, device="cpu")
      inp2 = torch.randn(1, 2048, 96, 128, dtype=torch.bfloat16, device="cpu")
      sharded_inp0 = multidevice_test.shard_tensor(inp0, 2, mesh).transpose(1, 2).contiguous().transpose(1, 2)
      sharded_inp1 = multidevice_test.shard_tensor(inp1, 2, mesh).transpose(1, 2).contiguous().transpose(1, 2)
      sharded_inp2 = multidevice_test.shard_tensor(inp2, 2, mesh).transpose(1, 2).contiguous().transpose(1, 2)
      fd = CatReduction()
>     _, _ = fd.execute([sharded_inp0, sharded_inp1, sharded_inp2])

tests/python/multidevice/test_transformer.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = 
def nvfuser_fusion_id0(fd : FusionDefinition) -> None :
    T0 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguit...s.permute(T48, dims=[1, 0])
    fd.add_output(T47)
    fd.add_output(T49, stride_order=[0, 1])
    fd.add_output(T48)


inputs = [tensor([[[[ 1.5442e-02, -7.5781e-01,  7.2266e-02,  ..., -4.1016e-01,
           -4.0430e-01, -1.3281e+00],
          ...5e+00, -1.2266e+00,  ...,  5.1953e-01,
           -2.9102e-01, -1.5781e+00]]]], device='cuda:1', dtype=torch.bfloat16)]

    def execute(
        self,
        inputs,
        *,
        device=None,
        override_user_schedule=False,
        capture_debug_output=False,
        print_repro=False,
        profile=False,
        save_repro_inputs=False,
        _enable_options: list[str] = [],
        _disable_options: list[str] = [],
    ) -> list[torch.Tensor] | tuple[list[torch.Tensor], list[Sharding]]:
        """
        Executes an nvFuser set of kernels for a given Fusion
    
        The FusionDefinition will be executed on a single CUDA device.
        Typically, which device to run on is determined by the devices where
        the input tensors reside. However, if the Fusion is defined such that
        none of the inputs are tensors, we are not able to infer a device from
        the inputs. For example, the following FusionDefinition will be unable
        to unambiguously infer the device of its output:
    
            with FusionDefinition() as fd:
                tv1 = fd.ops.full([5])
                fd.add_output(tv1)
    
        In that case, we default to selecting the first CUDA
        device, i.e. `torch.device("cuda:0")`. This method enables selecting an
        alternative preferred device.
    
        Args:
            inputs (List[Union[Tensor, Scalar]]): A list of inputs to fusion.
    
        Kwargs:
            device (Optional[Union[int, str, torch.device]]): This is a hint to run
                the Fusion on the given CUDA device. This is not typically
                necessary, as the device is usually inferred from the locations
                of input tensors. However, for some fusion definitions, no
                tensors will be input (for example when all tensors are
                generated with `full` or `uniform` ops). In these cases, we
                must either tell NVFuser where to run the resulting kernel, or
                let it default to 0. Note that passing this option providing
                and input tensors that lie on another device is an error.
            override_user_schedule (bool): For a user defined schedule,
                override with auto-generated schedule (default: False)
            capture_debug_output (bool): Whether to capture any printed
                debugging information as a string. If True, the string can be
                retrieved after execution using :meth:`get_debug_output`. If False,
                then that method will return None when called.
            print_repro (bool): Prints a reproduction script to stdout.
            profile (bool): Captures a CUPTI based profile of a fusion.
            save_repro_inputs (bool): Saves the inputs for last_repro_script() to
                provide a provide a reproduction script.
            _enable_options/_disable_options (list): NVFUSER_ENABLE/DISABLE options to use.
                This is an alternative to environment variables.
                Note: Currently, we do not cache/store these options in the FusionCache which makes it
                    plausible to reuse kernels when executing the same fusion definition with different sets of options.
                    Reset the FusionCache manually to avoid inadvertent kernel reuse when between different sets of options.
    
        Returns:
            A list of output tensors and, if multidevice_schedule is defined, a
            list of output shardings. The latter is important to pack the outputs
            into DTensors for framework integration.
        """
        self.profiled = profile
    
        if not isinstance(device, int) and device is not None:
            if not isinstance(device, torch.device):
                device = torch.device(device)
            assert (
                device.type == "cuda"
            ), "If device argument is passed it must be a CUDA device"
            device = device.index
    
        # if definition is not defined by a context manager, try a child class
        defined_multidevice_schedule = hasattr(self, "multidevice_schedule")
        if self.id() is None:
            self._setup_definition()
            self.definition()
            self._finalize_definition()
    
            defined_schedule = hasattr(self, "schedule") and isinstance(
                self.schedule, Callable
            )
            assert not (
                defined_multidevice_schedule and defined_schedule
            ), "I haven't tested what if both are defined. We don't plan to support this use case although it may just work."
    
            if defined_multidevice_schedule:
                # Unlike `schedule`, `multidevice_schedule` is designed for inter-device
                # scheduling, The scheduling is done before concretization and therefore
                # before pre-segmentation. `schedule` however assumes the FusionDefinition
                # has been concretized and pre-segmented, and therefore requires
                # `_setup_schedule` and `_finalize_schedule` to be called before and after.
                #
                # Note: there's a plan to embed multidevice schedules into FusionDefinition
                # as annotating nodes. This may eventually replace `multidevice_schedule`.
                self._setup_multidevice_schedule()
                self.multidevice_schedule()
                self._finalize_multidevice_schedule()
    
            # If schedule is defined by child class and schedule is not defined for
            # inputs, make a schedule.
            if defined_schedule:
                # Schedule fusion if it does not exist yet or profiling fusion
                if profile or not self._exist_schedule(inputs):
                    self._setup_schedule(inputs, overwrite_existing_schedule=profile)
                    self.schedule()
                    self._finalize_schedule(inputs)
    
        if save_repro_inputs:
            from torch._subclasses.fake_tensor import FakeTensorMode
    
            fake_mode = FakeTensorMode()
            self.fake_inputs = [fake_mode.from_tensor(inp) for inp in inputs]
    
        if hasattr(self, "segments") and len(self.segments) > 0:
            return self._execute_segments(inputs, device=device, profile=profile)
    
        try:
            if print_repro:
                print(self.repro_script_for(inputs))
            if len(_enable_options) or len(_disable_options):
                warnings.warn(
                    "Reset the FusionCache manually to avoid reusing kernels when re-executing the fusion definition with different options."
                )
    
>           out_tensors, out_shardings = self._execute(
                inputs,
                device=device,
                override_user_schedule=override_user_schedule,
                capture_debug_output=capture_debug_output,
                profile=profile,
                _enable_options=_enable_options,
                _disable_options=_disable_options,
            )
E           RuntimeError:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp":465, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. Detected exception while compiling fusion segments in parallel. Error messages from all threads are printed below.
E           
E           Error from segmentation group 0:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp":178, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. 
E           // Codegen generated code
E           __global__ void nvfuser_reduction_f0_c1_r0_g0(Tensor<__bfloat, 4, 5> T0, Tensor<__bfloat, 4, 5> T1, Tensor<__bfloat, 4, 5> T2, Tensor<__bfloat, 1, 2> T11, Tensor<__bfloat, 3, 4> T14, Tensor<float, 1, 1> T18, Tensor<int64_t, 1, 1> T19) {
E             alignas(16) extern __shared__ char array[];
E             void* shared_mem = array;
E             NVFUSER_DEFINE_MAGIC_ZERO;
E             nvfuser_index_t i0;
E             i0 = ceilDiv((ceilDiv((ceilDiv(2048, ((nvfuser_index_t)blockDim.y))), 4)), ((nvfuser_index_t)gridDim.y));
E             nvfuser_index_t i1;
E             i1 = ((nvfuser_index_t)threadIdx.x) + (((nvfuser_index_t)blockDim.x) * ((nvfuser_index_t)blockIdx.x));
E             nvfuser_index_t i2;
E             i2 = ((nvfuser_index_t)blockDim.y) * 512;
E             nvfuser_index_t i3;
E             i3 = 8 * (i1 % 48);
E             nvfuser_index_t i4;
E             i4 = 128 * ((nvfuser_index_t)threadIdx.y);
E             nvfuser_index_t i5;
E             i5 = (i2 * i0) * ((nvfuser_index_t)blockIdx.y);
E             nvfuser_index_t i6;
E             i6 = 262144 * (i1 / 48);
E             nvfuser_index_t i7;
E             i7 = ((i4 + i5) + i6) + i3;
E             nvfuser_index_t i8;
E             i8 = 128 * ((nvfuser_index_t)blockDim.y);
E             nvfuser_index_t i9;
E             i9 = -128 + i3;
E             nvfuser_index_t i10;
E             i10 = (((-256 + i4) + i5) + i6) + i3;
E             nvfuser_index_t i11;
E             i11 = -256 + i3;
E             nvfuser_index_t i12;
E             i12 = (((-128 + i4) + i5) + i6) + i3;
E             nvfuser_index_t i13;
E             i13 = ((nvfuser_index_t)blockDim.y) * 73728;
E             nvfuser_index_t i14;
E             i14 = 8 * ((nvfuser_index_t)threadIdx.x);
E             nvfuser_index_t i15;
E             i15 = (8 * ((nvfuser_index_t)blockDim.x)) * ((nvfuser_index_t)blockIdx.x);
E             nvfuser_index_t i16;
E             i16 = (((18432 * ((nvfuser_index_t)threadIdx.y)) + ((i13 * i0) * ((nvfuser_index_t)blockIdx.y))) + i14) + i15;
E             nvfuser_index_t i17;
E             i17 = 18432 * ((nvfuser_index_t)blockDim.y);
E             nvfuser_index_t i18;
E             i18 = i14 + i15;
E             nvfuser_index_t i19;
E             i19 = (7 + i14) + i15;
E             bool b20;
E             b20 = (i19 < 36864) && (i19 < 18432);
E             nvfuser_index_t i21;
E             i21 = ((nvfuser_index_t)blockDim.y) * 4;
E             nvfuser_index_t i22;
E             i22 = (((i21 * ((nvfuser_index_t)blockIdx.y)) * i0) + (((nvfuser_index_t)blockDim.y) * 3)) + ((nvfuser_index_t)threadIdx.y);
E             nvfuser_index_t i23;
E             i23 = (-36864 + i14) + i15;
E             nvfuser_index_t i24;
E             i24 = (-18432 + i14) + i15;
E             nvfuser_index_t i25;
E             i25 = (-2048 + ((nvfuser_index_t)threadIdx.y)) + ((i21 * i0) * ((nvfuser_index_t)blockIdx.y));
E             bool b26;
E             b26 = (((nvfuser_index_t)blockIdx.y) == (((nvfuser_index_t)gridDim.y) + -1)) && (((nvfuser_index_t)threadIdx.y) == 0);
E             nvfuser_index_t i27;
E             i27 = 0LL + 128;
E             nvfuser_index_t i28;
E             i28 = i27 + 128;
E             // Allocate global tensor T18
E             // Allocate global tensor T19
E             Array<float, 8, 8> T17;
E             #pragma unroll
E             for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
E               T17[i29] = 0.000000000e+00f;
E             }
E             NVFUSER_UPDATE_MAGIC_ZERO;
E             #pragma unroll 1
E             for(nvfuser_index_t i30 = 0; i30 < i0; ++i30) {
E               nvfuser_index_t i31;
E               i31 = i2 * i30;
E               nvfuser_index_t i32;
E               i32 = i7 + i31;
E               nvfuser_index_t i33;
E               i33 = i10 + i31;
E               nvfuser_index_t i34;
E               i34 = i12 + i31;
E               nvfuser_index_t i35;
E               i35 = i16 + (i13 * i30);
E               nvfuser_index_t i36;
E               i36 = i21 * i30;
E               nvfuser_index_t i37;
E               i37 = i25 + i36;
E               if ((b20 && ((i22 + i36) < 2048))) {
E                 #pragma unroll
E                 for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
E                   nvfuser_index_t i38;
E                   i38 = i32 + i29;
E                   nvfuser_index_t i39;
E                   i39 = -i29;
E                   bool b40;
E                   b40 = i9 < i39;
E                   nvfuser_index_t i41;
E                   i41 = i33 + i29;
E                   bool b42;
E                   b42 = i11 >= i39;
E                   nvfuser_index_t i43;
E                   i43 = i34 + i29;
E                   bool b44;
E                   b44 = (i9 >= i39) && (i11 < i39);
E                   nvfuser_index_t i45;
E                   i45 = i35 + i29;
E                   #pragma unroll
E                   for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
E                     nvfuser_index_t i47;
E                     i47 = i46 + nvfuser_zero;
E                     nvfuser_index_t i48;
E                     i48 = i8 * i47;
E                     Array<__bfloat, 1, 1> T3;
E                     T3[0]
E                        = b40 ? T0[(i38 + i48)] : 0.0000e+00f;
E                     Array<__bfloat, 1, 1> T5;
E                     T5[0]
E                        = b42 ? T2[(i41 + i48)] : 0.0000e+00f;
E                     Array<__bfloat, 1, 1> T4;
E                     T4[0]
E                        = b44 ? T1[(i43 + i48)] : 0.0000e+00f;
E                     Array<__bfloat, 1, 1> T6;
E                     T6[0]
E                       = (T3[0] | T4[0])
E                       | T5[0];
E                     Array<__bfloat, 1, 1> T7;
E                     T7[0]
E                        = T6[0];
E                     Array<float, 1, 1> T8;
E                     T8[0]
E                        = __bfloat2float(T7[0]);
E                     Array<__bfloat, 1, 1> T16;
E                     T16[0]
E                        = T7[0];
E                     T14[(i45 + (i17 * i47))]
E                        = T16[0];
E                     Array<float, 1, 1> T9;
E                     T9[0]
E                        = T8[0];
E                     T17[i29]
E                       = T17[i29]
E                       + T9[0];
E                   }
E                 }
E                 NVFUSER_UPDATE_MAGIC_ZERO;
E               } else {
E                 #pragma unroll
E                 for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
E                   nvfuser_index_t i49;
E                   i49 = i32 + i29;
E                   nvfuser_index_t i50;
E                   i50 = -i29;
E                   bool b51;
E                   b51 = i9 < i50;
E                   nvfuser_index_t i52;
E                   i52 = i33 + i29;
E                   bool b53;
E                   b53 = i11 >= i50;
E                   nvfuser_index_t i54;
E                   i54 = i34 + i29;
E                   bool b55;
E                   b55 = (i9 >= i50) && (i11 < i50);
E                   nvfuser_index_t i56;
E                   i56 = i35 + i29;
E                   nvfuser_index_t i57;
E                   i57 = -(i29 + nvfuser_zero);
E                   bool b58;
E                   b58 = (i23 < i57) && (i24 < i57);
E                   #pragma unroll
E                   for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
E                     nvfuser_index_t i59;
E                     i59 = i46 + nvfuser_zero;
E                     nvfuser_index_t i60;
E                     i60 = i8 * i59;
E                     bool b61;
E                     b61 = b58 && (i37 < (-(((nvfuser_index_t)blockDim.y) * i59)));
E                     Array<__bfloat, 1, 1> T3;
E                     if (b61) {
E                       T3[0]
E                          = b51 ? T0[(i49 + i60)] : 0.0000e+00f;
E                     }
E                     Array<__bfloat, 1, 1> T5;
E                     if (b61) {
E                       T5[0]
E                          = b53 ? T2[(i52 + i60)] : 0.0000e+00f;
E                     }
E                     Array<__bfloat, 1, 1> T4;
E                     if (b61) {
E                       T4[0]
E                          = b55 ? T1[(i54 + i60)] : 0.0000e+00f;
E                     }
E                     Array<__bfloat, 1, 1> T6;
E                     if (b61) {
E                       T6[0]
E                         = (T3[0] | T4[0])
E                         | T5[0];
E                     }
E                     Array<__bfloat, 1, 1> T7;
E                     if (b61) {
E                       T7[0]
E                          = T6[0];
E                     }
E                     Array<float, 1, 1> T8;
E                     if (b61) {
E                       T8[0]
E                          = __bfloat2float(T7[0]);
E                     }
E                     Array<__bfloat, 1, 1> T16;
E                     if (b61) {
E                       T16[0]
E                          = T7[0];
E                     }
E                     if (b61) {
E                       T14[(i56 + (i17 * i59))]
E                          = T16[0];
E                     }
E                     Array<float, 1, 1> T9;
E                     if (b61) {
E                       T9[0]
E                          = T8[0];
E                     }
E                     if (b61) {
E                       T17[i29]
E                         = T17[i29]
E                         + T9[0];
E                     }
E                   }
E                 }
E                 NVFUSER_UPDATE_MAGIC_ZERO;
E               }
E             }
E             if (b20) {
E               Array<float, 8, 1> T10;
E               #pragma unroll
E               for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
E                 T10[i62] = 0.000000000e+00f;
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
E                 T10.array,
E                 T17.array,
E                 [](float &a, float b) { a = a + b; },
E                 &T18[0],
E                 &T19[0],
E                 static_cast<float*>(shared_mem),
E                 true,
E                 true,
E                 float(0.000000000e+00f),
E                 DefaultBlockDim());
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               #pragma unroll
E               for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
E                 Array<__bfloat, 1, 1> T15;
E                 if (b26) {
E                   T15[0]
E                      = __float2bfloat(T10[i63]);
E                 }
E                 if (b26) {
E                   T11[(i18 + (i63 + nvfuser_zero))]
E                      = T15[0];
E                 }
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E             } else {
E               Array<float, 8, 1> T10;
E               #pragma unroll
E               for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
E                 T10[i62] = 0.000000000e+00f;
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
E                 T10.array,
E                 T17.array,
E                 [](float &a, float b) { a = a + b; },
E                 &T18[0],
E                 &T19[0],
E                 static_cast<float*>(shared_mem),
E                 ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
E                 ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
E                 float(0.000000000e+00f),
E                 DefaultBlockDim());
E               NVFUSER_UPDATE_MAGIC_ZERO;
E               #pragma unroll
E               for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
E                 nvfuser_index_t i64;
E                 i64 = i63 + nvfuser_zero;
E                 nvfuser_index_t i65;
E                 i65 = -i64;
E                 bool b66;
E                 b66 = i23 < i65;
E                 bool b67;
E                 b67 = i24 < i65;
E                 Array<__bfloat, 1, 1> T15;
E                 if ((b66 && b67)) {
E                   T15[0]
E                      = __float2bfloat(T10[i63]);
E                 }
E                 if (((b26 && b66) && b67)) {
E                   T11[(i18 + i64)]
E                      = T15[0];
E                 }
E               }
E               NVFUSER_UPDATE_MAGIC_ZERO;
E             }
E           }
E           
E           } // namespace nvf
E           
E           CUDA NVRTC compile error: __tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12953): error: identifier "i62" is undefined
E                   ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
E                              ^
E           
E           __tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12737): warning #550-D: variable "i28" was set but never used
E               nvfuser_index_t i28;
E                               ^
E           
E           Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"
E           
E           1 error detected in the compilation of "__tmp_nvfuser_reduction_f0_c1_r0_g0.cu".
E           
E           Exception raised from invoke at /opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp:178 (most recent call first):
E           frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x72dbd923d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x72dbd923dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #2: <unknown function> + 0x103f9b2 (0x72dbd984f9b2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #3: <unknown function> + 0x1043ff0 (0x72dbd9853ff0 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #4: <unknown function> + 0x1044c99 (0x72dbd9854c99 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #5: nvfuser::CompiledKernel::compile(nvfuser::LaunchParams const&) + 0xd04 (0x72dbd9858dc4 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #6: nvfuser::KernelExecutor::compile(nvfuser::Fusion*, nvfuser::KernelArgumentHolder const&, nvfuser::LaunchParams const&, nvfuser::CompileParams, nvfuser::SchedulerType) + 0x832 (0x72dbd9874946 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #7: <unknown function> + 0x1082c8a (0x72dbd9892c8a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #8: <unknown function> + 0x10e5ca6 (0x72dbd98f5ca6 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #9: <unknown function> + 0x10e279a (0x72dbd98f279a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #10: <unknown function> + 0x10e729a (0x72dbd98f729a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #11: <unknown function> + 0x10e6eb2 (0x72dbd98f6eb2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #12: <unknown function> + 0x10e6c8d (0x72dbd98f6c8d in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #13: c10::ThreadPool::main_loop(unsigned long) + 0x2ad (0x72dd1668b5ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
E           frame #14: <unknown function> + 0xecdb4 (0x72dd15d7bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
E           frame #15: <unknown function> + 0x9caa4 (0x72dd57a15aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           frame #16: <unknown function> + 0x129c3c (0x72dd57aa2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           
E           
E           Use NVFUSER_DISABLE=parallel_compile to simplify error message.
E           Exception raised from compileFusionParallel at /opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp:465 (most recent call first):
E           frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x72dbd923d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x72dbd923dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #2: nvfuser::FusionKernelRuntime::compileFusionParallel(nvfuser::KernelArgumentHolder) + 0x61d (0x72dbd98f2fd7 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #3: nvfuser::FusionExecutorCache::runFusionWithInputs(nvfuser::KernelArgumentHolder, std::optional<nvfuser::PrimDataType>, std::optional<signed char>) + 0x13f (0x72dbd98dac71 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #4: nvfuser::python_frontend::FusionDefinition::execute(nvfuser::KernelArgumentHolder, std::optional<signed char>, bool, bool, bool, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) const + 0x790 (0x72dbd9c6de1e in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #5: <unknown function> + 0x246f74 (0x72dbd8a56f74 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #6: <unknown function> + 0x37dd85 (0x72dbd8b8dd85 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #7: <unknown function> + 0x36f08f (0x72dbd8b7f08f in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #8: <unknown function> + 0x3153fd (0x72dbd8b253fd in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #9: <unknown function> + 0x3154ec (0x72dbd8b254ec in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #10: <unknown function> + 0x205d90 (0x72dbd8a15d90 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
E           frame #11: /usr/bin/python3() [0x581d4f]
E           frame #12: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #13: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #14: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #15: /usr/bin/python3() [0x5a3148]
E           frame #16: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #17: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #18: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #19: /usr/bin/python3() [0x5a3148]
E           frame #20: PyObject_Call + 0x9c (0x54b13c in /usr/bin/python3)
E           frame #21: _PyEval_EvalFrameDefault + 0x4cc6 (0x5dad16 in /usr/bin/python3)
E           frame #22: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #23: /usr/bin/python3() [0x5a3148]
E           frame #24: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #25: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #26: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #27: /usr/bin/python3() [0x5a3148]
E           frame #28: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #29: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #30: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
E           frame #31: /usr/bin/python3() [0x5a3148]
E           frame #32: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
E           frame #33: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
E           frame #34: PyEval_EvalCode + 0x15b (0x5d500b in /usr/bin/python3)
E           frame #35: /usr/bin/python3() [0x6081e2]
E           frame #36: /usr/bin/python3() [0x6b5033]
E           frame #37: _PyRun_SimpleFileObject + 0x1aa (0x6b4d9a in /usr/bin/python3)
E           frame #38: _PyRun_AnyFileObject + 0x4f (0x6b4bcf in /usr/bin/python3)
E           frame #39: Py_RunMain + 0x3b5 (0x6bcc35 in /usr/bin/python3)
E           frame #40: Py_BytesMain + 0x2d (0x6bc71d in /usr/bin/python3)
E           frame #41: <unknown function> + 0x2a1ca (0x72dd579a31ca in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           frame #42: __libc_start_main + 0x8b (0x72dd579a328b in /usr/lib/x86_64-linux-gnu/libc.so.6)
E           frame #43: _start + 0x25 (0x6575a5 in /usr/bin/python3)

python/nvfuser/__init__.py:333: RuntimeError
-------------------------------------- Captured log call ---------------------------------------
ERROR    nvfuser:__init__.py:350 An error occurred while executing nvFuser FusionDefinition 0.
If you believe this is a bug or need assistance, please file an issue at https://github.com/NVIDIA/Fuser/issues/new
Here's a script to reproduce the error:
```python
# CUDA devices:
#  0: NVIDIA RTX 6000 Ada Generation
#  1: NVIDIA RTX 6000 Ada Generation
# torch version: 2.8.0a0+34c6371d24.nvInternal
# cuda version: 13.0
# nvfuser version: 0.2.28+gitf13308c
import torch
from nvfuser import FusionDefinition, DataType

def nvfuser_fusion_id0(fd : FusionDefinition) -> None :
    T0 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
    T1 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
    T2 = fd.define_tensor(shape=[1, 2048, 96, 128], contiguity=[None, True, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 1, 2, 0])
    S3 = fd.define_scalar(0.00000, dtype=DataType.BFloat16)
    S4 = fd.define_scalar(0, dtype=DataType.Int)
    S5 = fd.define_scalar(0, dtype=DataType.Int)
    S6 = fd.define_scalar(0, dtype=DataType.Int)
    S7 = fd.define_scalar(0, dtype=DataType.Int)
    S8 = fd.define_scalar(0, dtype=DataType.Int)
    S9 = fd.define_scalar(0, dtype=DataType.Int)
    S10 = fd.define_scalar(0, dtype=DataType.Int)
    S11 = fd.define_scalar(256, dtype=DataType.Int)
    V12 = fd.define_vector([S10, S11, S8, S9, S6, S7, S4, S5], dtype=DataType.Int)
    T13 = fd.ops.pad(T0, V12, S3)
    S14 = fd.define_scalar(0, dtype=DataType.Int)
    S15 = fd.ops.size(T1, dim=3)
    S16 = fd.ops.add(S14, S15)
    S17 = fd.define_scalar(0.00000, dtype=DataType.BFloat16)
    S18 = fd.define_scalar(0, dtype=DataType.Int)
    S19 = fd.define_scalar(0, dtype=DataType.Int)
    S20 = fd.define_scalar(0, dtype=DataType.Int)
    S21 = fd.define_scalar(0, dtype=DataType.Int)
    S22 = fd.define_scalar(0, dtype=DataType.Int)
    S23 = fd.define_scalar(0, dtype=DataType.Int)
    S24 = fd.define_scalar(128, dtype=DataType.Int)
    V25 = fd.define_vector([S16, S24, S22, S23, S20, S21, S18, S19], dtype=DataType.Int)
    T26 = fd.ops.pad(T1, V25, S17)
    S27 = fd.ops.add(S16, S15)
    S28 = fd.define_scalar(0.00000, dtype=DataType.BFloat16)
    S29 = fd.define_scalar(0, dtype=DataType.Int)
    S30 = fd.define_scalar(0, dtype=DataType.Int)
    S31 = fd.define_scalar(0, dtype=DataType.Int)
    S32 = fd.define_scalar(0, dtype=DataType.Int)
    S33 = fd.define_scalar(0, dtype=DataType.Int)
    S34 = fd.define_scalar(0, dtype=DataType.Int)
    S35 = fd.define_scalar(0, dtype=DataType.Int)
    V36 = fd.define_vector([S27, S35, S33, S34, S31, S32, S29, S30], dtype=DataType.Int)
    T37 = fd.ops.pad(T2, V36, S28)
    T38 = fd.ops.cat([T13, T26, T37], dim=3, manual_padding=1)
    S39 = fd.ops.size(T37, dim=0)
    S40 = fd.ops.size(T37, dim=1)
    S41 = fd.define_scalar(36864, dtype=DataType.Int)
    V42 = fd.define_vector([S39, S40, S41], dtype=DataType.Int)
    T43 = fd.ops.reshape(T38, new_shape=V42)
    T44 = fd.ops.cast(T43, dtype=DataType.Float)
    T45 = fd.ops.squeeze(T44, dims=[0], squeeze_expanded=True)
    T46 = fd.ops.sum(T45, dims=[0], keepdim=False, dtype=DataType.Float)
    T47 = fd.ops.cast(T46, dtype=DataType.BFloat16)
    T48 = fd.ops.squeeze(T43, dims=[0], squeeze_expanded=True)
    T49 = fd.ops.permute(T48, dims=[1, 0])
    fd.add_output(T47)
    fd.add_output(T49, stride_order=[0, 1])
    fd.add_output(T48)

with FusionDefinition() as fd:
    nvfuser_fusion_id0(fd)

inputs = [
    torch.randn(12582912, dtype=torch.bfloat16, device='cuda:1').as_strided((1, 2048, 48, 128), (12582912, 128, 262144, 1)),
    torch.randn(12582912, dtype=torch.bfloat16, device='cuda:1').as_strided((1, 2048, 48, 128), (12582912, 128, 262144, 1)),
    torch.randn(12582912, dtype=torch.bfloat16, device='cuda:1').as_strided((1, 2048, 48, 128), (12582912, 128, 262144, 1)),
]
fd.execute(inputs)
```
Traceback (most recent call last):
  File "/opt/pytorch/nvfuser/python/nvfuser/__init__.py", line 333, in execute
    out_tensors, out_shardings = self._execute(
                                 ^^^^^^^^^^^^^^
RuntimeError:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp":465, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. Detected exception while compiling fusion segments in parallel. Error messages from all threads are printed below.

Error from segmentation group 0:  INTERNAL ASSERT FAILED at "/opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp":178, please report a bug with repro script to NVFuser at https://github.com/NVIDIA/Fuser/issues. 
// Codegen generated code
__global__ void nvfuser_reduction_f0_c1_r0_g0(Tensor<__bfloat, 4, 5> T0, Tensor<__bfloat, 4, 5> T1, Tensor<__bfloat, 4, 5> T2, Tensor<__bfloat, 1, 2> T11, Tensor<__bfloat, 3, 4> T14, Tensor<float, 1, 1> T18, Tensor<int64_t, 1, 1> T19) {
  alignas(16) extern __shared__ char array[];
  void* shared_mem = array;
  NVFUSER_DEFINE_MAGIC_ZERO;
  nvfuser_index_t i0;
  i0 = ceilDiv((ceilDiv((ceilDiv(2048, ((nvfuser_index_t)blockDim.y))), 4)), ((nvfuser_index_t)gridDim.y));
  nvfuser_index_t i1;
  i1 = ((nvfuser_index_t)threadIdx.x) + (((nvfuser_index_t)blockDim.x) * ((nvfuser_index_t)blockIdx.x));
  nvfuser_index_t i2;
  i2 = ((nvfuser_index_t)blockDim.y) * 512;
  nvfuser_index_t i3;
  i3 = 8 * (i1 % 48);
  nvfuser_index_t i4;
  i4 = 128 * ((nvfuser_index_t)threadIdx.y);
  nvfuser_index_t i5;
  i5 = (i2 * i0) * ((nvfuser_index_t)blockIdx.y);
  nvfuser_index_t i6;
  i6 = 262144 * (i1 / 48);
  nvfuser_index_t i7;
  i7 = ((i4 + i5) + i6) + i3;
  nvfuser_index_t i8;
  i8 = 128 * ((nvfuser_index_t)blockDim.y);
  nvfuser_index_t i9;
  i9 = -128 + i3;
  nvfuser_index_t i10;
  i10 = (((-256 + i4) + i5) + i6) + i3;
  nvfuser_index_t i11;
  i11 = -256 + i3;
  nvfuser_index_t i12;
  i12 = (((-128 + i4) + i5) + i6) + i3;
  nvfuser_index_t i13;
  i13 = ((nvfuser_index_t)blockDim.y) * 73728;
  nvfuser_index_t i14;
  i14 = 8 * ((nvfuser_index_t)threadIdx.x);
  nvfuser_index_t i15;
  i15 = (8 * ((nvfuser_index_t)blockDim.x)) * ((nvfuser_index_t)blockIdx.x);
  nvfuser_index_t i16;
  i16 = (((18432 * ((nvfuser_index_t)threadIdx.y)) + ((i13 * i0) * ((nvfuser_index_t)blockIdx.y))) + i14) + i15;
  nvfuser_index_t i17;
  i17 = 18432 * ((nvfuser_index_t)blockDim.y);
  nvfuser_index_t i18;
  i18 = i14 + i15;
  nvfuser_index_t i19;
  i19 = (7 + i14) + i15;
  bool b20;
  b20 = (i19 < 36864) && (i19 < 18432);
  nvfuser_index_t i21;
  i21 = ((nvfuser_index_t)blockDim.y) * 4;
  nvfuser_index_t i22;
  i22 = (((i21 * ((nvfuser_index_t)blockIdx.y)) * i0) + (((nvfuser_index_t)blockDim.y) * 3)) + ((nvfuser_index_t)threadIdx.y);
  nvfuser_index_t i23;
  i23 = (-36864 + i14) + i15;
  nvfuser_index_t i24;
  i24 = (-18432 + i14) + i15;
  nvfuser_index_t i25;
  i25 = (-2048 + ((nvfuser_index_t)threadIdx.y)) + ((i21 * i0) * ((nvfuser_index_t)blockIdx.y));
  bool b26;
  b26 = (((nvfuser_index_t)blockIdx.y) == (((nvfuser_index_t)gridDim.y) + -1)) && (((nvfuser_index_t)threadIdx.y) == 0);
  nvfuser_index_t i27;
  i27 = 0LL + 128;
  nvfuser_index_t i28;
  i28 = i27 + 128;
  // Allocate global tensor T18
  // Allocate global tensor T19
  Array<float, 8, 8> T17;
  #pragma unroll
  for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
    T17[i29] = 0.000000000e+00f;
  }
  NVFUSER_UPDATE_MAGIC_ZERO;
  #pragma unroll 1
  for(nvfuser_index_t i30 = 0; i30 < i0; ++i30) {
    nvfuser_index_t i31;
    i31 = i2 * i30;
    nvfuser_index_t i32;
    i32 = i7 + i31;
    nvfuser_index_t i33;
    i33 = i10 + i31;
    nvfuser_index_t i34;
    i34 = i12 + i31;
    nvfuser_index_t i35;
    i35 = i16 + (i13 * i30);
    nvfuser_index_t i36;
    i36 = i21 * i30;
    nvfuser_index_t i37;
    i37 = i25 + i36;
    if ((b20 && ((i22 + i36) < 2048))) {
      #pragma unroll
      for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
        nvfuser_index_t i38;
        i38 = i32 + i29;
        nvfuser_index_t i39;
        i39 = -i29;
        bool b40;
        b40 = i9 < i39;
        nvfuser_index_t i41;
        i41 = i33 + i29;
        bool b42;
        b42 = i11 >= i39;
        nvfuser_index_t i43;
        i43 = i34 + i29;
        bool b44;
        b44 = (i9 >= i39) && (i11 < i39);
        nvfuser_index_t i45;
        i45 = i35 + i29;
        #pragma unroll
        for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
          nvfuser_index_t i47;
          i47 = i46 + nvfuser_zero;
          nvfuser_index_t i48;
          i48 = i8 * i47;
          Array<__bfloat, 1, 1> T3;
          T3[0]
             = b40 ? T0[(i38 + i48)] : 0.0000e+00f;
          Array<__bfloat, 1, 1> T5;
          T5[0]
             = b42 ? T2[(i41 + i48)] : 0.0000e+00f;
          Array<__bfloat, 1, 1> T4;
          T4[0]
             = b44 ? T1[(i43 + i48)] : 0.0000e+00f;
          Array<__bfloat, 1, 1> T6;
          T6[0]
            = (T3[0] | T4[0])
            | T5[0];
          Array<__bfloat, 1, 1> T7;
          T7[0]
             = T6[0];
          Array<float, 1, 1> T8;
          T8[0]
             = __bfloat2float(T7[0]);
          Array<__bfloat, 1, 1> T16;
          T16[0]
             = T7[0];
          T14[(i45 + (i17 * i47))]
             = T16[0];
          Array<float, 1, 1> T9;
          T9[0]
             = T8[0];
          T17[i29]
            = T17[i29]
            + T9[0];
        }
      }
      NVFUSER_UPDATE_MAGIC_ZERO;
    } else {
      #pragma unroll
      for(nvfuser_index_t i29 = 0; i29 < 8; ++i29) {
        nvfuser_index_t i49;
        i49 = i32 + i29;
        nvfuser_index_t i50;
        i50 = -i29;
        bool b51;
        b51 = i9 < i50;
        nvfuser_index_t i52;
        i52 = i33 + i29;
        bool b53;
        b53 = i11 >= i50;
        nvfuser_index_t i54;
        i54 = i34 + i29;
        bool b55;
        b55 = (i9 >= i50) && (i11 < i50);
        nvfuser_index_t i56;
        i56 = i35 + i29;
        nvfuser_index_t i57;
        i57 = -(i29 + nvfuser_zero);
        bool b58;
        b58 = (i23 < i57) && (i24 < i57);
        #pragma unroll
        for(nvfuser_index_t i46 = 0; i46 < 4; ++i46) {
          nvfuser_index_t i59;
          i59 = i46 + nvfuser_zero;
          nvfuser_index_t i60;
          i60 = i8 * i59;
          bool b61;
          b61 = b58 && (i37 < (-(((nvfuser_index_t)blockDim.y) * i59)));
          Array<__bfloat, 1, 1> T3;
          if (b61) {
            T3[0]
               = b51 ? T0[(i49 + i60)] : 0.0000e+00f;
          }
          Array<__bfloat, 1, 1> T5;
          if (b61) {
            T5[0]
               = b53 ? T2[(i52 + i60)] : 0.0000e+00f;
          }
          Array<__bfloat, 1, 1> T4;
          if (b61) {
            T4[0]
               = b55 ? T1[(i54 + i60)] : 0.0000e+00f;
          }
          Array<__bfloat, 1, 1> T6;
          if (b61) {
            T6[0]
              = (T3[0] | T4[0])
              | T5[0];
          }
          Array<__bfloat, 1, 1> T7;
          if (b61) {
            T7[0]
               = T6[0];
          }
          Array<float, 1, 1> T8;
          if (b61) {
            T8[0]
               = __bfloat2float(T7[0]);
          }
          Array<__bfloat, 1, 1> T16;
          if (b61) {
            T16[0]
               = T7[0];
          }
          if (b61) {
            T14[(i56 + (i17 * i59))]
               = T16[0];
          }
          Array<float, 1, 1> T9;
          if (b61) {
            T9[0]
               = T8[0];
          }
          if (b61) {
            T17[i29]
              = T17[i29]
              + T9[0];
          }
        }
      }
      NVFUSER_UPDATE_MAGIC_ZERO;
    }
  }
  if (b20) {
    Array<float, 8, 1> T10;
    #pragma unroll
    for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
      T10[i62] = 0.000000000e+00f;
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
    reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
      T10.array,
      T17.array,
      [](float &a, float b) { a = a + b; },
      &T18[0],
      &T19[0],
      static_cast<float*>(shared_mem),
      true,
      true,
      float(0.000000000e+00f),
      DefaultBlockDim());
    NVFUSER_UPDATE_MAGIC_ZERO;
    #pragma unroll
    for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
      Array<__bfloat, 1, 1> T15;
      if (b26) {
        T15[0]
           = __float2bfloat(T10[i63]);
      }
      if (b26) {
        T11[(i18 + (i63 + nvfuser_zero))]
           = T15[0];
      }
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
  } else {
    Array<float, 8, 1> T10;
    #pragma unroll
    for(nvfuser_index_t i62 = 0; i62 < 8; ++i62) {
      T10[i62] = 0.000000000e+00f;
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
    reduction::iterGroupedGridReduce<false, true, false, false, true, false, false, false, 8>(
      T10.array,
      T17.array,
      [](float &a, float b) { a = a + b; },
      &T18[0],
      &T19[0],
      static_cast<float*>(shared_mem),
      ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
      ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
      float(0.000000000e+00f),
      DefaultBlockDim());
    NVFUSER_UPDATE_MAGIC_ZERO;
    #pragma unroll
    for(nvfuser_index_t i63 = 0; i63 < 8; ++i63) {
      nvfuser_index_t i64;
      i64 = i63 + nvfuser_zero;
      nvfuser_index_t i65;
      i65 = -i64;
      bool b66;
      b66 = i23 < i65;
      bool b67;
      b67 = i24 < i65;
      Array<__bfloat, 1, 1> T15;
      if ((b66 && b67)) {
        T15[0]
           = __float2bfloat(T10[i63]);
      }
      if (((b26 && b66) && b67)) {
        T11[(i18 + i64)]
           = T15[0];
      }
    }
    NVFUSER_UPDATE_MAGIC_ZERO;
  }
}

} // namespace nvf

CUDA NVRTC compile error: __tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12953): error: identifier "i62" is undefined
        ((i23 < (-(i62 + nvfuser_zero))) && (i24 < (-(i62 + nvfuser_zero)))),
                   ^

__tmp_nvfuser_reduction_f0_c1_r0_g0.cu(12737): warning #550-D: variable "i28" was set but never used
    nvfuser_index_t i28;
                    ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

1 error detected in the compilation of "__tmp_nvfuser_reduction_f0_c1_r0_g0.cu".

Exception raised from invoke at /opt/pytorch/nvfuser/csrc/runtime/compiled_kernel.cpp:178 (most recent call first):
frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x72dbd923d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x72dbd923dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #2: <unknown function> + 0x103f9b2 (0x72dbd984f9b2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #3: <unknown function> + 0x1043ff0 (0x72dbd9853ff0 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #4: <unknown function> + 0x1044c99 (0x72dbd9854c99 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #5: nvfuser::CompiledKernel::compile(nvfuser::LaunchParams const&) + 0xd04 (0x72dbd9858dc4 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #6: nvfuser::KernelExecutor::compile(nvfuser::Fusion*, nvfuser::KernelArgumentHolder const&, nvfuser::LaunchParams const&, nvfuser::CompileParams, nvfuser::SchedulerType) + 0x832 (0x72dbd9874946 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #7: <unknown function> + 0x1082c8a (0x72dbd9892c8a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #8: <unknown function> + 0x10e5ca6 (0x72dbd98f5ca6 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #9: <unknown function> + 0x10e279a (0x72dbd98f279a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #10: <unknown function> + 0x10e729a (0x72dbd98f729a in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #11: <unknown function> + 0x10e6eb2 (0x72dbd98f6eb2 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #12: <unknown function> + 0x10e6c8d (0x72dbd98f6c8d in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #13: c10::ThreadPool::main_loop(unsigned long) + 0x2ad (0x72dd1668b5ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
frame #14: <unknown function> + 0xecdb4 (0x72dd15d7bdb4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #15: <unknown function> + 0x9caa4 (0x72dd57a15aa4 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #16: <unknown function> + 0x129c3c (0x72dd57aa2c3c in /usr/lib/x86_64-linux-gnu/libc.so.6)


Use NVFUSER_DISABLE=parallel_compile to simplify error message.
Exception raised from compileFusionParallel at /opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp:465 (most recent call first):
frame #0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x91 (0x72dbd923d9be in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #1: nvfuser::nvfErrorFail(char const*, char const*, unsigned int, char const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x71 (0x72dbd923dc88 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #2: nvfuser::FusionKernelRuntime::compileFusionParallel(nvfuser::KernelArgumentHolder) + 0x61d (0x72dbd98f2fd7 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #3: nvfuser::FusionExecutorCache::runFusionWithInputs(nvfuser::KernelArgumentHolder, std::optional<nvfuser::PrimDataType>, std::optional<signed char>) + 0x13f (0x72dbd98dac71 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #4: nvfuser::python_frontend::FusionDefinition::execute(nvfuser::KernelArgumentHolder, std::optional<signed char>, bool, bool, bool, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) const + 0x790 (0x72dbd9c6de1e in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #5: <unknown function> + 0x246f74 (0x72dbd8a56f74 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #6: <unknown function> + 0x37dd85 (0x72dbd8b8dd85 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #7: <unknown function> + 0x36f08f (0x72dbd8b7f08f in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #8: <unknown function> + 0x3153fd (0x72dbd8b253fd in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #9: <unknown function> + 0x3154ec (0x72dbd8b254ec in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #10: <unknown function> + 0x205d90 (0x72dbd8a15d90 in /opt/pytorch/nvfuser/python/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)
frame #11: /usr/bin/python3() [0x581d4f]
frame #12: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #13: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #14: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #15: /usr/bin/python3() [0x5a3148]
frame #16: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #17: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #18: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #19: /usr/bin/python3() [0x5a3148]
frame #20: PyObject_Call + 0x9c (0x54b13c in /usr/bin/python3)
frame #21: _PyEval_EvalFrameDefault + 0x4cc6 (0x5dad16 in /usr/bin/python3)
frame #22: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #23: /usr/bin/python3() [0x5a3148]
frame #24: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #25: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #26: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #27: /usr/bin/python3() [0x5a3148]
frame #28: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #29: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #30: _PyObject_Call_Prepend + 0x18a (0x54a89a in /usr/bin/python3)
frame #31: /usr/bin/python3() [0x5a3148]
frame #32: _PyObject_MakeTpCall + 0x13e (0x54904e in /usr/bin/python3)
frame #33: _PyEval_EvalFrameDefault + 0xadf (0x5d6b2f in /usr/bin/python3)
frame #34: PyEval_EvalCode + 0x15b (0x5d500b in /usr/bin/python3)
frame #35: /usr/bin/python3() [0x6081e2]
frame #36: /usr/bin/python3() [0x6b5033]
frame #37: _PyRun_SimpleFileObject + 0x1aa (0x6b4d9a in /usr/bin/python3)
frame #38: _PyRun_AnyFileObject + 0x4f (0x6b4bcf in /usr/bin/python3)
frame #39: Py_RunMain + 0x3b5 (0x6bcc35 in /usr/bin/python3)
frame #40: Py_BytesMain + 0x2d (0x6bc71d in /usr/bin/python3)
frame #41: <unknown function> + 0x2a1ca (0x72dd579a31ca in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #42: __libc_start_main + 0x8b (0x72dd579a328b in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #43: _start + 0x25 (0x6575a5 in /usr/bin/python3)
======================================= MPI Information ========================================
rank: 1
size: 2
MPI version: 3.1
MPI library version: Open MPI v4.1.9a1, package: Open MPI root@sharp-ci-02 Distribution, ident: 4.1.9a1, repo rev: v4.1.5-222-g92f9fca4eb, Unreleased developer copy 
MPI vendor: Open MPI 4.1.9
mpi4py rc: 
mpi4py config:
=================================== short test summary info ====================================
FAILED tests/python/multidevice/test_transformer.py::test_cat_reduction - RuntimeError:  INTE...
=============================== 1 failed, 4 deselected in 5.90s ================================
