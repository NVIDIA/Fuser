// automatically generated by the FlatBuffers compiler, do not modify

#ifndef FLATBUFFERS_GENERATED_FUSIONCACHE_NVFUSER_SERDE_H_
#define FLATBUFFERS_GENERATED_FUSIONCACHE_NVFUSER_SERDE_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(
    FLATBUFFERS_VERSION_MAJOR == 2 && FLATBUFFERS_VERSION_MINOR == 0 &&
        FLATBUFFERS_VERSION_REVISION == 7,
    "Non-compatible flatbuffers version included");

namespace nvfuser {
namespace serde {

struct Bool;
struct BoolBuilder;

struct Double;
struct DoubleBuilder;

struct Int;
struct IntBuilder;

struct BatchNorm;
struct BatchNormBuilder;

struct Broadcast;
struct BroadcastBuilder;

struct BroadcastInDim;
struct BroadcastInDimBuilder;

struct BroadcastInDimSymbolic;
struct BroadcastInDimSymbolicBuilder;

struct ComplexDouble;
struct ComplexDoubleBuilder;

struct Dtype;
struct DtypeBuilder;

struct Dimension;
struct DimensionBuilder;

struct Norm;
struct NormBuilder;

struct Output;
struct OutputBuilder;

struct Pad;
struct PadBuilder;

struct Permute;
struct PermuteBuilder;

struct Reduction;
struct ReductionBuilder;

struct Reshape;
struct ReshapeBuilder;

struct Slice;
struct SliceBuilder;

struct Squeeze;
struct SqueezeBuilder;

struct Tensor;
struct TensorBuilder;

struct TensorCreation;
struct TensorCreationBuilder;

struct TensorCreationSymbolic;
struct TensorCreationSymbolicBuilder;

struct State;

struct RecordFunctor;
struct RecordFunctorBuilder;

struct TrieNode;
struct TrieNodeBuilder;

struct FusionCache;
struct FusionCacheBuilder;

enum DataType : int32_t {
  DataType_Double = 0,
  DataType_Float = 1,
  DataType_Half = 2,
  DataType_Int = 3,
  DataType_Int32 = 4,
  DataType_Bool = 5,
  DataType_BFloat16 = 6,
  DataType_ComplexFloat = 7,
  DataType_ComplexDouble = 8,
  DataType_None = 9,
  DataType_MIN = DataType_Double,
  DataType_MAX = DataType_None
};

inline const DataType (&EnumValuesDataType())[10] {
  static const DataType values[] = {
      DataType_Double,
      DataType_Float,
      DataType_Half,
      DataType_Int,
      DataType_Int32,
      DataType_Bool,
      DataType_BFloat16,
      DataType_ComplexFloat,
      DataType_ComplexDouble,
      DataType_None};
  return values;
}

inline const char* const* EnumNamesDataType() {
  static const char* const names[11] = {
      "Double",
      "Float",
      "Half",
      "Int",
      "Int32",
      "Bool",
      "BFloat16",
      "ComplexFloat",
      "ComplexDouble",
      "None",
      nullptr};
  return names;
}

inline const char* EnumNameDataType(DataType e) {
  if (flatbuffers::IsOutRange(e, DataType_Double, DataType_None))
    return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesDataType()[index];
}

enum StateType : int32_t {
  StateType_Tensor = 0,
  StateType_Scalar = 1,
  StateType_None = 2,
  StateType_MIN = StateType_Tensor,
  StateType_MAX = StateType_None
};

inline const StateType (&EnumValuesStateType())[3] {
  static const StateType values[] = {
      StateType_Tensor, StateType_Scalar, StateType_None};
  return values;
}

inline const char* const* EnumNamesStateType() {
  static const char* const names[4] = {"Tensor", "Scalar", "None", nullptr};
  return names;
}

inline const char* EnumNameStateType(StateType e) {
  if (flatbuffers::IsOutRange(e, StateType_Tensor, StateType_None))
    return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesStateType()[index];
}

enum Contiguity : int32_t {
  Contiguity_Strided = 0,
  Contiguity_Contiguous = 1,
  Contiguity_None = 2,
  Contiguity_MIN = Contiguity_Strided,
  Contiguity_MAX = Contiguity_None
};

inline const Contiguity (&EnumValuesContiguity())[3] {
  static const Contiguity values[] = {
      Contiguity_Strided, Contiguity_Contiguous, Contiguity_None};
  return values;
}

inline const char* const* EnumNamesContiguity() {
  static const char* const names[4] = {
      "Strided", "Contiguous", "None", nullptr};
  return names;
}

inline const char* EnumNameContiguity(Contiguity e) {
  if (flatbuffers::IsOutRange(e, Contiguity_Strided, Contiguity_None))
    return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesContiguity()[index];
}

enum RecordType : int32_t {
  RecordType_Base = 0,
  RecordType_BatchNormOp = 1,
  RecordType_BroadcastOp = 2,
  RecordType_BroadcastInDim = 3,
  RecordType_BroadcastInDimSymbolic = 4,
  RecordType_CastTv = 5,
  RecordType_CastVal = 6,
  RecordType_CatOp = 7,
  RecordType_ConstantBool = 8,
  RecordType_ConstantInt = 9,
  RecordType_ConstantDouble = 10,
  RecordType_ConstantComplexDouble = 11,
  RecordType_End = 12,
  RecordType_FullOp = 13,
  RecordType_IotaOp = 14,
  RecordType_IndexSelectOp = 15,
  RecordType_TorchGatherOp = 16,
  RecordType_TakeAlongAxisOp = 17,
  RecordType_Unary_TV = 18,
  RecordType_Unary_VAL = 19,
  RecordType_Binary_TV = 20,
  RecordType_Binary_VAL = 21,
  RecordType_Binary_TV_VAL = 22,
  RecordType_Binary_VAL_TV = 23,
  RecordType_Ternary_TV = 24,
  RecordType_Ternary_VAL = 25,
  RecordType_Ternary_TV_TV_VAL = 26,
  RecordType_Ternary_TV_VAL_TV = 27,
  RecordType_Ternary_VAL_TV_TV = 28,
  RecordType_Ternary_VAL_VAL_TV = 29,
  RecordType_Ternary_TV_VAL_VAL = 30,
  RecordType_Ternary_VAL_TV_VAL = 31,
  RecordType_Ternary_Alpha_TV = 32,
  RecordType_Ternary_Alpha_VAL = 33,
  RecordType_Ternary_Alpha_TV_TV_VAL = 34,
  RecordType_Ternary_Alpha_TV_VAL_TV = 35,
  RecordType_Ternary_Alpha_VAL_TV_TV = 36,
  RecordType_Ternary_Alpha_VAL_VAL_TV = 37,
  RecordType_Ternary_Alpha_TV_VAL_VAL = 38,
  RecordType_Ternary_Alpha_VAL_TV_VAL = 39,
  RecordType_OutputTv = 40,
  RecordType_OutputVal = 41,
  RecordType_PadOp = 42,
  RecordType_PermuteOp = 43,
  RecordType_RandomOp = 44,
  RecordType_ReductionMax = 45,
  RecordType_ReductionMin = 46,
  RecordType_ReductionProd = 47,
  RecordType_ReductionSum = 48,
  RecordType_ReshapeOp = 49,
  RecordType_Scalar = 50,
  RecordType_SliceOp = 51,
  RecordType_SqueezeOp = 52,
  RecordType_Start = 53,
  RecordType_Tensor = 54,
  RecordType_TensorSizes = 55,
  RecordType_VarianceOp = 56,
  RecordType_VarianceMeanOp = 57,
  RecordType_MIN = RecordType_Base,
  RecordType_MAX = RecordType_VarianceMeanOp
};

inline const RecordType (&EnumValuesRecordType())[58] {
  static const RecordType values[] = {
      RecordType_Base,
      RecordType_BatchNormOp,
      RecordType_BroadcastOp,
      RecordType_BroadcastInDim,
      RecordType_BroadcastInDimSymbolic,
      RecordType_CastTv,
      RecordType_CastVal,
      RecordType_CatOp,
      RecordType_ConstantBool,
      RecordType_ConstantInt,
      RecordType_ConstantDouble,
      RecordType_ConstantComplexDouble,
      RecordType_End,
      RecordType_FullOp,
      RecordType_IotaOp,
      RecordType_IndexSelectOp,
      RecordType_TorchGatherOp,
      RecordType_TakeAlongAxisOp,
      RecordType_Unary_TV,
      RecordType_Unary_VAL,
      RecordType_Binary_TV,
      RecordType_Binary_VAL,
      RecordType_Binary_TV_VAL,
      RecordType_Binary_VAL_TV,
      RecordType_Ternary_TV,
      RecordType_Ternary_VAL,
      RecordType_Ternary_TV_TV_VAL,
      RecordType_Ternary_TV_VAL_TV,
      RecordType_Ternary_VAL_TV_TV,
      RecordType_Ternary_VAL_VAL_TV,
      RecordType_Ternary_TV_VAL_VAL,
      RecordType_Ternary_VAL_TV_VAL,
      RecordType_Ternary_Alpha_TV,
      RecordType_Ternary_Alpha_VAL,
      RecordType_Ternary_Alpha_TV_TV_VAL,
      RecordType_Ternary_Alpha_TV_VAL_TV,
      RecordType_Ternary_Alpha_VAL_TV_TV,
      RecordType_Ternary_Alpha_VAL_VAL_TV,
      RecordType_Ternary_Alpha_TV_VAL_VAL,
      RecordType_Ternary_Alpha_VAL_TV_VAL,
      RecordType_OutputTv,
      RecordType_OutputVal,
      RecordType_PadOp,
      RecordType_PermuteOp,
      RecordType_RandomOp,
      RecordType_ReductionMax,
      RecordType_ReductionMin,
      RecordType_ReductionProd,
      RecordType_ReductionSum,
      RecordType_ReshapeOp,
      RecordType_Scalar,
      RecordType_SliceOp,
      RecordType_SqueezeOp,
      RecordType_Start,
      RecordType_Tensor,
      RecordType_TensorSizes,
      RecordType_VarianceOp,
      RecordType_VarianceMeanOp};
  return values;
}

inline const char* const* EnumNamesRecordType() {
  static const char* const names[59] = {
      "Base",
      "BatchNormOp",
      "BroadcastOp",
      "BroadcastInDim",
      "BroadcastInDimSymbolic",
      "CastTv",
      "CastVal",
      "CatOp",
      "ConstantBool",
      "ConstantInt",
      "ConstantDouble",
      "ConstantComplexDouble",
      "End",
      "FullOp",
      "IotaOp",
      "IndexSelectOp",
      "TorchGatherOp",
      "TakeAlongAxisOp",
      "Unary_TV",
      "Unary_VAL",
      "Binary_TV",
      "Binary_VAL",
      "Binary_TV_VAL",
      "Binary_VAL_TV",
      "Ternary_TV",
      "Ternary_VAL",
      "Ternary_TV_TV_VAL",
      "Ternary_TV_VAL_TV",
      "Ternary_VAL_TV_TV",
      "Ternary_VAL_VAL_TV",
      "Ternary_TV_VAL_VAL",
      "Ternary_VAL_TV_VAL",
      "Ternary_Alpha_TV",
      "Ternary_Alpha_VAL",
      "Ternary_Alpha_TV_TV_VAL",
      "Ternary_Alpha_TV_VAL_TV",
      "Ternary_Alpha_VAL_TV_TV",
      "Ternary_Alpha_VAL_VAL_TV",
      "Ternary_Alpha_TV_VAL_VAL",
      "Ternary_Alpha_VAL_TV_VAL",
      "OutputTv",
      "OutputVal",
      "PadOp",
      "PermuteOp",
      "RandomOp",
      "ReductionMax",
      "ReductionMin",
      "ReductionProd",
      "ReductionSum",
      "ReshapeOp",
      "Scalar",
      "SliceOp",
      "SqueezeOp",
      "Start",
      "Tensor",
      "TensorSizes",
      "VarianceOp",
      "VarianceMeanOp",
      nullptr};
  return names;
}

inline const char* EnumNameRecordType(RecordType e) {
  if (flatbuffers::IsOutRange(e, RecordType_Base, RecordType_VarianceMeanOp))
    return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesRecordType()[index];
}

enum RecordData : uint8_t {
  RecordData_NONE = 0,
  RecordData_BatchNorm = 1,
  RecordData_Bool = 2,
  RecordData_Broadcast = 3,
  RecordData_BroadcastInDim = 4,
  RecordData_BroadcastInDimSymbolic = 5,
  RecordData_ComplexDouble = 6,
  RecordData_Double = 7,
  RecordData_Dtype = 8,
  RecordData_Dimension = 9,
  RecordData_Int = 10,
  RecordData_Norm = 11,
  RecordData_Output = 12,
  RecordData_Pad = 13,
  RecordData_Permute = 14,
  RecordData_Slice = 15,
  RecordData_Squeeze = 16,
  RecordData_Reduction = 17,
  RecordData_Reshape = 18,
  RecordData_Tensor = 19,
  RecordData_TensorCreation = 20,
  RecordData_TensorCreationSymbolic = 21,
  RecordData_MIN = RecordData_NONE,
  RecordData_MAX = RecordData_TensorCreationSymbolic
};

inline const RecordData (&EnumValuesRecordData())[22] {
  static const RecordData values[] = {
      RecordData_NONE,
      RecordData_BatchNorm,
      RecordData_Bool,
      RecordData_Broadcast,
      RecordData_BroadcastInDim,
      RecordData_BroadcastInDimSymbolic,
      RecordData_ComplexDouble,
      RecordData_Double,
      RecordData_Dtype,
      RecordData_Dimension,
      RecordData_Int,
      RecordData_Norm,
      RecordData_Output,
      RecordData_Pad,
      RecordData_Permute,
      RecordData_Slice,
      RecordData_Squeeze,
      RecordData_Reduction,
      RecordData_Reshape,
      RecordData_Tensor,
      RecordData_TensorCreation,
      RecordData_TensorCreationSymbolic};
  return values;
}

inline const char* const* EnumNamesRecordData() {
  static const char* const names[23] = {
      "NONE",
      "BatchNorm",
      "Bool",
      "Broadcast",
      "BroadcastInDim",
      "BroadcastInDimSymbolic",
      "ComplexDouble",
      "Double",
      "Dtype",
      "Dimension",
      "Int",
      "Norm",
      "Output",
      "Pad",
      "Permute",
      "Slice",
      "Squeeze",
      "Reduction",
      "Reshape",
      "Tensor",
      "TensorCreation",
      "TensorCreationSymbolic",
      nullptr};
  return names;
}

inline const char* EnumNameRecordData(RecordData e) {
  if (flatbuffers::IsOutRange(
          e, RecordData_NONE, RecordData_TensorCreationSymbolic))
    return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesRecordData()[index];
}

template <typename T>
struct RecordDataTraits {
  static const RecordData enum_value = RecordData_NONE;
};

template <>
struct RecordDataTraits<nvfuser::serde::BatchNorm> {
  static const RecordData enum_value = RecordData_BatchNorm;
};

template <>
struct RecordDataTraits<nvfuser::serde::Bool> {
  static const RecordData enum_value = RecordData_Bool;
};

template <>
struct RecordDataTraits<nvfuser::serde::Broadcast> {
  static const RecordData enum_value = RecordData_Broadcast;
};

template <>
struct RecordDataTraits<nvfuser::serde::BroadcastInDim> {
  static const RecordData enum_value = RecordData_BroadcastInDim;
};

template <>
struct RecordDataTraits<nvfuser::serde::BroadcastInDimSymbolic> {
  static const RecordData enum_value = RecordData_BroadcastInDimSymbolic;
};

template <>
struct RecordDataTraits<nvfuser::serde::ComplexDouble> {
  static const RecordData enum_value = RecordData_ComplexDouble;
};

template <>
struct RecordDataTraits<nvfuser::serde::Double> {
  static const RecordData enum_value = RecordData_Double;
};

template <>
struct RecordDataTraits<nvfuser::serde::Dtype> {
  static const RecordData enum_value = RecordData_Dtype;
};

template <>
struct RecordDataTraits<nvfuser::serde::Dimension> {
  static const RecordData enum_value = RecordData_Dimension;
};

template <>
struct RecordDataTraits<nvfuser::serde::Int> {
  static const RecordData enum_value = RecordData_Int;
};

template <>
struct RecordDataTraits<nvfuser::serde::Norm> {
  static const RecordData enum_value = RecordData_Norm;
};

template <>
struct RecordDataTraits<nvfuser::serde::Output> {
  static const RecordData enum_value = RecordData_Output;
};

template <>
struct RecordDataTraits<nvfuser::serde::Pad> {
  static const RecordData enum_value = RecordData_Pad;
};

template <>
struct RecordDataTraits<nvfuser::serde::Permute> {
  static const RecordData enum_value = RecordData_Permute;
};

template <>
struct RecordDataTraits<nvfuser::serde::Slice> {
  static const RecordData enum_value = RecordData_Slice;
};

template <>
struct RecordDataTraits<nvfuser::serde::Squeeze> {
  static const RecordData enum_value = RecordData_Squeeze;
};

template <>
struct RecordDataTraits<nvfuser::serde::Reduction> {
  static const RecordData enum_value = RecordData_Reduction;
};

template <>
struct RecordDataTraits<nvfuser::serde::Reshape> {
  static const RecordData enum_value = RecordData_Reshape;
};

template <>
struct RecordDataTraits<nvfuser::serde::Tensor> {
  static const RecordData enum_value = RecordData_Tensor;
};

template <>
struct RecordDataTraits<nvfuser::serde::TensorCreation> {
  static const RecordData enum_value = RecordData_TensorCreation;
};

template <>
struct RecordDataTraits<nvfuser::serde::TensorCreationSymbolic> {
  static const RecordData enum_value = RecordData_TensorCreationSymbolic;
};

bool VerifyRecordData(
    flatbuffers::Verifier& verifier,
    const void* obj,
    RecordData type);
bool VerifyRecordDataVector(
    flatbuffers::Verifier& verifier,
    const flatbuffers::Vector<flatbuffers::Offset<void>>* values,
    const flatbuffers::Vector<uint8_t>* types);

FLATBUFFERS_MANUALLY_ALIGNED_STRUCT(4) State FLATBUFFERS_FINAL_CLASS {
 private:
  int32_t index_;
  int32_t type_;

 public:
  State() : index_(0), type_(0) {}
  State(int32_t _index, nvfuser::serde::StateType _type)
      : index_(flatbuffers::EndianScalar(_index)),
        type_(flatbuffers::EndianScalar(static_cast<int32_t>(_type))) {}
  int32_t index() const {
    return flatbuffers::EndianScalar(index_);
  }
  nvfuser::serde::StateType type() const {
    return static_cast<nvfuser::serde::StateType>(
        flatbuffers::EndianScalar(type_));
  }
};
FLATBUFFERS_STRUCT_END(State, 8);

struct Bool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef BoolBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BOOL_VAL = 4
  };
  bool bool_val() const {
    return GetField<uint8_t>(VT_BOOL_VAL, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<uint8_t>(verifier, VT_BOOL_VAL, 1) && verifier.EndTable();
  }
};

struct BoolBuilder {
  typedef Bool Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_bool_val(bool bool_val) {
    fbb_.AddElement<uint8_t>(
        Bool::VT_BOOL_VAL, static_cast<uint8_t>(bool_val), 0);
  }
  explicit BoolBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Bool> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Bool>(end);
    return o;
  }
};

inline flatbuffers::Offset<Bool> CreateBool(
    flatbuffers::FlatBufferBuilder& _fbb,
    bool bool_val = false) {
  BoolBuilder builder_(_fbb);
  builder_.add_bool_val(bool_val);
  return builder_.Finish();
}

struct Double FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef DoubleBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DOUBLE_VAL = 4,
    VT_DTYPE = 6
  };
  double double_val() const {
    return GetField<double>(VT_DOUBLE_VAL, 0.0);
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<double>(verifier, VT_DOUBLE_VAL, 8) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct DoubleBuilder {
  typedef Double Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_double_val(double double_val) {
    fbb_.AddElement<double>(Double::VT_DOUBLE_VAL, double_val, 0.0);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(Double::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit DoubleBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Double> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Double>(end);
    return o;
  }
};

inline flatbuffers::Offset<Double> CreateDouble(
    flatbuffers::FlatBufferBuilder& _fbb,
    double double_val = 0.0,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  DoubleBuilder builder_(_fbb);
  builder_.add_double_val(double_val);
  builder_.add_dtype(dtype);
  return builder_.Finish();
}

struct Int FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef IntBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INT_VAL = 4,
    VT_DTYPE = 6
  };
  int64_t int_val() const {
    return GetField<int64_t>(VT_INT_VAL, 0);
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<int64_t>(verifier, VT_INT_VAL, 8) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct IntBuilder {
  typedef Int Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_int_val(int64_t int_val) {
    fbb_.AddElement<int64_t>(Int::VT_INT_VAL, int_val, 0);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(Int::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit IntBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Int> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Int>(end);
    return o;
  }
};

inline flatbuffers::Offset<Int> CreateInt(
    flatbuffers::FlatBufferBuilder& _fbb,
    int64_t int_val = 0,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  IntBuilder builder_(_fbb);
  builder_.add_int_val(int_val);
  builder_.add_dtype(dtype);
  return builder_.Finish();
}

struct BatchNorm FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef BatchNormBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TRAINING = 4,
    VT_CHANNELS_LAST = 6
  };
  bool training() const {
    return GetField<uint8_t>(VT_TRAINING, 0) != 0;
  }
  bool channels_last() const {
    return GetField<uint8_t>(VT_CHANNELS_LAST, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<uint8_t>(verifier, VT_TRAINING, 1) &&
        VerifyField<uint8_t>(verifier, VT_CHANNELS_LAST, 1) &&
        verifier.EndTable();
  }
};

struct BatchNormBuilder {
  typedef BatchNorm Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_training(bool training) {
    fbb_.AddElement<uint8_t>(
        BatchNorm::VT_TRAINING, static_cast<uint8_t>(training), 0);
  }
  void add_channels_last(bool channels_last) {
    fbb_.AddElement<uint8_t>(
        BatchNorm::VT_CHANNELS_LAST, static_cast<uint8_t>(channels_last), 0);
  }
  explicit BatchNormBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<BatchNorm> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<BatchNorm>(end);
    return o;
  }
};

inline flatbuffers::Offset<BatchNorm> CreateBatchNorm(
    flatbuffers::FlatBufferBuilder& _fbb,
    bool training = false,
    bool channels_last = false) {
  BatchNormBuilder builder_(_fbb);
  builder_.add_channels_last(channels_last);
  builder_.add_training(training);
  return builder_.Finish();
}

struct Broadcast FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef BroadcastBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BROADCAST_DIMS = 4
  };
  const flatbuffers::Vector<uint8_t>* broadcast_dims() const {
    return GetPointer<const flatbuffers::Vector<uint8_t>*>(VT_BROADCAST_DIMS);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_BROADCAST_DIMS) &&
        verifier.VerifyVector(broadcast_dims()) && verifier.EndTable();
  }
};

struct BroadcastBuilder {
  typedef Broadcast Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_broadcast_dims(
      flatbuffers::Offset<flatbuffers::Vector<uint8_t>> broadcast_dims) {
    fbb_.AddOffset(Broadcast::VT_BROADCAST_DIMS, broadcast_dims);
  }
  explicit BroadcastBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Broadcast> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Broadcast>(end);
    return o;
  }
};

inline flatbuffers::Offset<Broadcast> CreateBroadcast(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> broadcast_dims = 0) {
  BroadcastBuilder builder_(_fbb);
  builder_.add_broadcast_dims(broadcast_dims);
  return builder_.Finish();
}

inline flatbuffers::Offset<Broadcast> CreateBroadcastDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<uint8_t>* broadcast_dims = nullptr) {
  auto broadcast_dims__ =
      broadcast_dims ? _fbb.CreateVector<uint8_t>(*broadcast_dims) : 0;
  return nvfuser::serde::CreateBroadcast(_fbb, broadcast_dims__);
}

struct BroadcastInDim FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef BroadcastInDimBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OUTPUT_SHAPE = 4,
    VT_BROADCAST_DIMS = 6
  };
  const flatbuffers::Vector<int64_t>* output_shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_OUTPUT_SHAPE);
  }
  const flatbuffers::Vector<int64_t>* broadcast_dims() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_BROADCAST_DIMS);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_OUTPUT_SHAPE) &&
        verifier.VerifyVector(output_shape()) &&
        VerifyOffset(verifier, VT_BROADCAST_DIMS) &&
        verifier.VerifyVector(broadcast_dims()) && verifier.EndTable();
  }
};

struct BroadcastInDimBuilder {
  typedef BroadcastInDim Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_output_shape(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> output_shape) {
    fbb_.AddOffset(BroadcastInDim::VT_OUTPUT_SHAPE, output_shape);
  }
  void add_broadcast_dims(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> broadcast_dims) {
    fbb_.AddOffset(BroadcastInDim::VT_BROADCAST_DIMS, broadcast_dims);
  }
  explicit BroadcastInDimBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<BroadcastInDim> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<BroadcastInDim>(end);
    return o;
  }
};

inline flatbuffers::Offset<BroadcastInDim> CreateBroadcastInDim(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> output_shape = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> broadcast_dims = 0) {
  BroadcastInDimBuilder builder_(_fbb);
  builder_.add_broadcast_dims(broadcast_dims);
  builder_.add_output_shape(output_shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<BroadcastInDim> CreateBroadcastInDimDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* output_shape = nullptr,
    const std::vector<int64_t>* broadcast_dims = nullptr) {
  auto output_shape__ =
      output_shape ? _fbb.CreateVector<int64_t>(*output_shape) : 0;
  auto broadcast_dims__ =
      broadcast_dims ? _fbb.CreateVector<int64_t>(*broadcast_dims) : 0;
  return nvfuser::serde::CreateBroadcastInDim(
      _fbb, output_shape__, broadcast_dims__);
}

struct BroadcastInDimSymbolic FLATBUFFERS_FINAL_CLASS
    : private flatbuffers::Table {
  typedef BroadcastInDimSymbolicBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OUTPUT_SHAPE = 4,
    VT_BROADCAST_DIMS = 6
  };
  const flatbuffers::Vector<const nvfuser::serde::State*>* output_shape()
      const {
    return GetPointer<const flatbuffers::Vector<const nvfuser::serde::State*>*>(
        VT_OUTPUT_SHAPE);
  }
  const flatbuffers::Vector<int64_t>* broadcast_dims() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_BROADCAST_DIMS);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_OUTPUT_SHAPE) &&
        verifier.VerifyVector(output_shape()) &&
        VerifyOffset(verifier, VT_BROADCAST_DIMS) &&
        verifier.VerifyVector(broadcast_dims()) && verifier.EndTable();
  }
};

struct BroadcastInDimSymbolicBuilder {
  typedef BroadcastInDimSymbolic Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_output_shape(
      flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
          output_shape) {
    fbb_.AddOffset(BroadcastInDimSymbolic::VT_OUTPUT_SHAPE, output_shape);
  }
  void add_broadcast_dims(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> broadcast_dims) {
    fbb_.AddOffset(BroadcastInDimSymbolic::VT_BROADCAST_DIMS, broadcast_dims);
  }
  explicit BroadcastInDimSymbolicBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<BroadcastInDimSymbolic> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<BroadcastInDimSymbolic>(end);
    return o;
  }
};

inline flatbuffers::Offset<BroadcastInDimSymbolic> CreateBroadcastInDimSymbolic(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
        output_shape = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> broadcast_dims = 0) {
  BroadcastInDimSymbolicBuilder builder_(_fbb);
  builder_.add_broadcast_dims(broadcast_dims);
  builder_.add_output_shape(output_shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<BroadcastInDimSymbolic>
CreateBroadcastInDimSymbolicDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<nvfuser::serde::State>* output_shape = nullptr,
    const std::vector<int64_t>* broadcast_dims = nullptr) {
  auto output_shape__ = output_shape
      ? _fbb.CreateVectorOfStructs<nvfuser::serde::State>(*output_shape)
      : 0;
  auto broadcast_dims__ =
      broadcast_dims ? _fbb.CreateVector<int64_t>(*broadcast_dims) : 0;
  return nvfuser::serde::CreateBroadcastInDimSymbolic(
      _fbb, output_shape__, broadcast_dims__);
}

struct ComplexDouble FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ComplexDoubleBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_REAL = 4,
    VT_IMAG = 6,
    VT_DTYPE = 8
  };
  double real() const {
    return GetField<double>(VT_REAL, 0.0);
  }
  double imag() const {
    return GetField<double>(VT_IMAG, 0.0);
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<double>(verifier, VT_REAL, 8) &&
        VerifyField<double>(verifier, VT_IMAG, 8) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct ComplexDoubleBuilder {
  typedef ComplexDouble Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_real(double real) {
    fbb_.AddElement<double>(ComplexDouble::VT_REAL, real, 0.0);
  }
  void add_imag(double imag) {
    fbb_.AddElement<double>(ComplexDouble::VT_IMAG, imag, 0.0);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(
        ComplexDouble::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit ComplexDoubleBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<ComplexDouble> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<ComplexDouble>(end);
    return o;
  }
};

inline flatbuffers::Offset<ComplexDouble> CreateComplexDouble(
    flatbuffers::FlatBufferBuilder& _fbb,
    double real = 0.0,
    double imag = 0.0,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  ComplexDoubleBuilder builder_(_fbb);
  builder_.add_imag(imag);
  builder_.add_real(real);
  builder_.add_dtype(dtype);
  return builder_.Finish();
}

struct Dtype FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef DtypeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DTYPE = 4
  };
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct DtypeBuilder {
  typedef Dtype Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(Dtype::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit DtypeBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Dtype> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Dtype>(end);
    return o;
  }
};

inline flatbuffers::Offset<Dtype> CreateDtype(
    flatbuffers::FlatBufferBuilder& _fbb,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  DtypeBuilder builder_(_fbb);
  builder_.add_dtype(dtype);
  return builder_.Finish();
}

struct Dimension FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef DimensionBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DIM = 4
  };
  int64_t dim() const {
    return GetField<int64_t>(VT_DIM, 0);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<int64_t>(verifier, VT_DIM, 8) && verifier.EndTable();
  }
};

struct DimensionBuilder {
  typedef Dimension Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_dim(int64_t dim) {
    fbb_.AddElement<int64_t>(Dimension::VT_DIM, dim, 0);
  }
  explicit DimensionBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Dimension> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Dimension>(end);
    return o;
  }
};

inline flatbuffers::Offset<Dimension> CreateDimension(
    flatbuffers::FlatBufferBuilder& _fbb,
    int64_t dim = 0) {
  DimensionBuilder builder_(_fbb);
  builder_.add_dim(dim);
  return builder_.Finish();
}

struct Norm FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NormBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_AXES = 4,
    VT_CORRECTION = 6,
    VT_KEEP_DIM = 8
  };
  const flatbuffers::Vector<int32_t>* axes() const {
    return GetPointer<const flatbuffers::Vector<int32_t>*>(VT_AXES);
  }
  int64_t correction() const {
    return GetField<int64_t>(VT_CORRECTION, 0);
  }
  bool keep_dim() const {
    return GetField<uint8_t>(VT_KEEP_DIM, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_AXES) &&
        verifier.VerifyVector(axes()) &&
        VerifyField<int64_t>(verifier, VT_CORRECTION, 8) &&
        VerifyField<uint8_t>(verifier, VT_KEEP_DIM, 1) && verifier.EndTable();
  }
};

struct NormBuilder {
  typedef Norm Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_axes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> axes) {
    fbb_.AddOffset(Norm::VT_AXES, axes);
  }
  void add_correction(int64_t correction) {
    fbb_.AddElement<int64_t>(Norm::VT_CORRECTION, correction, 0);
  }
  void add_keep_dim(bool keep_dim) {
    fbb_.AddElement<uint8_t>(
        Norm::VT_KEEP_DIM, static_cast<uint8_t>(keep_dim), 0);
  }
  explicit NormBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Norm> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Norm>(end);
    return o;
  }
};

inline flatbuffers::Offset<Norm> CreateNorm(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> axes = 0,
    int64_t correction = 0,
    bool keep_dim = false) {
  NormBuilder builder_(_fbb);
  builder_.add_correction(correction);
  builder_.add_axes(axes);
  builder_.add_keep_dim(keep_dim);
  return builder_.Finish();
}

inline flatbuffers::Offset<Norm> CreateNormDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int32_t>* axes = nullptr,
    int64_t correction = 0,
    bool keep_dim = false) {
  auto axes__ = axes ? _fbb.CreateVector<int32_t>(*axes) : 0;
  return nvfuser::serde::CreateNorm(_fbb, axes__, correction, keep_dim);
}

struct Output FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef OutputBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_STRIDE_ORDER = 4
  };
  const flatbuffers::Vector<int64_t>* stride_order() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_STRIDE_ORDER);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_STRIDE_ORDER) &&
        verifier.VerifyVector(stride_order()) && verifier.EndTable();
  }
};

struct OutputBuilder {
  typedef Output Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_stride_order(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> stride_order) {
    fbb_.AddOffset(Output::VT_STRIDE_ORDER, stride_order);
  }
  explicit OutputBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Output> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Output>(end);
    return o;
  }
};

inline flatbuffers::Offset<Output> CreateOutput(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> stride_order = 0) {
  OutputBuilder builder_(_fbb);
  builder_.add_stride_order(stride_order);
  return builder_.Finish();
}

inline flatbuffers::Offset<Output> CreateOutputDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* stride_order = nullptr) {
  auto stride_order__ =
      stride_order ? _fbb.CreateVector<int64_t>(*stride_order) : 0;
  return nvfuser::serde::CreateOutput(_fbb, stride_order__);
}

struct Pad FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef PadBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_PAD_WIDTHS = 4
  };
  const flatbuffers::Vector<int64_t>* pad_widths() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_PAD_WIDTHS);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_PAD_WIDTHS) &&
        verifier.VerifyVector(pad_widths()) && verifier.EndTable();
  }
};

struct PadBuilder {
  typedef Pad Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_pad_widths(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> pad_widths) {
    fbb_.AddOffset(Pad::VT_PAD_WIDTHS, pad_widths);
  }
  explicit PadBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Pad> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Pad>(end);
    return o;
  }
};

inline flatbuffers::Offset<Pad> CreatePad(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> pad_widths = 0) {
  PadBuilder builder_(_fbb);
  builder_.add_pad_widths(pad_widths);
  return builder_.Finish();
}

inline flatbuffers::Offset<Pad> CreatePadDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* pad_widths = nullptr) {
  auto pad_widths__ = pad_widths ? _fbb.CreateVector<int64_t>(*pad_widths) : 0;
  return nvfuser::serde::CreatePad(_fbb, pad_widths__);
}

struct Permute FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef PermuteBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DIMS = 4
  };
  const flatbuffers::Vector<int64_t>* dims() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_DIMS);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_DIMS) &&
        verifier.VerifyVector(dims()) && verifier.EndTable();
  }
};

struct PermuteBuilder {
  typedef Permute Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_dims(flatbuffers::Offset<flatbuffers::Vector<int64_t>> dims) {
    fbb_.AddOffset(Permute::VT_DIMS, dims);
  }
  explicit PermuteBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Permute> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Permute>(end);
    return o;
  }
};

inline flatbuffers::Offset<Permute> CreatePermute(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> dims = 0) {
  PermuteBuilder builder_(_fbb);
  builder_.add_dims(dims);
  return builder_.Finish();
}

inline flatbuffers::Offset<Permute> CreatePermuteDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* dims = nullptr) {
  auto dims__ = dims ? _fbb.CreateVector<int64_t>(*dims) : 0;
  return nvfuser::serde::CreatePermute(_fbb, dims__);
}

struct Reduction FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ReductionBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_AXES = 4,
    VT_KEEP_DIM = 6,
    VT_DTYPE = 8
  };
  const flatbuffers::Vector<int32_t>* axes() const {
    return GetPointer<const flatbuffers::Vector<int32_t>*>(VT_AXES);
  }
  bool keep_dim() const {
    return GetField<uint8_t>(VT_KEEP_DIM, 0) != 0;
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_AXES) &&
        verifier.VerifyVector(axes()) &&
        VerifyField<uint8_t>(verifier, VT_KEEP_DIM, 1) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct ReductionBuilder {
  typedef Reduction Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_axes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> axes) {
    fbb_.AddOffset(Reduction::VT_AXES, axes);
  }
  void add_keep_dim(bool keep_dim) {
    fbb_.AddElement<uint8_t>(
        Reduction::VT_KEEP_DIM, static_cast<uint8_t>(keep_dim), 0);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(
        Reduction::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit ReductionBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Reduction> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Reduction>(end);
    return o;
  }
};

inline flatbuffers::Offset<Reduction> CreateReduction(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> axes = 0,
    bool keep_dim = false,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  ReductionBuilder builder_(_fbb);
  builder_.add_dtype(dtype);
  builder_.add_axes(axes);
  builder_.add_keep_dim(keep_dim);
  return builder_.Finish();
}

inline flatbuffers::Offset<Reduction> CreateReductionDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int32_t>* axes = nullptr,
    bool keep_dim = false,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  auto axes__ = axes ? _fbb.CreateVector<int32_t>(*axes) : 0;
  return nvfuser::serde::CreateReduction(_fbb, axes__, keep_dim, dtype);
}

struct Reshape FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ReshapeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ORIGINAL_SHAPE = 4,
    VT_NEW_SHAPE = 6
  };
  const flatbuffers::Vector<int64_t>* original_shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_ORIGINAL_SHAPE);
  }
  const flatbuffers::Vector<int64_t>* new_shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_NEW_SHAPE);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_ORIGINAL_SHAPE) &&
        verifier.VerifyVector(original_shape()) &&
        VerifyOffset(verifier, VT_NEW_SHAPE) &&
        verifier.VerifyVector(new_shape()) && verifier.EndTable();
  }
};

struct ReshapeBuilder {
  typedef Reshape Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_original_shape(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> original_shape) {
    fbb_.AddOffset(Reshape::VT_ORIGINAL_SHAPE, original_shape);
  }
  void add_new_shape(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> new_shape) {
    fbb_.AddOffset(Reshape::VT_NEW_SHAPE, new_shape);
  }
  explicit ReshapeBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Reshape> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Reshape>(end);
    return o;
  }
};

inline flatbuffers::Offset<Reshape> CreateReshape(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> original_shape = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> new_shape = 0) {
  ReshapeBuilder builder_(_fbb);
  builder_.add_new_shape(new_shape);
  builder_.add_original_shape(original_shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<Reshape> CreateReshapeDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* original_shape = nullptr,
    const std::vector<int64_t>* new_shape = nullptr) {
  auto original_shape__ =
      original_shape ? _fbb.CreateVector<int64_t>(*original_shape) : 0;
  auto new_shape__ = new_shape ? _fbb.CreateVector<int64_t>(*new_shape) : 0;
  return nvfuser::serde::CreateReshape(_fbb, original_shape__, new_shape__);
}

struct Slice FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SliceBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_START_INDICES = 4,
    VT_END_INDICES = 6,
    VT_STRIDES = 8
  };
  const flatbuffers::Vector<int64_t>* start_indices() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_START_INDICES);
  }
  const flatbuffers::Vector<int64_t>* end_indices() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_END_INDICES);
  }
  const flatbuffers::Vector<int64_t>* strides() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_STRIDES);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_START_INDICES) &&
        verifier.VerifyVector(start_indices()) &&
        VerifyOffset(verifier, VT_END_INDICES) &&
        verifier.VerifyVector(end_indices()) &&
        VerifyOffset(verifier, VT_STRIDES) &&
        verifier.VerifyVector(strides()) && verifier.EndTable();
  }
};

struct SliceBuilder {
  typedef Slice Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_start_indices(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> start_indices) {
    fbb_.AddOffset(Slice::VT_START_INDICES, start_indices);
  }
  void add_end_indices(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> end_indices) {
    fbb_.AddOffset(Slice::VT_END_INDICES, end_indices);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int64_t>> strides) {
    fbb_.AddOffset(Slice::VT_STRIDES, strides);
  }
  explicit SliceBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Slice> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Slice>(end);
    return o;
  }
};

inline flatbuffers::Offset<Slice> CreateSlice(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> start_indices = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> end_indices = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> strides = 0) {
  SliceBuilder builder_(_fbb);
  builder_.add_strides(strides);
  builder_.add_end_indices(end_indices);
  builder_.add_start_indices(start_indices);
  return builder_.Finish();
}

inline flatbuffers::Offset<Slice> CreateSliceDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* start_indices = nullptr,
    const std::vector<int64_t>* end_indices = nullptr,
    const std::vector<int64_t>* strides = nullptr) {
  auto start_indices__ =
      start_indices ? _fbb.CreateVector<int64_t>(*start_indices) : 0;
  auto end_indices__ =
      end_indices ? _fbb.CreateVector<int64_t>(*end_indices) : 0;
  auto strides__ = strides ? _fbb.CreateVector<int64_t>(*strides) : 0;
  return nvfuser::serde::CreateSlice(
      _fbb, start_indices__, end_indices__, strides__);
}

struct Squeeze FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SqueezeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ORIGINAL_SHAPE = 4,
    VT_SQUEEZE_DIMS = 6
  };
  const flatbuffers::Vector<int64_t>* original_shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_ORIGINAL_SHAPE);
  }
  const flatbuffers::Vector<int64_t>* squeeze_dims() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_SQUEEZE_DIMS);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyOffset(verifier, VT_ORIGINAL_SHAPE) &&
        verifier.VerifyVector(original_shape()) &&
        VerifyOffset(verifier, VT_SQUEEZE_DIMS) &&
        verifier.VerifyVector(squeeze_dims()) && verifier.EndTable();
  }
};

struct SqueezeBuilder {
  typedef Squeeze Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_original_shape(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> original_shape) {
    fbb_.AddOffset(Squeeze::VT_ORIGINAL_SHAPE, original_shape);
  }
  void add_squeeze_dims(
      flatbuffers::Offset<flatbuffers::Vector<int64_t>> squeeze_dims) {
    fbb_.AddOffset(Squeeze::VT_SQUEEZE_DIMS, squeeze_dims);
  }
  explicit SqueezeBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Squeeze> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Squeeze>(end);
    return o;
  }
};

inline flatbuffers::Offset<Squeeze> CreateSqueeze(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> original_shape = 0,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> squeeze_dims = 0) {
  SqueezeBuilder builder_(_fbb);
  builder_.add_squeeze_dims(squeeze_dims);
  builder_.add_original_shape(original_shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<Squeeze> CreateSqueezeDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* original_shape = nullptr,
    const std::vector<int64_t>* squeeze_dims = nullptr) {
  auto original_shape__ =
      original_shape ? _fbb.CreateVector<int64_t>(*original_shape) : 0;
  auto squeeze_dims__ =
      squeeze_dims ? _fbb.CreateVector<int64_t>(*squeeze_dims) : 0;
  return nvfuser::serde::CreateSqueeze(_fbb, original_shape__, squeeze_dims__);
}

struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SIZES = 4,
    VT_CONTIGUITY = 6,
    VT_DTYPE = 8,
    VT_IS_CPU = 10
  };
  const flatbuffers::Vector<int64_t>* sizes() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_SIZES);
  }
  const flatbuffers::Vector<int32_t>* contiguity() const {
    return GetPointer<const flatbuffers::Vector<int32_t>*>(VT_CONTIGUITY);
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool is_cpu() const {
    return GetField<uint8_t>(VT_IS_CPU, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_SIZES) &&
        verifier.VerifyVector(sizes()) &&
        VerifyOffset(verifier, VT_CONTIGUITY) &&
        verifier.VerifyVector(contiguity()) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) &&
        VerifyField<uint8_t>(verifier, VT_IS_CPU, 1) && verifier.EndTable();
  }
};

struct TensorBuilder {
  typedef Tensor Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_sizes(flatbuffers::Offset<flatbuffers::Vector<int64_t>> sizes) {
    fbb_.AddOffset(Tensor::VT_SIZES, sizes);
  }
  void add_contiguity(
      flatbuffers::Offset<flatbuffers::Vector<int32_t>> contiguity) {
    fbb_.AddOffset(Tensor::VT_CONTIGUITY, contiguity);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(Tensor::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  void add_is_cpu(bool is_cpu) {
    fbb_.AddElement<uint8_t>(
        Tensor::VT_IS_CPU, static_cast<uint8_t>(is_cpu), 0);
  }
  explicit TensorBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensor>(end);
    return o;
  }
};

inline flatbuffers::Offset<Tensor> CreateTensor(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> sizes = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> contiguity = 0,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double,
    bool is_cpu = false) {
  TensorBuilder builder_(_fbb);
  builder_.add_dtype(dtype);
  builder_.add_contiguity(contiguity);
  builder_.add_sizes(sizes);
  builder_.add_is_cpu(is_cpu);
  return builder_.Finish();
}

inline flatbuffers::Offset<Tensor> CreateTensorDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* sizes = nullptr,
    const std::vector<int32_t>* contiguity = nullptr,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double,
    bool is_cpu = false) {
  auto sizes__ = sizes ? _fbb.CreateVector<int64_t>(*sizes) : 0;
  auto contiguity__ = contiguity ? _fbb.CreateVector<int32_t>(*contiguity) : 0;
  return nvfuser::serde::CreateTensor(
      _fbb, sizes__, contiguity__, dtype, is_cpu);
}

struct TensorCreation FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorCreationBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SHAPE = 4,
    VT_DTYPE = 6
  };
  const flatbuffers::Vector<int64_t>* shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t>*>(VT_SHAPE);
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_SHAPE) &&
        verifier.VerifyVector(shape()) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct TensorCreationBuilder {
  typedef TensorCreation Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_shape(flatbuffers::Offset<flatbuffers::Vector<int64_t>> shape) {
    fbb_.AddOffset(TensorCreation::VT_SHAPE, shape);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(
        TensorCreation::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit TensorCreationBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<TensorCreation> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorCreation>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorCreation> CreateTensorCreation(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<int64_t>> shape = 0,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  TensorCreationBuilder builder_(_fbb);
  builder_.add_dtype(dtype);
  builder_.add_shape(shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<TensorCreation> CreateTensorCreationDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<int64_t>* shape = nullptr,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  auto shape__ = shape ? _fbb.CreateVector<int64_t>(*shape) : 0;
  return nvfuser::serde::CreateTensorCreation(_fbb, shape__, dtype);
}

struct TensorCreationSymbolic FLATBUFFERS_FINAL_CLASS
    : private flatbuffers::Table {
  typedef TensorCreationSymbolicBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SHAPE = 4,
    VT_DTYPE = 6
  };
  const flatbuffers::Vector<const nvfuser::serde::State*>* shape() const {
    return GetPointer<const flatbuffers::Vector<const nvfuser::serde::State*>*>(
        VT_SHAPE);
  }
  nvfuser::serde::DataType dtype() const {
    return static_cast<nvfuser::serde::DataType>(
        GetField<int32_t>(VT_DTYPE, 0));
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_SHAPE) &&
        verifier.VerifyVector(shape()) &&
        VerifyField<int32_t>(verifier, VT_DTYPE, 4) && verifier.EndTable();
  }
};

struct TensorCreationSymbolicBuilder {
  typedef TensorCreationSymbolic Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_shape(
      flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
          shape) {
    fbb_.AddOffset(TensorCreationSymbolic::VT_SHAPE, shape);
  }
  void add_dtype(nvfuser::serde::DataType dtype) {
    fbb_.AddElement<int32_t>(
        TensorCreationSymbolic::VT_DTYPE, static_cast<int32_t>(dtype), 0);
  }
  explicit TensorCreationSymbolicBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<TensorCreationSymbolic> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorCreationSymbolic>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorCreationSymbolic> CreateTensorCreationSymbolic(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
        shape = 0,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  TensorCreationSymbolicBuilder builder_(_fbb);
  builder_.add_dtype(dtype);
  builder_.add_shape(shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<TensorCreationSymbolic>
CreateTensorCreationSymbolicDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<nvfuser::serde::State>* shape = nullptr,
    nvfuser::serde::DataType dtype = nvfuser::serde::DataType_Double) {
  auto shape__ =
      shape ? _fbb.CreateVectorOfStructs<nvfuser::serde::State>(*shape) : 0;
  return nvfuser::serde::CreateTensorCreationSymbolic(_fbb, shape__, dtype);
}

struct RecordFunctor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef RecordFunctorBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ARGS = 4,
    VT_OUTPUTS = 6,
    VT_NAME = 8,
    VT_TYPE = 10,
    VT_DATA_TYPE = 12,
    VT_DATA = 14
  };
  const flatbuffers::Vector<const nvfuser::serde::State*>* args() const {
    return GetPointer<const flatbuffers::Vector<const nvfuser::serde::State*>*>(
        VT_ARGS);
  }
  const flatbuffers::Vector<const nvfuser::serde::State*>* outputs() const {
    return GetPointer<const flatbuffers::Vector<const nvfuser::serde::State*>*>(
        VT_OUTPUTS);
  }
  const flatbuffers::String* name() const {
    return GetPointer<const flatbuffers::String*>(VT_NAME);
  }
  nvfuser::serde::RecordType type() const {
    return static_cast<nvfuser::serde::RecordType>(
        GetField<int32_t>(VT_TYPE, 0));
  }
  nvfuser::serde::RecordData data_type() const {
    return static_cast<nvfuser::serde::RecordData>(
        GetField<uint8_t>(VT_DATA_TYPE, 0));
  }
  const void* data() const {
    return GetPointer<const void*>(VT_DATA);
  }
  template <typename T>
  const T* data_as() const;
  const nvfuser::serde::BatchNorm* data_as_BatchNorm() const {
    return data_type() == nvfuser::serde::RecordData_BatchNorm
        ? static_cast<const nvfuser::serde::BatchNorm*>(data())
        : nullptr;
  }
  const nvfuser::serde::Bool* data_as_Bool() const {
    return data_type() == nvfuser::serde::RecordData_Bool
        ? static_cast<const nvfuser::serde::Bool*>(data())
        : nullptr;
  }
  const nvfuser::serde::Broadcast* data_as_Broadcast() const {
    return data_type() == nvfuser::serde::RecordData_Broadcast
        ? static_cast<const nvfuser::serde::Broadcast*>(data())
        : nullptr;
  }
  const nvfuser::serde::BroadcastInDim* data_as_BroadcastInDim() const {
    return data_type() == nvfuser::serde::RecordData_BroadcastInDim
        ? static_cast<const nvfuser::serde::BroadcastInDim*>(data())
        : nullptr;
  }
  const nvfuser::serde::BroadcastInDimSymbolic* data_as_BroadcastInDimSymbolic()
      const {
    return data_type() == nvfuser::serde::RecordData_BroadcastInDimSymbolic
        ? static_cast<const nvfuser::serde::BroadcastInDimSymbolic*>(data())
        : nullptr;
  }
  const nvfuser::serde::ComplexDouble* data_as_ComplexDouble() const {
    return data_type() == nvfuser::serde::RecordData_ComplexDouble
        ? static_cast<const nvfuser::serde::ComplexDouble*>(data())
        : nullptr;
  }
  const nvfuser::serde::Double* data_as_Double() const {
    return data_type() == nvfuser::serde::RecordData_Double
        ? static_cast<const nvfuser::serde::Double*>(data())
        : nullptr;
  }
  const nvfuser::serde::Dtype* data_as_Dtype() const {
    return data_type() == nvfuser::serde::RecordData_Dtype
        ? static_cast<const nvfuser::serde::Dtype*>(data())
        : nullptr;
  }
  const nvfuser::serde::Dimension* data_as_Dimension() const {
    return data_type() == nvfuser::serde::RecordData_Dimension
        ? static_cast<const nvfuser::serde::Dimension*>(data())
        : nullptr;
  }
  const nvfuser::serde::Int* data_as_Int() const {
    return data_type() == nvfuser::serde::RecordData_Int
        ? static_cast<const nvfuser::serde::Int*>(data())
        : nullptr;
  }
  const nvfuser::serde::Norm* data_as_Norm() const {
    return data_type() == nvfuser::serde::RecordData_Norm
        ? static_cast<const nvfuser::serde::Norm*>(data())
        : nullptr;
  }
  const nvfuser::serde::Output* data_as_Output() const {
    return data_type() == nvfuser::serde::RecordData_Output
        ? static_cast<const nvfuser::serde::Output*>(data())
        : nullptr;
  }
  const nvfuser::serde::Pad* data_as_Pad() const {
    return data_type() == nvfuser::serde::RecordData_Pad
        ? static_cast<const nvfuser::serde::Pad*>(data())
        : nullptr;
  }
  const nvfuser::serde::Permute* data_as_Permute() const {
    return data_type() == nvfuser::serde::RecordData_Permute
        ? static_cast<const nvfuser::serde::Permute*>(data())
        : nullptr;
  }
  const nvfuser::serde::Slice* data_as_Slice() const {
    return data_type() == nvfuser::serde::RecordData_Slice
        ? static_cast<const nvfuser::serde::Slice*>(data())
        : nullptr;
  }
  const nvfuser::serde::Squeeze* data_as_Squeeze() const {
    return data_type() == nvfuser::serde::RecordData_Squeeze
        ? static_cast<const nvfuser::serde::Squeeze*>(data())
        : nullptr;
  }
  const nvfuser::serde::Reduction* data_as_Reduction() const {
    return data_type() == nvfuser::serde::RecordData_Reduction
        ? static_cast<const nvfuser::serde::Reduction*>(data())
        : nullptr;
  }
  const nvfuser::serde::Reshape* data_as_Reshape() const {
    return data_type() == nvfuser::serde::RecordData_Reshape
        ? static_cast<const nvfuser::serde::Reshape*>(data())
        : nullptr;
  }
  const nvfuser::serde::Tensor* data_as_Tensor() const {
    return data_type() == nvfuser::serde::RecordData_Tensor
        ? static_cast<const nvfuser::serde::Tensor*>(data())
        : nullptr;
  }
  const nvfuser::serde::TensorCreation* data_as_TensorCreation() const {
    return data_type() == nvfuser::serde::RecordData_TensorCreation
        ? static_cast<const nvfuser::serde::TensorCreation*>(data())
        : nullptr;
  }
  const nvfuser::serde::TensorCreationSymbolic* data_as_TensorCreationSymbolic()
      const {
    return data_type() == nvfuser::serde::RecordData_TensorCreationSymbolic
        ? static_cast<const nvfuser::serde::TensorCreationSymbolic*>(data())
        : nullptr;
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_ARGS) &&
        verifier.VerifyVector(args()) && VerifyOffset(verifier, VT_OUTPUTS) &&
        verifier.VerifyVector(outputs()) && VerifyOffset(verifier, VT_NAME) &&
        verifier.VerifyString(name()) &&
        VerifyField<int32_t>(verifier, VT_TYPE, 4) &&
        VerifyField<uint8_t>(verifier, VT_DATA_TYPE, 1) &&
        VerifyOffset(verifier, VT_DATA) &&
        VerifyRecordData(verifier, data(), data_type()) && verifier.EndTable();
  }
};

template <>
inline const nvfuser::serde::BatchNorm* RecordFunctor::data_as<
    nvfuser::serde::BatchNorm>() const {
  return data_as_BatchNorm();
}

template <>
inline const nvfuser::serde::Bool* RecordFunctor::data_as<
    nvfuser::serde::Bool>() const {
  return data_as_Bool();
}

template <>
inline const nvfuser::serde::Broadcast* RecordFunctor::data_as<
    nvfuser::serde::Broadcast>() const {
  return data_as_Broadcast();
}

template <>
inline const nvfuser::serde::BroadcastInDim* RecordFunctor::data_as<
    nvfuser::serde::BroadcastInDim>() const {
  return data_as_BroadcastInDim();
}

template <>
inline const nvfuser::serde::BroadcastInDimSymbolic* RecordFunctor::data_as<
    nvfuser::serde::BroadcastInDimSymbolic>() const {
  return data_as_BroadcastInDimSymbolic();
}

template <>
inline const nvfuser::serde::ComplexDouble* RecordFunctor::data_as<
    nvfuser::serde::ComplexDouble>() const {
  return data_as_ComplexDouble();
}

template <>
inline const nvfuser::serde::Double* RecordFunctor::data_as<
    nvfuser::serde::Double>() const {
  return data_as_Double();
}

template <>
inline const nvfuser::serde::Dtype* RecordFunctor::data_as<
    nvfuser::serde::Dtype>() const {
  return data_as_Dtype();
}

template <>
inline const nvfuser::serde::Dimension* RecordFunctor::data_as<
    nvfuser::serde::Dimension>() const {
  return data_as_Dimension();
}

template <>
inline const nvfuser::serde::Int* RecordFunctor::data_as<nvfuser::serde::Int>()
    const {
  return data_as_Int();
}

template <>
inline const nvfuser::serde::Norm* RecordFunctor::data_as<
    nvfuser::serde::Norm>() const {
  return data_as_Norm();
}

template <>
inline const nvfuser::serde::Output* RecordFunctor::data_as<
    nvfuser::serde::Output>() const {
  return data_as_Output();
}

template <>
inline const nvfuser::serde::Pad* RecordFunctor::data_as<nvfuser::serde::Pad>()
    const {
  return data_as_Pad();
}

template <>
inline const nvfuser::serde::Permute* RecordFunctor::data_as<
    nvfuser::serde::Permute>() const {
  return data_as_Permute();
}

template <>
inline const nvfuser::serde::Slice* RecordFunctor::data_as<
    nvfuser::serde::Slice>() const {
  return data_as_Slice();
}

template <>
inline const nvfuser::serde::Squeeze* RecordFunctor::data_as<
    nvfuser::serde::Squeeze>() const {
  return data_as_Squeeze();
}

template <>
inline const nvfuser::serde::Reduction* RecordFunctor::data_as<
    nvfuser::serde::Reduction>() const {
  return data_as_Reduction();
}

template <>
inline const nvfuser::serde::Reshape* RecordFunctor::data_as<
    nvfuser::serde::Reshape>() const {
  return data_as_Reshape();
}

template <>
inline const nvfuser::serde::Tensor* RecordFunctor::data_as<
    nvfuser::serde::Tensor>() const {
  return data_as_Tensor();
}

template <>
inline const nvfuser::serde::TensorCreation* RecordFunctor::data_as<
    nvfuser::serde::TensorCreation>() const {
  return data_as_TensorCreation();
}

template <>
inline const nvfuser::serde::TensorCreationSymbolic* RecordFunctor::data_as<
    nvfuser::serde::TensorCreationSymbolic>() const {
  return data_as_TensorCreationSymbolic();
}

struct RecordFunctorBuilder {
  typedef RecordFunctor Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_args(
      flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
          args) {
    fbb_.AddOffset(RecordFunctor::VT_ARGS, args);
  }
  void add_outputs(
      flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
          outputs) {
    fbb_.AddOffset(RecordFunctor::VT_OUTPUTS, outputs);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(RecordFunctor::VT_NAME, name);
  }
  void add_type(nvfuser::serde::RecordType type) {
    fbb_.AddElement<int32_t>(
        RecordFunctor::VT_TYPE, static_cast<int32_t>(type), 0);
  }
  void add_data_type(nvfuser::serde::RecordData data_type) {
    fbb_.AddElement<uint8_t>(
        RecordFunctor::VT_DATA_TYPE, static_cast<uint8_t>(data_type), 0);
  }
  void add_data(flatbuffers::Offset<void> data) {
    fbb_.AddOffset(RecordFunctor::VT_DATA, data);
  }
  explicit RecordFunctorBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<RecordFunctor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<RecordFunctor>(end);
    return o;
  }
};

inline flatbuffers::Offset<RecordFunctor> CreateRecordFunctor(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
        args = 0,
    flatbuffers::Offset<flatbuffers::Vector<const nvfuser::serde::State*>>
        outputs = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    nvfuser::serde::RecordType type = nvfuser::serde::RecordType_Base,
    nvfuser::serde::RecordData data_type = nvfuser::serde::RecordData_NONE,
    flatbuffers::Offset<void> data = 0) {
  RecordFunctorBuilder builder_(_fbb);
  builder_.add_data(data);
  builder_.add_type(type);
  builder_.add_name(name);
  builder_.add_outputs(outputs);
  builder_.add_args(args);
  builder_.add_data_type(data_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<RecordFunctor> CreateRecordFunctorDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    const std::vector<nvfuser::serde::State>* args = nullptr,
    const std::vector<nvfuser::serde::State>* outputs = nullptr,
    const char* name = nullptr,
    nvfuser::serde::RecordType type = nvfuser::serde::RecordType_Base,
    nvfuser::serde::RecordData data_type = nvfuser::serde::RecordData_NONE,
    flatbuffers::Offset<void> data = 0) {
  auto args__ =
      args ? _fbb.CreateVectorOfStructs<nvfuser::serde::State>(*args) : 0;
  auto outputs__ =
      outputs ? _fbb.CreateVectorOfStructs<nvfuser::serde::State>(*outputs) : 0;
  auto name__ = name ? _fbb.CreateString(name) : 0;
  return nvfuser::serde::CreateRecordFunctor(
      _fbb, args__, outputs__, name__, type, data_type, data);
}

struct TrieNode FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TrieNodeBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_RECORD = 4,
    VT_CHILDREN = 6,
    VT_FUSION_ID = 8,
    VT_VISITS = 10,
    VT_IS_TERMINAL = 12
  };
  const nvfuser::serde::RecordFunctor* record() const {
    return GetPointer<const nvfuser::serde::RecordFunctor*>(VT_RECORD);
  }
  const flatbuffers::Vector<uint64_t>* children() const {
    return GetPointer<const flatbuffers::Vector<uint64_t>*>(VT_CHILDREN);
  }
  uint64_t fusion_id() const {
    return GetField<uint64_t>(VT_FUSION_ID, 0);
  }
  uint64_t visits() const {
    return GetField<uint64_t>(VT_VISITS, 0);
  }
  bool is_terminal() const {
    return GetField<uint8_t>(VT_IS_TERMINAL, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) && VerifyOffset(verifier, VT_RECORD) &&
        verifier.VerifyTable(record()) && VerifyOffset(verifier, VT_CHILDREN) &&
        verifier.VerifyVector(children()) &&
        VerifyField<uint64_t>(verifier, VT_FUSION_ID, 8) &&
        VerifyField<uint64_t>(verifier, VT_VISITS, 8) &&
        VerifyField<uint8_t>(verifier, VT_IS_TERMINAL, 1) &&
        verifier.EndTable();
  }
};

struct TrieNodeBuilder {
  typedef TrieNode Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_record(flatbuffers::Offset<nvfuser::serde::RecordFunctor> record) {
    fbb_.AddOffset(TrieNode::VT_RECORD, record);
  }
  void add_children(
      flatbuffers::Offset<flatbuffers::Vector<uint64_t>> children) {
    fbb_.AddOffset(TrieNode::VT_CHILDREN, children);
  }
  void add_fusion_id(uint64_t fusion_id) {
    fbb_.AddElement<uint64_t>(TrieNode::VT_FUSION_ID, fusion_id, 0);
  }
  void add_visits(uint64_t visits) {
    fbb_.AddElement<uint64_t>(TrieNode::VT_VISITS, visits, 0);
  }
  void add_is_terminal(bool is_terminal) {
    fbb_.AddElement<uint8_t>(
        TrieNode::VT_IS_TERMINAL, static_cast<uint8_t>(is_terminal), 0);
  }
  explicit TrieNodeBuilder(flatbuffers::FlatBufferBuilder& _fbb) : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<TrieNode> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TrieNode>(end);
    return o;
  }
};

inline flatbuffers::Offset<TrieNode> CreateTrieNode(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<nvfuser::serde::RecordFunctor> record = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint64_t>> children = 0,
    uint64_t fusion_id = 0,
    uint64_t visits = 0,
    bool is_terminal = false) {
  TrieNodeBuilder builder_(_fbb);
  builder_.add_visits(visits);
  builder_.add_fusion_id(fusion_id);
  builder_.add_children(children);
  builder_.add_record(record);
  builder_.add_is_terminal(is_terminal);
  return builder_.Finish();
}

inline flatbuffers::Offset<TrieNode> CreateTrieNodeDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    flatbuffers::Offset<nvfuser::serde::RecordFunctor> record = 0,
    const std::vector<uint64_t>* children = nullptr,
    uint64_t fusion_id = 0,
    uint64_t visits = 0,
    bool is_terminal = false) {
  auto children__ = children ? _fbb.CreateVector<uint64_t>(*children) : 0;
  return nvfuser::serde::CreateTrieNode(
      _fbb, record, children__, fusion_id, visits, is_terminal);
}

struct FusionCache FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FusionCacheBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_MAX_FUSIONS = 4,
    VT_STRUCTURE = 6,
    VT_TERMINAL_NODES = 8
  };
  uint64_t max_fusions() const {
    return GetField<uint64_t>(VT_MAX_FUSIONS, 0);
  }
  const flatbuffers::Vector<flatbuffers::Offset<nvfuser::serde::TrieNode>>*
  structure() const {
    return GetPointer<const flatbuffers::Vector<
        flatbuffers::Offset<nvfuser::serde::TrieNode>>*>(VT_STRUCTURE);
  }
  const flatbuffers::Vector<uint64_t>* terminal_nodes() const {
    return GetPointer<const flatbuffers::Vector<uint64_t>*>(VT_TERMINAL_NODES);
  }
  bool Verify(flatbuffers::Verifier& verifier) const {
    return VerifyTableStart(verifier) &&
        VerifyField<uint64_t>(verifier, VT_MAX_FUSIONS, 8) &&
        VerifyOffset(verifier, VT_STRUCTURE) &&
        verifier.VerifyVector(structure()) &&
        verifier.VerifyVectorOfTables(structure()) &&
        VerifyOffset(verifier, VT_TERMINAL_NODES) &&
        verifier.VerifyVector(terminal_nodes()) && verifier.EndTable();
  }
};

struct FusionCacheBuilder {
  typedef FusionCache Table;
  flatbuffers::FlatBufferBuilder& fbb_;
  flatbuffers::uoffset_t start_;
  void add_max_fusions(uint64_t max_fusions) {
    fbb_.AddElement<uint64_t>(FusionCache::VT_MAX_FUSIONS, max_fusions, 0);
  }
  void add_structure(
      flatbuffers::Offset<
          flatbuffers::Vector<flatbuffers::Offset<nvfuser::serde::TrieNode>>>
          structure) {
    fbb_.AddOffset(FusionCache::VT_STRUCTURE, structure);
  }
  void add_terminal_nodes(
      flatbuffers::Offset<flatbuffers::Vector<uint64_t>> terminal_nodes) {
    fbb_.AddOffset(FusionCache::VT_TERMINAL_NODES, terminal_nodes);
  }
  explicit FusionCacheBuilder(flatbuffers::FlatBufferBuilder& _fbb)
      : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FusionCache> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FusionCache>(end);
    return o;
  }
};

inline flatbuffers::Offset<FusionCache> CreateFusionCache(
    flatbuffers::FlatBufferBuilder& _fbb,
    uint64_t max_fusions = 0,
    flatbuffers::Offset<flatbuffers::Vector<
        flatbuffers::Offset<nvfuser::serde::TrieNode>>> structure = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint64_t>> terminal_nodes = 0) {
  FusionCacheBuilder builder_(_fbb);
  builder_.add_max_fusions(max_fusions);
  builder_.add_terminal_nodes(terminal_nodes);
  builder_.add_structure(structure);
  return builder_.Finish();
}

inline flatbuffers::Offset<FusionCache> CreateFusionCacheDirect(
    flatbuffers::FlatBufferBuilder& _fbb,
    uint64_t max_fusions = 0,
    const std::vector<flatbuffers::Offset<nvfuser::serde::TrieNode>>*
        structure = nullptr,
    const std::vector<uint64_t>* terminal_nodes = nullptr) {
  auto structure__ = structure
      ? _fbb.CreateVector<flatbuffers::Offset<nvfuser::serde::TrieNode>>(
            *structure)
      : 0;
  auto terminal_nodes__ =
      terminal_nodes ? _fbb.CreateVector<uint64_t>(*terminal_nodes) : 0;
  return nvfuser::serde::CreateFusionCache(
      _fbb, max_fusions, structure__, terminal_nodes__);
}

inline bool VerifyRecordData(
    flatbuffers::Verifier& verifier,
    const void* obj,
    RecordData type) {
  switch (type) {
    case RecordData_NONE: {
      return true;
    }
    case RecordData_BatchNorm: {
      auto ptr = reinterpret_cast<const nvfuser::serde::BatchNorm*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Bool: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Bool*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Broadcast: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Broadcast*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_BroadcastInDim: {
      auto ptr = reinterpret_cast<const nvfuser::serde::BroadcastInDim*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_BroadcastInDimSymbolic: {
      auto ptr =
          reinterpret_cast<const nvfuser::serde::BroadcastInDimSymbolic*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_ComplexDouble: {
      auto ptr = reinterpret_cast<const nvfuser::serde::ComplexDouble*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Double: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Double*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Dtype: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Dtype*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Dimension: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Dimension*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Int: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Int*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Norm: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Norm*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Output: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Output*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Pad: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Pad*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Permute: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Permute*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Slice: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Slice*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Squeeze: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Squeeze*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Reduction: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Reduction*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Reshape: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Reshape*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_Tensor: {
      auto ptr = reinterpret_cast<const nvfuser::serde::Tensor*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_TensorCreation: {
      auto ptr = reinterpret_cast<const nvfuser::serde::TensorCreation*>(obj);
      return verifier.VerifyTable(ptr);
    }
    case RecordData_TensorCreationSymbolic: {
      auto ptr =
          reinterpret_cast<const nvfuser::serde::TensorCreationSymbolic*>(obj);
      return verifier.VerifyTable(ptr);
    }
    default:
      return true;
  }
}

inline bool VerifyRecordDataVector(
    flatbuffers::Verifier& verifier,
    const flatbuffers::Vector<flatbuffers::Offset<void>>* values,
    const flatbuffers::Vector<uint8_t>* types) {
  if (!values || !types)
    return !values && !types;
  if (values->size() != types->size())
    return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyRecordData(
            verifier, values->Get(i), types->GetEnum<RecordData>(i))) {
      return false;
    }
  }
  return true;
}

inline const nvfuser::serde::FusionCache* GetFusionCache(const void* buf) {
  return flatbuffers::GetRoot<nvfuser::serde::FusionCache>(buf);
}

inline const nvfuser::serde::FusionCache* GetSizePrefixedFusionCache(
    const void* buf) {
  return flatbuffers::GetSizePrefixedRoot<nvfuser::serde::FusionCache>(buf);
}

inline const char* FusionCacheIdentifier() {
  return "NV00";
}

inline bool FusionCacheBufferHasIdentifier(const void* buf) {
  return flatbuffers::BufferHasIdentifier(buf, FusionCacheIdentifier());
}

inline bool SizePrefixedFusionCacheBufferHasIdentifier(const void* buf) {
  return flatbuffers::BufferHasIdentifier(buf, FusionCacheIdentifier(), true);
}

inline bool VerifyFusionCacheBuffer(flatbuffers::Verifier& verifier) {
  return verifier.VerifyBuffer<nvfuser::serde::FusionCache>(
      FusionCacheIdentifier());
}

inline bool VerifySizePrefixedFusionCacheBuffer(
    flatbuffers::Verifier& verifier) {
  return verifier.VerifySizePrefixedBuffer<nvfuser::serde::FusionCache>(
      FusionCacheIdentifier());
}

inline void FinishFusionCacheBuffer(
    flatbuffers::FlatBufferBuilder& fbb,
    flatbuffers::Offset<nvfuser::serde::FusionCache> root) {
  fbb.Finish(root, FusionCacheIdentifier());
}

inline void FinishSizePrefixedFusionCacheBuffer(
    flatbuffers::FlatBufferBuilder& fbb,
    flatbuffers::Offset<nvfuser::serde::FusionCache> root) {
  fbb.FinishSizePrefixed(root, FusionCacheIdentifier());
}

} // namespace serde
} // namespace nvfuser

#endif // FLATBUFFERS_GENERATED_FUSIONCACHE_NVFUSER_SERDE_H_
