// clang-format off
/*
 * SPDX-FileCopyrightText: Copyright (c) 2023-present NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved.
 * SPDX-License-Identifier: BSD-3-Clause
 */
namespace nvfuser.serde;

// This indicates the flatbuffer compatibility. The number will bump up when a
// breaking change is applied to the schema.
file_identifier "NV01";

// =====================================================================================
// Enum definitions

// The StateType enum indicates whether the state object is a Scalar or Tensor.
enum StateType: int {
  None = 0,
  Scalar,
  Vector,
  Tensor,
}

// The Contiguity enum shows whether a tensor dimension is contiguous
// with the dimension to its right.
enum Contiguity: int {
  None = 0,
  Contiguous,
  Strided,
}

// Each RecordFunctor is assigned a RecordType for the hash function.
// Otherwise, the record type is determined via the success of dynamic casting.
// We enumerate the template arguments of a RecordFunctor, so we can specify
// them during deserialization.
enum RecordType: int {
  Base = 0,
  AtOp,
  BatchNormOp,
  Binary_TV,
  Binary_TV_VAL,
  Binary_VAL,
  Binary_VAL_TV,
  BroadcastInDim,
  BroadcastOp,
  CastTv,
  CastVal,
  CatOp,
  End,
  FullOp,
  IndexSelectOp,
  IotaOp,
  NormalDistOp,
  OutputTv,
  OutputVal,
  PadOp,
  PermuteOp,
  ReductionMax,
  ReductionMin,
  ReductionProd,
  ReductionSum,
  ReshapeOp,
  Scalar,
  ShapeOp,
  SizeOp,
  SliceOp,
  SqueezeOp,
  Start,
  StrideOrderOp,
  TakeAlongAxisOp,
  Tensor,
  TensorSizes,
  Ternary_Alpha_TV,
  Ternary_Alpha_TV_TV_VAL,
  Ternary_Alpha_TV_VAL_TV,
  Ternary_Alpha_TV_VAL_VAL,
  Ternary_Alpha_VAL,
  Ternary_Alpha_VAL_TV_TV,
  Ternary_Alpha_VAL_TV_VAL,
  Ternary_Alpha_VAL_VAL_TV,
  Ternary_TV,
  Ternary_TV_TV_VAL,
  Ternary_TV_VAL_TV,
  Ternary_TV_VAL_VAL,
  Ternary_VAL,
  Ternary_VAL_TV_TV,
  Ternary_VAL_TV_VAL,
  Ternary_VAL_VAL_TV,
  TorchGatherOp,
  Unary_TV,
  Unary_VAL,
  UniformDistOp,
  VarianceMeanOp,
  VarianceOp,
  Vector,
}

// The ExprType enum maps to the corresponding IR class;
enum ExprType: int {
  None = 0,
  Allocate,
  AllocateFusedReduction,
  ArrayConstruct,
  Asm,
  AsyncCommit,
  AsyncWait,
  Binary,
  BlockSerializeRelease,
  BlockSerializeWait,
  BlockSync,
  Broadcast,
  Cat,
  EncodeTensorMapTiled,
  Expand,
  Eye,
  FlattenedAssocComm,
  ForLoop,
  Full,
  Gather,
  GetAttr,
  GetItem,
  GetMetaData,
  GetRNGSeedAndOffsetFromHost,
  GridBroadcast,
  GridSync,
  GridWelford,
  GroupedReduction,
  GroupedWelford,
  IfThenElse,
  IndexSelect,
  InitMagicZero,
  Iota,
  LoadStore,
  MBarrierArrive,
  MBarrierArriveExpectTx,
  MBarrierInit,
  MBarrierInvalidate,
  MBarrierWait,
  Merge,
  Mma,
  Pad,
  PipelineCommunication,
  PipelineStage,
  Reduction,
  Resize,
  ReverseArray,
  RNG,
  Scatter,
  Select,
  Shift,
  Slice,
  Split,
  Squeeze,
  StructConstruct,
  Swizzle,
  Swizzle2D,
  TensorConstruct,
  Ternary,
  TorchGather,
  Unary,
  UpdateMagicZero,
  View,
  ViewAsScalar,
  Welford,
}

// =====================================================================================
// Union definitions

// The RecordData hold the attribute information for each Record Functor.
union RecordData {
  At,
  BatchNorm,
  Broadcast,
  BroadcastInDim,
  Dimension,
  Dtype,
  Norm,
  Output,
  Pad,
  Dims,
  Slice,
  Squeeze,
  Reduction,
  Scalar,
  Size,
  Tensor,
  TensorCreationSymbolic,
  Vector,
}

// The PolymorphicValueData union holds the attribute information for each PolymorphicValue.
union PolymorphicValueData {
  Scalar,
  ScalarCpu,
  TensorArg,
}

// The ValData union holds the attribute information for each Val class.
union ValData {
  IterDomain,
  NamedScalar,
  PipelineVal,
  PolymorphicValue,
  Predicate,
  TensorDomain,
  TensorView,
  TensorIndex,
}

// =====================================================================================
// Basic data tables

// The State struct represents each scalar and tensor value.
// e.g., all input, output and intermediate values in the fusion.
struct State {
  index: int;
  type: StateType;
}

// Data for Scalar
table Scalar {
  dtype: long;
  has_value: bool;
  value_type: long;
  bool_value: bool;
  long_value: long;
  double_value: double;
  real_value: double;
  imag_value: double;
}

// =====================================================================================
// Tables for PolymorphicValue, ScalarCpu, TensorArg, KernelArgumentHolder used in FusionExecutor.

// The ScalarCpu is represented by a fixed size array of raw bytes.
table ScalarCpu {
  scalar_value: Scalar;
}

// Data of TensorArg.
// The original cpp TensorArg holds real data.
// However, only a metadata tensor is returned upon deserialization.
// The ptr parameter is used to determine vectorization during scheduling.
table TensorArg {
  ptr: ulong;
  sizes: [long];
  strides: [long];
  dtype: long;
}

// This table corresponds with a given PolymorphicValue object.
table PolymorphicValue {
  data: PolymorphicValueData;
}

// This table holds multiple PolymorphicValue objects.
table KernelArgumentHolder {
  arguments: [PolymorphicValue];
  device_index: byte;
  cache_id: ulong;
}

//
// =====================================================================================
// Tables for LaunchParams, GlobalBufferInfo, ExecutorEntry, and TensorShape used in FusionExecutor

// Data representing a tensor shape used in LaunchParam
table TensorShape {
  shape: [long];
}

// This table holds the cached launch parameters for a kernel.
table LaunchParams {
  gdimx: long;
  gdimy: long;
  gdimz: long;
  bdimx: long;
  bdimy: long;
  bdimz: long;
  smem: long;
  output_sizes: [TensorShape];
}

// This table describes the cached global buffers for a kernel.
// The original cpp GlobalBufferInfo contains a TensorView pointer.
// For this table, we represent the pointer with an integer position.
// For output tensors, we use its position in the fusion outputs.
// For intermediate tensors, we use its position in the KernelSummary global_allocations.
table GlobalBufferInfo {
  tv: long = -1;
  sizes: [long];
  strides: [long];
  dtype: long;
  zero_init: bool;
  is_profile_buffer: bool;
  is_fusion_output: bool;
}

// This table describes the cached ExecutorEntry for a kernel.
table ExecutorEntry {
  init: bool;
  launch_params: LaunchParams;
  outputs: [GlobalBufferInfo];
  intermediates: [GlobalBufferInfo];
}

// =====================================================================================
// RecordData tables for RecordFunctor objects

// Data for AtOpRecord
table At {
  index: long;
}

// Data for BatchNormOpRecord
table BatchNorm {
  training: bool;
  channels_last: bool;
}

// Data for BroadcastOpRecord
table Broadcast {
  broadcast_dims: [bool];
}

// Data for BroadcastInDimOpRecord
table BroadcastInDim {
  output_size: ulong;
  broadcast_dims: [long];
}

// Data for CastOpRecord, ScalarRecord, and IotaOpRecord
table Dtype {
  dtype: long;
}

// Data for TorchGatherOpRecord, TakeAlongAxisOpRecord, and IndexSelectOpRecord
table Dimension {
  dim: long;
}

// Data for NormOpRecord
table Norm {
  axes: [int];
  correction: long;
  keep_dim: bool;
}

// Data for OutputRecord
table Output {
  stride_order: [long];
}

// Data for PadOpRecord
table Pad {
  pad_widths: [long];
}

// Data for DimsOpRecord
table Dims {
  dims: [long];
}

// Data for ReductionOpRecord
table Reduction {
  axes: [int];
  keep_dim: bool;
  dtype: long;
}

// Data for SizeOpRecord
table Size {
  dim: long;
}

// Data for SliceOpRecord
table Slice {
  start_indices: [long];
  end_indices:[long];
  strides: [long];
}

// Data for SqueezeOpRecord
table Squeeze {
  squeeze_dims: [long];
}

// Data for TensorRecord
table Tensor {
  sizes: [long];
  contiguity: [Contiguity];
  stride_order: [long];
  dtype: long;
  is_cpu: bool;
}

// Data for RandomDistOpRecord
// The shape is symbolic.
table TensorCreationSymbolic {
  dtype: long;
}

// Data for Vector
table Vector {
  dtype: long;
}

// =====================================================================================
//

table Predicate {
    predicate_type_enum: long;
    expr: long;
    thread_pred: long;
    unrolled_loop: long;
    value: long;
}

table TensorIndex {
  view: long;
  index: long;
}

table PipelineVal {
  original_val: long;
  stage: long;
}

table NamedScalar {
  name: string;
}

table IterDomain {
  start_val: long;
  extent_val: long;
  expanded_extent_val: long;
  stop_offset_val: long;
  parallel_type_enum: long;
  iter_type_enum: long;
  is_rfactor_domain: bool;
  is_padded_dimension: bool;
  padded_to_size: long;
  is_mma_swizzled: bool;
}

table TensorDomain {
  root_domain: [long];
  rfactor_domain: [long];
  allocation_domain: [long];
  leaf_domain: [long];
  contiguity: [Contiguity];
}

table TensorView {
  domain: long;
  compute_at_pos: ulong;
  max_producer_pos_:  ulong;
  memory_type_enum: long;
  is_double_buffered: bool;
  is_circular_buffered: bool;
  circular_buffer_stage: ulong;
  cpu_scalar: bool;
  has_swizzle_op: bool;
  compute_with_consumers: [long];
  compute_with_pos: ulong;
  maybe_max_producer_pos: ulong;
  promote_reuse: bool;
}

table Value {
  dtype_enum: long;
  is_fusion_input: bool;
  is_fusion_output: bool;
  definition_expr: long;
  uses_expr: [long];
  evaluator_index: int;
  data: ValData;
}

table Expression {
  type: ExprType;
  input_vals: [long];
  output_vals: [long];
  attributes_vals: [long];
}

table IrContainer {
  vals: [Value];
  exprs: [Expression];
  val_type_name_map_keys: [long];
  val_type_name_map_values: [ulong];
  expr_name_counter: ulong;
  axioms: [long];
  metadata_keys: [long];
  metadata_values_lhs: [long];
  metadata_values_rhs: [long];
}

table AliasInfo {
  value: long;
  alias_type_enum: long;
  hide_output: bool;
}

// Map from index of tensor to permutation
table Permutation {
  key: int;
  value: [long];
}

// Managed Data is not supported
table Fusion {
  container: IrContainer;

  // Fusion inputs and outputs Val
  inputs_vals: [long];
  outputs_vals: [long];

  // I/O alias pointing from output to input
  io_alias_keys: [long];
  io_alias_values: [AliasInfo];

  permuted_input_map: [Permutation];
  permuted_output_map: [Permutation];

  // Records if the current use data in the IR nodes are valid
  //  the states are either all valid or all invalid
  all_tv_uses_valid: bool;
  is_during_update_uses: bool;
}

// Table represents kir::Allocate node
table AllocateBuffer {
  tv: long;
  shape: [long];
  zero_init: bool;
}

// This table stores the KernelSummary value necessary for running compiled fusion.
table KernelSummary {
  has_cooperative_grid_reduction: bool;
  has_dynamic_local_memory_allocations: bool;
  has_block_reductions: bool;
  has_grid_reductions: bool;
  has_block_broadcasts: bool;
  has_grid_broadcasts: bool;
  has_block_welford: bool;
  has_grid_welford: bool;
  has_outer_grouped_grid_welford: bool;
  largest_smem_data_type: long;
  outer_grouped_grid_welford_largest_smem_size: int = 0;
  global_allocations: [AllocateBuffer];
  dynamic_smem_allocations: [AllocateBuffer];
  static_smem_allocations: [AllocateBuffer];
}

table Kernel {
  fusion: Fusion;
  top_level_exprs: [long];
  summary: KernelSummary;

  // Is this kernel being compiled with int32 or int64 indexing?
  index_type: long;

  // Parameters of the kernel. The parameters contain the inputs and outputs of
  // the kernel, intermediate buffers, and special items such as RNG state and
  // tensor map for TMA support, etc. The parameters are not required to have no
  // definition. If a parameter has a definition, its definition will be
  // evaluated before the kernel is executed.
  parameters: [long];

  // Data members for WarpPaddedParallelInfo
  is_tidx_padded: bool;
  is_tidx_single_warp: bool;
  has_warp_reduction: bool;
}

// Each CudaKernel represents a single, compiled kernel.
table CudaKernel {
  kernel_name: string;
  compile_args: string;
  cubin: [ubyte];
  cubin_filename: string;
  ptx: [ubyte];
  ptx_filename: string;
  // The block size field is used to generate compile arguments.
  // We compare the generated compile args against those stored in this table
  // when deserializing this cuda kernel.
  block_size: long = -1;
}

// Each Fusion Executor maps to a lowered and compiled kernel.
table FusionExecutor {
  device_smem_limit: long;
  block_size_high_water_mark: long;
  maxrregcount_high_water_mark: long;
  warp_size: long;
  heuristic: long;
  fusion_id: long;
  concrete_id: long;
  runtime_id: long;
  group_id: long;
  kernel_code: string;
  executor_entry_lookup_keys: [ulong];
  executor_entry_lookup_values: [ExecutorEntry];
  // Is this kernel being compiled with int32 or int64 indexing?
  index_type: long;
  compiled_kernel: CudaKernel;
}

// A directed edge on DAG, which wraps a value that connects segmented groups.
table SegmentedEdge {
  from_segmented_group: long;
  to_segmented_group: long;
  val: long;
}

// Each SegmentedGroup represents a segmented fusion.
table SegmentedGroup {
  producer_edges: [long];
  consumer_edges: [long];
  input_vals: [long];
  output_vals: [long];
  group_id: int;
  heuristic: long;
  exprs: [long];
  level: int;
  visited: bool;
  merge_with_segmented_group: long;
  merge_through_segmented_edge: long;
  merged: bool;
  is_fusion_input: bool;
}

// The SegmentedFusion represents a segmented fusion graph that owns the segmented groups.
table SegmentedFusion {
  segmented_fusion_name: ulong;
  num_vals: ulong;
  num_exprs: ulong;
  edges: [SegmentedEdge];
  groups: [SegmentedGroup];
  force_fp16_tv_set: [long];
  force_half_precision_type: long;
}

// Each FusionKernelRuntime represents a concretized, segmented Fusion.
// We store the metadata for the original arguments to segment, schedule, and compile the Fusion at deserialization.
// Each fusion segment is given a FusionExecutor.
// The unscheduled fusion is defined by traversing Trie in FusionCache.
table FusionKernelRuntime {
  fusion_id: long;
  concrete_id: long;
  runtime_id: long;
  args: KernelArgumentHolder;
  executors: [FusionExecutor];
  segmented_fusion: SegmentedFusion;
}

// EncodingEntry for InputsIdLookup LRU cache.
struct EncodingEntry {
  id: ulong;
  lru_iter: ulong;
}

// This table is a LRU cache containing input arguments known by the FusionExecutorCache.
table InputsIdLookup {
  max_cache_size: ulong;
  current_id: ulong;
  lru_cache: [string];

  // This field defines map<std::string, EncodingEntry> encoding_lookup
  encoding_lookup_keys: [string];
  encoding_lookup_values: [EncodingEntry];
}

// This table represents a key-value pair in the kernel_runtimes map in FusionExecutorCache.
table KernelRuntimeState {
  device_id: long;
  concrete_id: long;
  has_dynamic_transform_info: bool;
  runtimes: [FusionKernelRuntime];
}

// This table describes the FusionExecutorCache.
// The unscheduled fusion is defined by traversing Trie in FusionCache.
table FusionExecutorCache {
  fusion_id: long;
  inputs_cache: InputsIdLookup;

  // This field represents a map<<size_t, DynamicTransformConcretizationInfo>, vector<FusionKernelRuntime>>.
  // DynamicTransformConcretizationInfo is regenerated during deserialization.
  kernel_runtimes_map: [KernelRuntimeState];

  // This field defines a map<size_t, FusionKernelRuntime> id_to_kernel_runtime.
  kernel_cache_keys: [ulong];
  // indices into kernel_runtime_values
  kernel_cache_values: [ulong];
}

// RecordFunctor represents operations in the Fusion. It is a node in the graph with input and output edges.
// Some operations require storing extra attributes in the RecordData field.
table RecordFunctor {
  args: [State];
  outputs: [State];
  name: string;
  type: RecordType;
  data: RecordData;
}

// The trie node is represents a Node in the trie structure.
// Only the terminal leaf nodes have cached fusions.
table TrieNode {
  record: RecordFunctor;
  children: [ulong];
  fusion_id: ulong;
  visits: ulong;
  is_terminal: bool;
}

// The fusion cache is a prefix tree (trie) of records that caches fusions in
// its leaves. For serialization, we flatten the trie structure using
// breadth-first search.
//
// TODO We skipped these fields required for user-defined schedulers
// * fusion_schedules
// * user_def_input_encodings
table FusionCache {
  max_fusions: ulong;
  structure: [TrieNode];
  terminal_nodes: [ulong];
  auto_gen_schedules: [FusionExecutorCache];
  // static fusion executor counter
  global_fusion_count: long;
  device_major: long;
  device_minor: long;
  cuda_major: long;
  cuda_minor: long;
}

root_type FusionCache;
