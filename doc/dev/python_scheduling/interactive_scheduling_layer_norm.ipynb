{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f832c053-b198-49ab-b780-ba109195188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nvfuser import (\n",
    "    FusionDefinition,\n",
    "    DataType,\n",
    "    ParallelType,\n",
    "    MemoryType,\n",
    "    LoadStoreOpType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750a975c-632e-47dd-9f80-1d0addd25841",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "tensor_size = 4096\n",
    "inputs = [\n",
    "    torch.randn(batch_size, tensor_size, dtype=torch.bfloat16, device=\"cuda\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bb764c-9e65-4e88-a487-6ca6c70f949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(FusionDefinition):\n",
    "    def definition(self):\n",
    "        self.t0 = self.from_pytorch(inputs[0])\n",
    "        self.s0 = self.define_scalar(1e-6, dtype=DataType.Double)\n",
    "        self.norm_const = self.define_scalar(tensor_size, dtype=DataType.Int)\n",
    "\n",
    "        self.mean_cast = self.ops.cast(self.t0, dtype=DataType.Float)\n",
    "        self.sum0 = self.ops.sum(self.mean_cast, dims=[-1])\n",
    "        # NOTE Manually broadcast because fusion definition cannot access hidden reduction tensor view.\n",
    "        self.bcast_sum0 = self.ops.broadcast(self.sum0, [False, True])\n",
    "        self.mean = self.ops.div(self.bcast_sum0, self.norm_const)\n",
    "\n",
    "        self.var_cast = self.ops.cast(self.t0, dtype=DataType.Float)\n",
    "        self.diff = self.ops.sub(self.var_cast, self.mean)\n",
    "        self.diff_sq = self.ops.mul(self.diff, self.diff)\n",
    "        self.sum1 = self.ops.sum(self.diff_sq, dims=[-1])\n",
    "        # NOTE Manually broadcast because fusion definition cannot access hidden reduction tensor view.\n",
    "        self.bcast_sum1 = self.ops.broadcast(self.sum1, [False, True])\n",
    "        self.var = self.ops.div(self.bcast_sum1, self.norm_const)\n",
    "\n",
    "        self.t0_cast = self.ops.cast(self.t0, dtype=DataType.Float)\n",
    "        self.t0_diff = self.ops.sub(self.t0_cast, self.mean)\n",
    "        self.var_eps = self.ops.sqrt(self.ops.add(self.var, self.s0))\n",
    "        self.t0_norm = self.ops.div(self.t0_diff, self.var_eps)\n",
    "\n",
    "        self.t0_norm_cast = self.ops.cast(self.t0_norm, dtype=DataType.BFloat16)\n",
    "        self.add_output(self.t0_norm_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979dba31-b5c3-4896-ae12-49ae7bbbf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FusionDefinition\n",
    "fn = LayerNorm()\n",
    "fn._setup_definition()\n",
    "fn.definition()\n",
    "fn._finalize_definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3118863c-2c54-4923-8c8d-a1d92f117170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%kernel {\n",
      "T11_l[ iS22{i0}, iS23{i1} ]\n",
      "   = __bfloat2float(T0_g[ iS0{i0}, iS1{i1} ]);\n",
      "T1_l[ iS2{i0}, iS3{i1} ]\n",
      "   = __bfloat2float(T0_g[ iS0{i0}, iS1{i1} ]);\n",
      "T2_l[ iS4{i0}, rS5{i1} ]\n",
      "   = reduction( T1_l[ iS2{i0}, iS3{i1} ], op = add, initial value = float(0), allreduce = false )\n",
      "T3_l[ iS6{i0}, bS7{1} ]\n",
      "   = broadcast( T2_l[ iS4{i0}, rS5{i1} ] )\n",
      "f16 = (float)(4096);\n",
      "T4_l[ iS8{i0}, bS9{1} ]\n",
      "   = T3_l[ iS6{i0}, bS7{1} ]\n",
      "   / f16;\n",
      "T12_l[ iS24{i0}, iS25{i1} ]\n",
      "   = T11_l[ iS22{i0}, iS23{i1} ]\n",
      "   - T4_l[ iS8{i0}, bS9{1} ];\n",
      "T5_l[ iS10{i0}, iS11{i1} ]\n",
      "   = __bfloat2float(T0_g[ iS0{i0}, iS1{i1} ]);\n",
      "T6_l[ iS12{i0}, iS13{i1} ]\n",
      "   = T5_l[ iS10{i0}, iS11{i1} ]\n",
      "   - T4_l[ iS8{i0}, bS9{1} ];\n",
      "T7_l[ iS14{i0}, iS15{i1} ]\n",
      "   = T6_l[ iS12{i0}, iS13{i1} ]\n",
      "   * T6_l[ iS12{i0}, iS13{i1} ];\n",
      "T8_l[ iS16{i0}, rS17{i1} ]\n",
      "   = reduction( T7_l[ iS14{i0}, iS15{i1} ], op = add, initial value = float(0), allreduce = false )\n",
      "T9_l[ iS18{i0}, bS19{1} ]\n",
      "   = broadcast( T8_l[ iS16{i0}, rS17{i1} ] )\n",
      "f41 = (float)(4096);\n",
      "T10_l[ iS20{i0}, bS21{1} ]\n",
      "   = T9_l[ iS18{i0}, bS19{1} ]\n",
      "   / f41;\n",
      "T13_l[ iS26{i0}, bS27{1} ]\n",
      "   = T10_l[ iS20{i0}, bS21{1} ]\n",
      "   + double(9.9999999999999995e-07);\n",
      "T14_l[ iS28{i0}, bS29{1} ]\n",
      "   = sqrtf(T13_l[ iS26{i0}, bS27{1} ]);\n",
      "T15_l[ iS30{i0}, iS31{i1} ]\n",
      "   = T12_l[ iS24{i0}, iS25{i1} ]\n",
      "   / T14_l[ iS28{i0}, bS29{1} ];\n",
      "T16_g[ iS32{i0}, iS33{i1} ]\n",
      "   = __float2bfloat(T15_l[ iS30{i0}, iS31{i1} ]);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create user schedule for this input\n",
    "# NOTE: Schedules defined by the user for specific input sizes.\n",
    "fn._setup_schedule(inputs)\n",
    "print(fn._user_schedule_ir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add61e4e-8bff-40ba-8465-06bc99d50ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T17_s[ iS34{i0}, iS35{i1} ]', 'T18_l[ iS30{i0}, iS31{i1} ]']\n"
     ]
    }
   ],
   "source": [
    "# create cache tensors\n",
    "cache_after_t0 = fn.sched.cache_after(fn.t0)\n",
    "fn.sched.set_memory_type(cache_after_t0, MemoryType.shared)\n",
    "\n",
    "cache_before_t0_norm = fn.sched.cache_before(fn.t0_norm)\n",
    "cache_tvs = [cache_after_t0, cache_before_t0_norm]\n",
    "print(list(map(fn.sched.to_string, cache_tvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a242a25a-0f54-4544-80b3-92316fa44b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T4_l[ iS8{i0}, bS38{( ceilDiv(1, 1024) )}, bS40{( ceilDiv(1024, 4) )}, bS41{4} ]\n"
     ]
    }
   ],
   "source": [
    "# Schedule Reference Tensor\n",
    "reference_tv = fn.mean\n",
    "fn.sched.split(reference_tv, dim=-1, factor=256 * 4)\n",
    "fn.sched.split(reference_tv, dim=-1, factor=4)\n",
    "fn.sched.transform_like(reference_tv)\n",
    "print(fn.sched.to_string(reference_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279b4d7a-0458-4419-aae7-a8acbf12301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T19_l[ iS114{i0}, iS116{( ceilDiv(i1, 1024) )}rf, iS118{( ceilDiv(1024, 4) )}rf, rS119{4}rf ]', 'T20_l[ iS123{i0}, iS125{( ceilDiv(i1, 1024) )}rf, iS127{( ceilDiv(1024, 4) )}rf, rS128{4}rf ]']\n"
     ]
    }
   ],
   "source": [
    "# Add rfactor TensorViews\n",
    "reduction_tvs = list(\n",
    "    filter(fn.sched.is_reduction, fn.sched.tensors())\n",
    ")\n",
    "assert len(reduction_tvs) == 2\n",
    "rfactor_tvs = [fn.sched.rfactor(tv, dims=[-1]) for tv in reduction_tvs]\n",
    "print(list(map(fn.sched.to_string, rfactor_tvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b376575-9f28-4394-acad-5795f9fde2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T4_l[ iblockIdx.x8{i0}, bS38{( ceilDiv(1, 1024) )}, bthreadIdx.x40{( ceilDiv(1024, 4) )}, bS41{4} ]\n"
     ]
    }
   ],
   "source": [
    "# Add common parallelization\n",
    "fn.sched.parallelize(reference_tv, axis := 0, ParallelType.grid_x)\n",
    "fn.sched.parallelize(reference_tv, axis := -2, ParallelType.block_x)\n",
    "fn.sched.parallelize_like(reference_tv)\n",
    "print(fn.sched.to_string(reference_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beda4262-bc5c-4473-9a15-3643751a368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T15_l[ iblockIdx.x36{i0}, iS106{( ceilDiv(i1, 1024) )}, ithreadIdx.x108{( ceilDiv(1024, 4) )}, iV109{4} ]\n"
     ]
    }
   ],
   "source": [
    "# Vectorize input load and output store\n",
    "fn.sched.parallelize(cache_after_t0, axis := -1, ParallelType.vectorize)\n",
    "fn.sched.parallelize(fn.t0_norm, axis := -1, ParallelType.vectorize)\n",
    "print(fn.sched.to_string(fn.t0_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea464ace-e092-4915-b3b8-e8c7f059f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%kernel {\n",
      "T17_s[ iblockIdx.x34{i0}, iS54{( ceilDiv(i1, 1024) )}, ithreadIdx.x56{( ceilDiv(1024, 4) )}, iV57{4} ] ca_pos( 1 )\n",
      "   = Set( T0_g[ iS0{i0}, iS58{( ceilDiv(i1, 1024) )}, iS60{( ceilDiv(1024, 4) )}, iS61{4} ], cache_op=Streaming )\n",
      "T11_l[ iblockIdx.x22{i0}, iS70{( ceilDiv(i1, 1024) )}, ithreadIdx.x72{( ceilDiv(1024, 4) )}, iS73{4} ] ca_pos( 4 ) produce_pos( 1 )\n",
      "   = __bfloat2float(T17_s[ iblockIdx.x34{i0}, iS54{( ceilDiv(i1, 1024) )}, ithreadIdx.x56{( ceilDiv(1024, 4) )}, iV57{4} ] ca_pos( 1 ));\n",
      "T1_l[ iblockIdx.x2{i0}, iS62{( ceilDiv(i1, 1024) )}, ithreadIdx.x64{( ceilDiv(1024, 4) )}, iS65{4} ] ca_pos( 4 ) produce_pos( 1 )\n",
      "   = __bfloat2float(T17_s[ iblockIdx.x34{i0}, iS54{( ceilDiv(i1, 1024) )}, ithreadIdx.x56{( ceilDiv(1024, 4) )}, iV57{4} ] ca_pos( 1 ));\n",
      "T19_l[ iblockIdx.x114{i0}, iS116{( ceilDiv(i1, 1024) )}rf, ithreadIdx.x118{( ceilDiv(1024, 4) )}rf, rS119{4}rf ] ca_pos( 3 ) produce_pos( 4 )\n",
      "   = reduction( T1_l[ iblockIdx.x2{i0}, iS62{( ceilDiv(i1, 1024) )}, ithreadIdx.x64{( ceilDiv(1024, 4) )}, iS65{4} ] ca_pos( 4 ) produce_pos( 1 ), op = add, initial value = float(0), allreduce = false )\n",
      "T2_l[ iblockIdx.x120{i0}, rS121{( ceilDiv(i1, 1024) )}, rthreadIdx.x122{( ceilDiv(1024, 4) )} ] ca_pos( 1 ) produce_pos( 3 )\n",
      "   = reduction( T19_l[ iblockIdx.x114{i0}, iS116{( ceilDiv(i1, 1024) )}rf, ithreadIdx.x118{( ceilDiv(1024, 4) )}rf, rS119{4}rf ] ca_pos( 3 ) produce_pos( 4 ), op = add, initial value = float(0), allreduce = false )\n",
      "T3_l[ iblockIdx.x6{i0}, bS42{( ceilDiv(1, 1024) )}, bthreadIdx.x44{( ceilDiv(1024, 4) )}, bS45{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   = broadcast( T2_l[ iblockIdx.x120{i0}, rS121{( ceilDiv(i1, 1024) )}, rthreadIdx.x122{( ceilDiv(1024, 4) )} ] ca_pos( 1 ) produce_pos( 3 ) )\n",
      "f16 = (float)(4096);\n",
      "T4_l[ iblockIdx.x8{i0}, bS38{( ceilDiv(1, 1024) )}, bthreadIdx.x40{( ceilDiv(1024, 4) )}, bS41{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   = T3_l[ iblockIdx.x6{i0}, bS42{( ceilDiv(1, 1024) )}, bthreadIdx.x44{( ceilDiv(1024, 4) )}, bS45{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   / f16;\n",
      "T12_l[ iblockIdx.x24{i0}, iS82{( ceilDiv(i1, 1024) )}, ithreadIdx.x84{( ceilDiv(1024, 4) )}, iS85{4} ] ca_pos( 4 ) produce_pos( 4 )\n",
      "   = T11_l[ iblockIdx.x22{i0}, iS70{( ceilDiv(i1, 1024) )}, ithreadIdx.x72{( ceilDiv(1024, 4) )}, iS73{4} ] ca_pos( 4 ) produce_pos( 1 )\n",
      "   - T4_l[ iblockIdx.x8{i0}, bS38{( ceilDiv(1, 1024) )}, bthreadIdx.x40{( ceilDiv(1024, 4) )}, bS41{4} ] ca_pos( 1 ) produce_pos( 1 );\n",
      "T5_l[ iblockIdx.x10{i0}, iS50{( ceilDiv(i1, 1024) )}, ithreadIdx.x52{( ceilDiv(1024, 4) )}, iS53{4} ] ca_pos( 4 ) produce_pos( 1 )\n",
      "   = __bfloat2float(T17_s[ iblockIdx.x34{i0}, iS54{( ceilDiv(i1, 1024) )}, ithreadIdx.x56{( ceilDiv(1024, 4) )}, iV57{4} ] ca_pos( 1 ));\n",
      "T6_l[ iblockIdx.x12{i0}, iS46{( ceilDiv(i1, 1024) )}, ithreadIdx.x48{( ceilDiv(1024, 4) )}, iS49{4} ] ca_pos( 4 ) produce_pos( 4 )\n",
      "   = T5_l[ iblockIdx.x10{i0}, iS50{( ceilDiv(i1, 1024) )}, ithreadIdx.x52{( ceilDiv(1024, 4) )}, iS53{4} ] ca_pos( 4 ) produce_pos( 1 )\n",
      "   - T4_l[ iblockIdx.x8{i0}, bS38{( ceilDiv(1, 1024) )}, bthreadIdx.x40{( ceilDiv(1024, 4) )}, bS41{4} ] ca_pos( 1 ) produce_pos( 1 );\n",
      "T7_l[ iblockIdx.x14{i0}, iS74{( ceilDiv(i1, 1024) )}, ithreadIdx.x76{( ceilDiv(1024, 4) )}, iS77{4} ] ca_pos( 4 ) produce_pos( 4 )\n",
      "   = T6_l[ iblockIdx.x12{i0}, iS46{( ceilDiv(i1, 1024) )}, ithreadIdx.x48{( ceilDiv(1024, 4) )}, iS49{4} ] ca_pos( 4 ) produce_pos( 4 )\n",
      "   * T6_l[ iblockIdx.x12{i0}, iS46{( ceilDiv(i1, 1024) )}, ithreadIdx.x48{( ceilDiv(1024, 4) )}, iS49{4} ] ca_pos( 4 ) produce_pos( 4 );\n",
      "T20_l[ iblockIdx.x123{i0}, iS125{( ceilDiv(i1, 1024) )}rf, ithreadIdx.x127{( ceilDiv(1024, 4) )}rf, rS128{4}rf ] ca_pos( 3 ) produce_pos( 4 )\n",
      "   = reduction( T7_l[ iblockIdx.x14{i0}, iS74{( ceilDiv(i1, 1024) )}, ithreadIdx.x76{( ceilDiv(1024, 4) )}, iS77{4} ] ca_pos( 4 ) produce_pos( 4 ), op = add, initial value = float(0), allreduce = false )\n",
      "T8_l[ iblockIdx.x129{i0}, rS130{( ceilDiv(i1, 1024) )}, rthreadIdx.x131{( ceilDiv(1024, 4) )} ] ca_pos( 1 ) produce_pos( 3 )\n",
      "   = reduction( T20_l[ iblockIdx.x123{i0}, iS125{( ceilDiv(i1, 1024) )}rf, ithreadIdx.x127{( ceilDiv(1024, 4) )}rf, rS128{4}rf ] ca_pos( 3 ) produce_pos( 4 ), op = add, initial value = float(0), allreduce = false )\n",
      "T9_l[ iblockIdx.x18{i0}, bS102{( ceilDiv(1, 1024) )}, bthreadIdx.x104{( ceilDiv(1024, 4) )}, bS105{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   = broadcast( T8_l[ iblockIdx.x129{i0}, rS130{( ceilDiv(i1, 1024) )}, rthreadIdx.x131{( ceilDiv(1024, 4) )} ] ca_pos( 1 ) produce_pos( 3 ) )\n",
      "f41 = (float)(4096);\n",
      "T10_l[ iblockIdx.x20{i0}, bS98{( ceilDiv(1, 1024) )}, bthreadIdx.x100{( ceilDiv(1024, 4) )}, bS101{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   = T9_l[ iblockIdx.x18{i0}, bS102{( ceilDiv(1, 1024) )}, bthreadIdx.x104{( ceilDiv(1024, 4) )}, bS105{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   / f41;\n",
      "T13_l[ iblockIdx.x26{i0}, bS94{( ceilDiv(1, 1024) )}, bthreadIdx.x96{( ceilDiv(1024, 4) )}, bS97{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   = T10_l[ iblockIdx.x20{i0}, bS98{( ceilDiv(1, 1024) )}, bthreadIdx.x100{( ceilDiv(1024, 4) )}, bS101{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   + double(9.9999999999999995e-07);\n",
      "T14_l[ iblockIdx.x28{i0}, bS90{( ceilDiv(1, 1024) )}, bthreadIdx.x92{( ceilDiv(1024, 4) )}, bS93{4} ] ca_pos( 1 ) produce_pos( 1 )\n",
      "   = sqrtf(T13_l[ iblockIdx.x26{i0}, bS94{( ceilDiv(1, 1024) )}, bthreadIdx.x96{( ceilDiv(1024, 4) )}, bS97{4} ] ca_pos( 1 ) produce_pos( 1 ));\n",
      "T18_l[ iblockIdx.x30{i0}, iS86{( ceilDiv(i1, 1024) )}, ithreadIdx.x88{( ceilDiv(1024, 4) )}, iS89{4} ] ca_pos( 3 ) produce_pos( 4 )\n",
      "   = T12_l[ iblockIdx.x24{i0}, iS82{( ceilDiv(i1, 1024) )}, ithreadIdx.x84{( ceilDiv(1024, 4) )}, iS85{4} ] ca_pos( 4 ) produce_pos( 4 )\n",
      "   / T14_l[ iblockIdx.x28{i0}, bS90{( ceilDiv(1, 1024) )}, bthreadIdx.x92{( ceilDiv(1024, 4) )}, bS93{4} ] ca_pos( 1 ) produce_pos( 1 );\n",
      "T15_l[ iblockIdx.x36{i0}, iS106{( ceilDiv(i1, 1024) )}, ithreadIdx.x108{( ceilDiv(1024, 4) )}, iV109{4} ] ca_pos( 3 ) produce_pos( 3 )\n",
      "   = Set( T18_l[ iblockIdx.x30{i0}, iS86{( ceilDiv(i1, 1024) )}, ithreadIdx.x88{( ceilDiv(1024, 4) )}, iS89{4} ] ca_pos( 3 ) produce_pos( 4 ), cache_op=Streaming )\n",
      "T16_g[ iblockIdx.x32{i0}, iS110{( ceilDiv(i1, 1024) )}, ithreadIdx.x112{( ceilDiv(1024, 4) )}, iS113{4} ] ca_pos( 4 ) produce_pos( 3 )\n",
      "   = __float2bfloat(T15_l[ iblockIdx.x36{i0}, iS106{( ceilDiv(i1, 1024) )}, ithreadIdx.x108{( ceilDiv(1024, 4) )}, iV109{4} ] ca_pos( 3 ) produce_pos( 3 ));\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add computeAt; inline_most automatically skips vectorized iterDomains\n",
    "fn.sched.inline_most()\n",
    "print(fn._user_schedule_ir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8631d03b-46ba-45cb-b8db-a26c00d1ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Fusion\n",
    "fn._finalize_schedule(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8e3dfc-2ac5-4572-905e-8d518d9cddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 2.4844, -0.8281, -0.3281,  ..., -0.4902,  1.3906,  0.2598],\n",
      "        [ 1.9297, -0.9648,  0.6992,  ...,  0.7695, -0.1060,  0.9023],\n",
      "        [-1.0859,  0.4551, -1.2500,  ..., -0.5625,  0.8242, -1.7109],\n",
      "        ...,\n",
      "        [ 0.7734, -0.6328, -1.9062,  ..., -0.6914,  1.0625, -0.2480],\n",
      "        [ 0.6250, -0.7188,  1.6875,  ..., -0.2168, -1.7188,  0.0840],\n",
      "        [-0.4746, -0.2656,  0.2402,  ...,  0.3086,  2.5938,  0.4863]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)]\n"
     ]
    }
   ],
   "source": [
    "nvf_out = fn.execute(inputs, profile=True)\n",
    "print(nvf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f9c89a-f023-4077-8292-3bbfb1a92786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4844, -0.8281, -0.3281,  ..., -0.4902,  1.3906,  0.2598],\n",
      "        [ 1.9297, -0.9648,  0.6992,  ...,  0.7695, -0.1060,  0.9023],\n",
      "        [-1.0859,  0.4551, -1.2500,  ..., -0.5625,  0.8242, -1.7109],\n",
      "        ...,\n",
      "        [ 0.7734, -0.6328, -1.9062,  ..., -0.6914,  1.0625, -0.2480],\n",
      "        [ 0.6250, -0.7188,  1.6875,  ..., -0.2168, -1.7188,  0.0840],\n",
      "        [-0.4746, -0.2656,  0.2402,  ...,  0.3086,  2.5938,  0.4863]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "torch_out = torch.nn.functional.layer_norm(inputs[0], normalized_shape=inputs[0].shape[1:])\n",
    "print(torch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6506d076-4881-48cd-acbb-b7924a0af5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(nvf_out[0], torch_out, rtol=1e-2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac028d6-b252-4b20-a373-ac0902b902ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kernel_profile(kp):\n",
    "    basic_information = f\"name: {kp.name}, schedule: {kp.scheduler}, segment_id: {kp.segment_id}, device: {kp.device}, stream: {kp.stream}\"\n",
    "    print(basic_information)\n",
    "\n",
    "    kernel_information = f\"compile time: {kp.compile_time_ms:.2f} ms, grid: {kp.grid_str}, block: {kp.block_str}, registers: {kp.registers}\"\n",
    "    print(kernel_information)\n",
    "\n",
    "    runtime_information = f\"input size: {kp.input_bytes} bytes, output size: {kp.output_bytes} bytes, time: {kp.time_ms:2f} ms\"\n",
    "    print(runtime_information)\n",
    "\n",
    "    bandwidth_information = f\"Effective Bandwidth: {kp.effective_bandwidth_gbs:.2f} GB/s, Peak Bandwidth: {kp.percentage_peak_bandwidth:2f}%\"\n",
    "    print(bandwidth_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633174f6-4986-4dde-b92e-17f5f885f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: nvfuser_none_f37_c0_r0_g0, schedule: user, segment_id: 0, device: 0, stream: 7\n",
      "compile time: 88.50 ms, grid: [1024, 1, 1], block: [256, 1, 1], registers: 30\n",
      "input size: 8388608 bytes, output size: 8388608 bytes, time: 0.035584 ms\n",
      "Effective Bandwidth: 471.48 GB/s, Peak Bandwidth: 50.366844%\n"
     ]
    }
   ],
   "source": [
    "kps = fn.profile().kernel_profiles\n",
    "for kp in kps:\n",
    "    print_kernel_profile(kp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
