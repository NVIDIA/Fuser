

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Debugging &mdash; nvFuser 0.2.34 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/css/nvidia_font.css?v=e009355c" />
      <link rel="stylesheet" type="text/css" href="../_static/css/nvidia_footer.css?v=84031d34" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=b85e2031"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Symbol Visibility" href="visibility.html" />
    <link rel="prev" title="TMA Modeling In Depth" href="../reading/tma-modeling-in-depth.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 

          
          
          <a href="../index.html" class="icon icon-home">
            nvFuser
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-menu > p > span.caption-text {
      color: #76b900;
    }

    .wy-menu-vertical p {
      height: 32px;
      line-height: 32px;
      padding: 0 1.618em;
      margin: 12px 0 0;
      display: block;
      font-weight: 700;
      text-transform: uppercase;
      font-size: 85%;
      white-space: nowrap;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    .wy-nav-content {
      max-width: 1000px;
    }

    /* override table width restrictions */
    .wy-table-responsive table td, .wy-table-responsive table th {
        /* !important prevents the common CSS stylesheets from
          overriding this as on RTD they are loaded after this stylesheet */
        white-space: normal !important;
    }

    .wy-table-responsive {
        overflow: visible !important;
    }

  </style>
  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple)>dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }

  html.writer-html4 .rst-content dl:not(.docutils) .property, html.writer-html5 .rst-content dl[class]:not(.option-list):not(.field-list):not(.footnote):not(.glossary):not(.simple) .property {
    text-transform: capitalize;
    display: inline-block;
    padding-right: 8px;
  }
  </style>

  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#nightly-nvfuser-pip-wheel">Nightly nvfuser pip wheel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#nvfuser-pip-wheel-against-pytorch-stable-release">Nvfuser pip wheel against pytorch stable release</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#developer">Developer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#install-from-source">Install From Source:</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/general.html">General</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#statement">Statement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#val">Val</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#expr">Expr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#iterdomain">IterDomain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#tensordomain">TensorDomain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#tensorview">TensorView</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#fusionexecutorcache">FusionExecutorCache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#kernelexecutor">KernelExecutor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/general.html#fusion-definition">Fusion Definition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/ops.html">Operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/ops.html#ops">Ops</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/multidevice.html">Multidevice</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/multidevice.html#communicator">Communicator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/multidevice.html#devicemesh">DeviceMesh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/multidevice.html#sharding">Sharding</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/enum.html">Enums</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/enum.html#communicatorbackend-types">CommunicatorBackend Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/enum.html#data-types">Data Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/enum.html#parallel-types">Parallel Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/enum.html#scheduler-types">Scheduler Types</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api/pod_class.html">Data classes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/pod_class.html#launchparams">LaunchParams</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/pod_class.html#compileparams">CompileParams</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer References</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../reading/divisibility-of-split.html">Divisibility of Split</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../reading/divisibility-of-split.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/divisibility-of-split.html#predication">Predication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/divisibility-of-split.html#allocation-and-correctness-model">Allocation and correctness model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/divisibility-of-split.html#properties-of-split">Properties of split</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../reading/divisibility-of-split.html#merge-then-split-vs-split-then-merge">Merge-then-split vs split-then-merge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reading/divisibility-of-split.html#merging-discontiguous-iterdomains">Merging discontiguous IterDomains</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../reading/divisibility-of-split.html#question">Question</a></li>
<li class="toctree-l4"><a class="reference internal" href="../reading/divisibility-of-split.html#answer">Answer</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reading/iterdomain.html">The Mathematical Theory of IterDomain</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../reading/iterdomain.html#iterdomain-transformations">1. IterDomain Transformations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/iterdomain.html#properties-of-iterdomain-transformations">2. Properties of IterDomain Transformations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reading/multigpu.html">Multi-GPU Support in nvFuser</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../reading/multigpu.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/multigpu.html#user-api">User API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/multigpu.html#parallelisms">Parallelisms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#tensor-parallelism-tp">Tensor Parallelism (TP)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../reading/multigpu.html#sharding-propagation">Sharding Propagation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../reading/multigpu.html#communication-computation-decomposition">Communication-computation Decomposition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#sequence-parallelism-sp">Sequence Parallelism (SP)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../reading/multigpu.html#id1">Sharding Propagation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../reading/multigpu.html#id2">Communication-computation Decomposition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#overlap-communication-with-gemm-via-decomposition">Overlap Communication with GEMM via Decomposition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#distributed-data-parallelism-ddp">Distributed Data Parallelism (DDP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#fully-sharded-data-parallelism-fsdp">Fully Sharded Data Parallelism (FSDP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#pipeline-parallelism-pp">Pipeline Parallelism (PP)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reading/multigpu.html#context-parallelism-cp">Context Parallelism (CP)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reading/tma-modeling-in-depth.html">TMA Modeling In Depth</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../reading/tma-modeling-in-depth.html#what-is-tma">What is TMA?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/tma-modeling-in-depth.html#correctness-model">Correctness model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/tma-modeling-in-depth.html#the-unachievability-of-strong-correctness-for-indivisible-element-stride">The unachievability of strong correctness for indivisible element stride</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reading/tma-modeling-in-depth.html#the-lowering-strategy">The lowering strategy</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Debugging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#debug-a-failing-nvfuser-script">Debug a failing nvFuser script</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#nvfuser-dump">NVFUSER_DUMP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gdb">gdb</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#debug-memory-corruption-using-asan">Debug memory corruption using <code class="docutils literal notranslate"><span class="pre">asan</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#if-built-with-clang">If built with clang</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#debug-memory-leaks-or-excessive-memory-usage">Debug memory leaks or excessive memory usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#debug-slow-kernels">Debug slow kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="#debug-slow-cpu-execution">Debug slow CPU execution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="visibility.html">Symbol Visibility</a><ul>
<li class="toctree-l2"><a class="reference internal" href="visibility.html#faq">FAQ</a><ul>
<li class="toctree-l3"><a class="reference internal" href="visibility.html#should-i-mark-a-method-visible-or-the-whole-class">Should I mark a method visible or the whole class?</a></li>
<li class="toctree-l3"><a class="reference internal" href="visibility.html#i-see-an-undefined-reference-to-typeinfo-for-class-how-do-i-fix-this">I see an undefined reference to <code class="docutils literal notranslate"><span class="pre">typeinfo</span> <span class="pre">for</span> <span class="pre">&lt;class&gt;</span></code>. How do I fix this?</a></li>
<li class="toctree-l3"><a class="reference internal" href="visibility.html#i-see-an-undefined-reference-to-vtable-for-class-how-do-i-fix-this">I see an undefined reference to <code class="docutils literal notranslate"><span class="pre">vtable</span> <span class="pre">for</span> <span class="pre">&lt;class&gt;</span></code>. How do I fix this?</a></li>
<li class="toctree-l3"><a class="reference internal" href="visibility.html#i-see-that-foo-is-visible-but-i-do-not-think-it-needs-to-be">I see that <code class="docutils literal notranslate"><span class="pre">Foo</span></code> is visible but I do not think it needs to be.</a></li>
<li class="toctree-l3"><a class="reference internal" href="visibility.html#should-i-mark-my-new-method-or-class-as-nvf-api">Should I mark my new method or class as <code class="docutils literal notranslate"><span class="pre">NVF_API</span></code>?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="visibility.html#symbol-visibility-checking">Symbol Visibility Checking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="host_ir_jit.html">Host IR JIT Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="host_ir_jit.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="host_ir_jit.html#jit-compilation-process">JIT Compilation Process</a><ul>
<li class="toctree-l3"><a class="reference internal" href="host_ir_jit.html#llvm-integration">1. LLVM Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="host_ir_jit.html#compilation-pipeline">2. Compilation Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="host_ir_jit.html#external-function-integration">3. External Function Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="host_ir_jit.html#ir-translation">3. IR Translation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="host_ir_jit.html#runtime-execution">Runtime Execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="host_ir_jit.html#function-interface">1. Function Interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="host_ir_jit.html#execution-flow">2. Execution Flow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="host_ir_jit.html#configuration-and-build-options">Configuration and Build Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="host_ir_jit.html#future-integration-plan">Future Integration plan</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ldmatrix_stmatrix.html">LdMatrix and StMatrix Support in NVFuser</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ldmatrix_stmatrix.html#what-is-ldmatrix">What is LdMatrix?</a></li>
<li class="toctree-l2"><a class="reference internal" href="ldmatrix_stmatrix.html#what-is-stmatrix">What is StMatrix?</a></li>
<li class="toctree-l2"><a class="reference internal" href="ldmatrix_stmatrix.html#general-details">General Details</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#indices-shared-memory-tensor">Indices shared memory tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#indices-for-register-tensor">Indices for register tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#register-layout-for-one-8x8-matrix-with-16-bit-elements">Register layout for one 8x8 Matrix with 16-bit elements</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ldmatrix_stmatrix.html#example-1-a-copy-kernel-using-tma-ldmatrix-and-stmatrix">Example 1: A copy kernel using TMA, LdMatrix, and StMatrix.</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ldmatrix_stmatrix.html#how-to-compute-the-index-into-register-tensorview">How to compute the index into register TensorView?</a></li>
<li class="toctree-l2"><a class="reference internal" href="ldmatrix_stmatrix.html#how-to-compute-the-index-into-shared-memory-tensorview">How to compute the index into shared memory TensorView?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#figure-1-loop-domain-for-ldmatrix-and-stmatrix">Figure 1: Loop domain for LdMatrix and StMatrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#figure-2-tma-shared-memory-allocation-domain">Figure 2: TMA shared memory allocation domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#figure-3-map-from-ldmatrix-stmatrix-loop-domain-to-tma-shared-memory-allocation-domain">Figure 3: Map from LdMatrix / StMatrix loop domain to TMA shared memory allocation domain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="ldmatrix_stmatrix.html#derivation-of-figure-3">Derivation of Figure 3</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ldmatrix_stmatrix.html#code-walkthrough">Code Walkthrough</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ldmatrix_stmatrix.html#scheduleldstmatrix-function">scheduleLdStMatrix function</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tma.html">Introduction to TMA Support in NVFuser</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tma.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="tma.html#schedule">Schedule</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tma.html#step-1-define-tma-domain">Step 1: define TMA domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="tma.html#step-2-define-box">Step 2: define box</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tma.html#the-canonical-way-to-define-box">The canonical way to define box</a></li>
<li class="toctree-l4"><a class="reference internal" href="tma.html#define-box-by-mathematical-equivalence">Define box by mathematical equivalence</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tma.html#step-3-define-tile">Step 3: define tile</a></li>
<li class="toctree-l3"><a class="reference internal" href="tma.html#step-4-schedule-the-shared-memory-tensor">Step 4: schedule the shared memory tensor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tma.html#data-swizzle">Data swizzle</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tma.html#step-5-schedule-the-consumer-tensor">Step 5: schedule the consumer tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="tma.html#code-walk-through">Code walk-through</a></li>
<li class="toctree-l3"><a class="reference internal" href="tma.html#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tma.html#example-1-tma-load-inputs-and-vectorize-store-output-pointwise-kernel">Example 1: tma-load inputs and vectorize-store output pointwise kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="tma.html#example-2-broadcast-kernel-with-discontiguous-input">Example 2: broadcast kernel with discontiguous input</a></li>
<li class="toctree-l4"><a class="reference internal" href="tma.html#example-3-bank-conflict-free-transpose-of-32bit-data">Example 3: bank-conflict-free transpose of 32bit data</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tmem.html">Tensor Memory Support in NVFuser</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tmem.html#review-of-inlining-and-parallelization">Review of inlining and parallelization</a></li>
<li class="toctree-l2"><a class="reference internal" href="tmem.html#tensor-memory">Tensor memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="tmem.html#the-loop-domain-of-tmem-load-and-store">The loop domain of TMem load and store</a></li>
<li class="toctree-l2"><a class="reference internal" href="tmem.html#vectorization-of-tmem-load-and-store">Vectorization of TMem load and store</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nvFuser</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Debugging</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/dev/debug.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <!--
 * SPDX-FileCopyrightText: Copyright (c) 2025-present NVIDIA CORPORATION & AFFILIATES.
 * All rights reserved.
 * SPDX-License-Identifier: BSD-3-Clause
-->
<section class="tex2jax_ignore mathjax_ignore" id="debugging">
<h1>Debugging<a class="headerlink" href="#debugging" title="Link to this heading"></a></h1>
<section id="debug-a-failing-nvfuser-script">
<h2>Debug a failing nvFuser script<a class="headerlink" href="#debug-a-failing-nvfuser-script" title="Link to this heading"></a></h2>
<p>Debugging a failing nvFuser Python script typically follows the following workflow.</p>
<ol class="arabic simple">
<li><p>An error in compilation is observed when running a python script. This will print a reproducer Python script as part of the error message that defines the fusion and some inputs.</p></li>
<li><p>You begin debugging by inspecting where the error came from and isolating the problematic Fusion segment that failed to compile.</p></li>
<li><p>You isolate a repro for that failing segment and try to simplify it as much as possible while checking that it still triggers the bad behavior.</p></li>
<li><p>(optional) You copy the repro error and describe what you were doing in a new here issue on the nvFuser repo.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">NVFUSER_DUMP</span></code> options and <code class="docutils literal notranslate"><span class="pre">gdb</span></code> to inspect the runtime state of nvFuser to try and determine the root cause and find a fix.</p></li>
</ol>
<p>In step 1, the repro will look something like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>An error occurred while executing nvFuser FusionDefinition 0.
If you believe this is a bug or need assistance, please file an issue at https://github.com/NVIDIA/Fuser/issues/new
Here&#39;s a script to reproduce the error:
```python
# CUDA devices:
#  0: NVIDIA H100 80GB HBM3
# torch version: 2.6.0a0+gitffb7a08
# cuda version: 12.6
# nvfuser version: 0.2.22+git6912435
import torch
from nvfuser import FusionDefinition, DataType

def nvfuser_fusion_id0(fd : FusionDefinition) -&gt; None :
    T0 = fd.define_tensor(shape=[1, 28, 32768, 2], contiguity=[None, True, False, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[3, 2, 1, 0])
    T1 = fd.define_tensor(shape=[1, 32768, 2], contiguity=[None, True, True], dtype=DataType.BFloat16, is_cpu=False, stride_order=[2, 1, 0])
    # ...
    fd.add_output(T273)

with FusionDefinition() as fd:
    nvfuser_fusion_id0(fd)

inputs = [
    torch.randn(7340026, dtype=torch.bfloat16, device=&#39;cuda:0&#39;).as_strided((1, 28, 32768, 2), (7340032, 262144, 8, 1)),
    torch.randn(7340026, dtype=torch.bfloat16, device=&#39;cuda:0&#39;).as_strided((1, 28, 32768, 2), (7340032, 262144, 8, 1)),
]
fd.execute(inputs)
```
</pre></div>
</div>
<p>while a compile error might give a message like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
  <span class="n">File</span> <span class="s2">&quot;/opt/pytorch/nvfuser/nvfuser/__init__.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">182</span><span class="p">,</span> <span class="ow">in</span> <span class="n">execute</span>
    <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execute</span><span class="p">(</span>
              <span class="o">^^^^^^^^^^^^^^</span>
<span class="ne">RuntimeError</span><span class="p">:</span>  <span class="n">INTERNAL</span> <span class="n">ASSERT</span> <span class="n">FAILED</span> <span class="n">at</span> <span class="s2">&quot;/opt/pytorch/nvfuser/csrc/runtime/fusion_kernel_runtime.cpp&quot;</span><span class="p">:</span><span class="mi">368</span><span class="p">,</span> <span class="n">please</span> <span class="n">report</span> <span class="n">a</span> <span class="n">bug</span> <span class="k">with</span> <span class="n">repro</span> <span class="n">script</span> <span class="n">to</span> <span class="n">NVFuser</span> <span class="n">at</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">NVIDIA</span><span class="o">/</span><span class="n">Fuser</span><span class="o">/</span><span class="n">issues</span><span class="o">.</span> <span class="n">Detected</span> <span class="n">exception</span> <span class="k">while</span> <span class="n">compiling</span> <span class="n">fusion</span> <span class="n">segments</span> <span class="ow">in</span> <span class="n">parallel</span><span class="o">.</span> <span class="n">Error</span> <span class="n">messages</span> <span class="kn">from</span><span class="w"> </span><span class="nn">all</span> <span class="n">threads</span> <span class="n">are</span> <span class="n">printed</span> <span class="n">below</span><span class="o">.</span>

<span class="n">Error</span> <span class="kn">from</span><span class="w"> </span><span class="nn">segmentation</span> <span class="n">group</span> <span class="mi">11</span><span class="p">:</span>  <span class="n">INTERNAL</span> <span class="n">ASSERT</span> <span class="n">FAILED</span> <span class="n">at</span> <span class="s2">&quot;/opt/pytorch/nvfuser/csrc/index_compute.cpp&quot;</span><span class="p">:</span><span class="mi">1995</span><span class="p">,</span> <span class="n">please</span> <span class="n">report</span> <span class="n">a</span> <span class="n">bug</span> <span class="k">with</span> <span class="n">repro</span> <span class="n">script</span> <span class="n">to</span> <span class="n">NVFuser</span> <span class="n">at</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">NVIDIA</span><span class="o">/</span><span class="n">Fuser</span><span class="o">/</span><span class="n">issues</span><span class="o">.</span> <span class="n">Couldn</span><span class="s1">&#39;t find allocation mapping for T125_l___bfloat[ iblockIdx.x846{( ceilDiv(2, blockDim.x) )}, ithreadIdx.x847</span><span class="si">{blockDim.x}</span><span class="s1">, iS855{( ceilDiv(( ceilDiv(( ceilDiv(( ceilDiv(32768, blockDim.y) ), 16) ), 1) ), gridDim.y) )}, iblockIdx.y854</span><span class="si">{gridDim.y}</span><span class="s1">, ithreadIdx.y849</span><span class="si">{blockDim.y}</span><span class="s1">, iUS853</span><span class="si">{1}</span><span class="s1">, iUR851</span><span class="si">{16}</span><span class="s1">, bS505</span><span class="si">{1}</span><span class="s1"> ] ca_pos( 6 ) dim: 2 id: iS507</span><span class="si">{2}</span>
<span class="ne">Exception</span> <span class="n">raised</span> <span class="kn">from</span><span class="w"> </span><span class="nn">getNonGlobalConsumerStridedIndices</span> <span class="n">at</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">nvfuser</span><span class="o">/</span><span class="n">csrc</span><span class="o">/</span><span class="n">index_compute</span><span class="o">.</span><span class="n">cpp</span><span class="p">:</span><span class="mi">1995</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">first</span><span class="p">):</span>
<span class="n">frame</span> <span class="c1">#0: nvfuser::nvfCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) + 0x91 (0x7ff45f092448 in /opt/pytorch/nvfuser/nvfuser/_C.cpython-312-x86_64-linux-gnu.so)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>This indicates that segmentation group 11 is the one with the problem.</p>
<p>Step 2 is aided by launching your script like <code class="docutils literal notranslate"><span class="pre">NVFUSER_DUMP=python_definition_segments</span> <span class="pre">python</span> <span class="pre">foo.py</span></code>. This will print, for each segment, a smaller fusion definition than in the overall repro shown above:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Python</span> <span class="n">definition</span> <span class="k">for</span> <span class="n">segmented</span> <span class="n">group</span> <span class="mi">8</span><span class="p">:</span>

<span class="k">def</span><span class="w"> </span><span class="nf">nvfuser_fusion_id8</span><span class="p">(</span><span class="n">fd</span> <span class="p">:</span> <span class="n">FusionDefinition</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="p">:</span>
    <span class="n">T0</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">define_tensor</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32768</span><span class="p">,</span> <span class="mi">56</span><span class="p">],</span> <span class="n">contiguity</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">DataType</span><span class="o">.</span><span class="n">BFloat16</span><span class="p">,</span> <span class="n">is_cpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">T1</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">T0</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">squeeze_expanded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">T2</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">fd</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">stride_order</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">fd</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">stride_order</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Find the group matching the problematic one shown in the error message and this will allow you to cut+paste a new, more targeted repro. Don’t forget to modify the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> to match those expected by the segment fusion definition.</p>
<section id="nvfuser-dump">
<h3>NVFUSER_DUMP<a class="headerlink" href="#nvfuser-dump" title="Link to this heading"></a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">NVFUSER_DUMP</span></code> environment variable to control what intermediate results
to dump and verbose logging. It can be prepended to any command that launches
nvfuser, e.g., <code class="docutils literal notranslate"><span class="pre">bin/test_nvfuser</span></code>, <code class="docutils literal notranslate"><span class="pre">bin/nvfuser_bench</span></code> and <code class="docutils literal notranslate"><span class="pre">python3</span> <span class="pre">a_python_script_that_imports_and_runs_nvfuser.py</span></code>.
<code class="docutils literal notranslate"><span class="pre">csrc/options.cpp</span></code> lists all dumping options and their meanings.</p>
<p>Examples:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">NVFUSER_DUMP=cuda_kernel</span></code> prints the generated CUDA kernels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NVFUSER_DUMP=segmenter_logging</span></code> prints which scheduler gets used.</p></li>
</ul>
</section>
<section id="gdb">
<h3>gdb<a class="headerlink" href="#gdb" title="Link to this heading"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">NVFUSER_BUILD_BUILD_TYPE</span><span class="o">=</span>Debug<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-v<span class="w"> </span>-e<span class="w"> </span>./python<span class="w"> </span>--no-build-isolation
<span class="c1"># or if you are on the PJNL docker image, DEBUG_BUILD=1 _bn</span>
$<span class="w"> </span>gdb<span class="w"> </span>--args<span class="w"> </span>bin/test_nvfuser<span class="w"> </span>--gtest_filter<span class="o">=</span>&lt;FILTER&gt;
<span class="o">(</span>gdb<span class="o">)</span><span class="w"> </span>catch<span class="w"> </span>throw<span class="w"> </span>nvfuser::nvfError
<span class="o">(</span>gdb<span class="o">)</span><span class="w"> </span>r
</pre></div>
</div>
</section>
</section>
<section id="debug-memory-corruption-using-asan">
<h2>Debug memory corruption using <code class="docutils literal notranslate"><span class="pre">asan</span></code><a class="headerlink" href="#debug-memory-corruption-using-asan" title="Link to this heading"></a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">NVFUSER_BUILD_WITH_ASAN</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-v<span class="w"> </span>-e<span class="w"> </span>./python<span class="w"> </span>--no-build-isolation
<span class="c1"># or if you are on the PJNL docker image, NVFUSER_BUILD_WITH_ASAN=1 _bn</span>

$<span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span><span class="k">$(</span>gcc<span class="w"> </span>-print-file-name<span class="o">=</span>libasan.so<span class="k">)</span><span class="w"> </span><span class="nv">ASAN_OPTIONS</span><span class="o">=</span><span class="nv">protect_shadow_gap</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>&lt;CMD&gt;
<span class="c1"># The ASAN_OPTIONS is needed to work around https://github.com/google/sanitizers/issues/629.</span>
</pre></div>
</div>
<section id="if-built-with-clang">
<h3>If built with clang<a class="headerlink" href="#if-built-with-clang" title="Link to this heading"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">ASAN_OPTIONS</span><span class="o">=</span><span class="nv">protect_shadow_gap</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>&lt;<span class="nb">test</span><span class="w"> </span>binary<span class="w"> </span>e.g.<span class="w"> </span>bin/test_nvfuser&gt;
</pre></div>
</div>
<p>for C++ tests. <code class="docutils literal notranslate"><span class="pre">LD_PRELOAD</span></code> isn’t needed because clang by default uses <code class="docutils literal notranslate"><span class="pre">-static-libsan</span></code> and C++ tests are statically linked.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span><span class="k">$(</span>clang<span class="w"> </span>-print-file-name<span class="o">=</span>libclang_rt.asan-x86_64.so<span class="k">)</span><span class="w"> </span><span class="nv">ASAN_OPTIONS</span><span class="o">=</span><span class="nv">protect_shadow_gap</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>pytest<span class="w"> </span>tests/python/&lt;test_file<span class="w"> </span>e.g.<span class="w"> </span>test_python_frontend.py&gt;
</pre></div>
</div>
<p>For Python tests. <code class="docutils literal notranslate"><span class="pre">LD_PRELOAD</span></code> is needed because the Python API loads nvFuser as a shared library.</p>
</section>
</section>
<section id="debug-memory-leaks-or-excessive-memory-usage">
<h2>Debug memory leaks or excessive memory usage<a class="headerlink" href="#debug-memory-leaks-or-excessive-memory-usage" title="Link to this heading"></a></h2>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install tcmalloc and some other tools.</span>
$<span class="w"> </span>sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>google-perftools

<span class="c1"># For me, tcmalloc was installed at /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4</span>
$<span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span>&lt;path<span class="w"> </span>to<span class="w"> </span>libtcmalloc.so&gt;<span class="w"> </span><span class="nv">HEAPPROFILE</span><span class="o">=</span>/tmp/&lt;NAME&gt;<span class="w"> </span>&lt;CMD&gt;
</pre></div>
</div>
<p>The above command should print out “Starting tracking the heap” at the beginning. During or at the end of the program execution, you should be able to see something like “Dumping heap profile to /tmp/<NAME>.<NUMBER>.heap”. These are the dumped heap profiles to be examined by <code class="docutils literal notranslate"><span class="pre">pprof</span></code>.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>golang
$<span class="w"> </span>go<span class="w"> </span>install<span class="w"> </span>github.com/google/pprof@latest
$<span class="w"> </span><span class="nv">$HOME</span>/go/bin/pprof<span class="w"> </span>-dot<span class="w"> </span>-output<span class="w"> </span>/tmp/&lt;NAME&gt;.dot<span class="w"> </span>/tmp/&lt;NAME&gt;.&lt;NUMBER&gt;.heap
$<span class="w"> </span>dot<span class="w"> </span>-Tpng<span class="w"> </span>/tmp/&lt;NAME&gt;.dot<span class="w"> </span>-o<span class="w"> </span>/tmp/&lt;NAME&gt;.png
</pre></div>
</div>
</section>
<section id="debug-slow-kernels">
<h2>Debug slow kernels<a class="headerlink" href="#debug-slow-kernels" title="Link to this heading"></a></h2>
<p>You can do that with <code class="docutils literal notranslate"><span class="pre">nsys</span></code> or <code class="docutils literal notranslate"><span class="pre">ncu</span></code>. For example,</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>nsys<span class="w"> </span>profile<span class="w"> </span>&lt;CMD&gt;
$<span class="w"> </span>nsys<span class="w"> </span>stats<span class="w"> </span>--report<span class="w"> </span>cuda_gpu_kern_sum<span class="w"> </span>&lt;the<span class="w"> </span>.nsys-rep<span class="w"> </span>file<span class="w"> </span>generated<span class="w"> </span>by<span class="w"> </span>the<span class="w"> </span>above<span class="w"> </span>command&gt;
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>ncu<span class="w"> </span>-k<span class="w"> </span>&lt;KERNEL_NAME_FILTER&gt;<span class="w"> </span>&lt;CMD&gt;
</pre></div>
</div>
<p>Unlike <code class="docutils literal notranslate"><span class="pre">nsys</span></code>, <code class="docutils literal notranslate"><span class="pre">ncu</span></code> by default tries to stabilize measurement by flushing GPU caches and locking clocks. <code class="docutils literal notranslate"><span class="pre">ncu</span> <span class="pre">-h</span></code> for knobs to change that behavior.</p>
<p>For better UI, you can let <code class="docutils literal notranslate"><span class="pre">ncu</span></code> export profiling results to <code class="docutils literal notranslate"><span class="pre">.ncu-rep</span></code> remotely and open that from the Nsight Compute GUI on your host (e.g. a MacBook). Note that Nsight Compute is a different tool from Nsight Systems.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>ncu<span class="w"> </span>-o<span class="w"> </span>&lt;OUTPUT_NAME&gt;<span class="w"> </span>&lt;OTHER_OPTIONS&gt;<span class="w"> </span>&lt;CMD&gt;
...
<span class="o">==</span><span class="nv">PROF</span><span class="o">==</span><span class="w"> </span>Report:<span class="w"> </span>&lt;OUTPUT_NAME&gt;.ncu-rep
</pre></div>
</div>
<p>When examine nvrtc compiled kernel, it’s useful to associate cuda source file with the lowered device code. <code class="docutils literal notranslate"><span class="pre">-lineinfo</span></code> is useful for that as well as the source code.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nv">NVFUSER_ENABLE</span><span class="o">=</span>kernel_lineinfo<span class="w"> </span><span class="nv">NVFUSER_DUMP</span><span class="o">=</span>cuda_to_file<span class="w"> </span>ncu<span class="w"> </span>&lt;CMD&gt;
</pre></div>
</div>
</section>
<section id="debug-slow-cpu-execution">
<h2>Debug slow CPU execution<a class="headerlink" href="#debug-slow-cpu-execution" title="Link to this heading"></a></h2>
<p>Use Google’s <a class="reference external" href="https://gperftools.github.io/gperftools/cpuprofile.html">cpuprofile</a></p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>sudo<span class="w"> </span>apt<span class="w"> </span>install<span class="w"> </span>google-perftools<span class="w"> </span>libgoogle-perftools-dev<span class="w"> </span>golang
<span class="c1"># Run the binary with the profiler, e.g.,</span>
$<span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span>&lt;path<span class="w"> </span>to<span class="w"> </span>libprofiler<span class="w"> </span>e.g.<span class="w"> </span>/usr/lib/x86_64-linux-gnu/libprofiler.so&gt;<span class="w"> </span><span class="nv">CPUPROFILE</span><span class="o">=</span>&lt;path<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>profiling<span class="w"> </span>results<span class="w"> </span>to<span class="w"> </span>be<span class="w"> </span>created<span class="w"> </span>e.g<span class="w"> </span>/tmp/test_nvfuser.prof&gt;<span class="w"> </span>bin/test_nvfuser<span class="w"> </span>--gtest_filter<span class="o">=</span>&lt;filter&gt;
$<span class="w"> </span>go<span class="w"> </span>install<span class="w"> </span>github.com/google/pprof@latest
$<span class="w"> </span><span class="nv">$HOME</span>/go/bin/pprof<span class="w"> </span>--pdf<span class="w"> </span>bin/test_nvfuser<span class="w"> </span>/tmp/test_nvfuser.prof
Generating<span class="w"> </span>report<span class="w"> </span><span class="k">in</span><span class="w"> </span>profile001.pdf
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../reading/tma-modeling-in-depth.html" class="btn btn-neutral float-left" title="TMA Modeling In Depth" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="visibility.html" class="btn btn-neutral float-right" title="Symbol Visibility" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
<img src="../_static/NVIDIA-LogoBlack.svg"/>
<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>

    <p>&#169; Copyright 2023-2025, NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved..</p>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        
        Version: 0.2.34
        
    </span>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>