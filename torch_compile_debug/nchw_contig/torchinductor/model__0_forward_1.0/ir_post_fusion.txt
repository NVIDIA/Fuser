op0_op1_op4_op5: FusedSchedulerNode(SchedulerNode,SchedulerNode,SchedulerNode,SchedulerNode)
op0_op1_op4_op5.writes = 
    [   MemoryDep('buf0', c0, {c0: 32768}, None),
        MemoryDep('buf1', c0, {c0: 32768}, None),
        MemoryDep('buf4', c0, {c0: 32768}, None),
        MemoryDep('buf5', c0, {c0: 32768}, None)]
op0_op1_op4_op5.unmet_dependencies = []
op0_op1_op4_op5.met_dependencies = [MemoryDep('primals_3', c0, {c0: 67108864}, None)]
op0_op1_op4_op5.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf0.users = [
        NodeUser(node=SchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op4'), can_inplace=True, is_weak=False),
    ]
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf1.users = [
        NodeUser(node=SchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op5'), can_inplace=True, is_weak=False),
    ]
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda', torch.float16, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf4.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf5: ComputedBuffer
    buf5.layout = FixedLayout('cuda', torch.float16, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf5.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op0_op1_op4_op5.snodes[0] =
op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: 32768}, None)]
op0.unmet_dependencies = []
op0.met_dependencies = [MemoryDep('primals_3', c0, {c0: 67108864}, None)]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf0.users = [
        NodeUser(node=SchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op4'), can_inplace=True, is_weak=False),
    ]
]
op0.group.device = cuda:0
op0.group.iteration = (32768, 2048)
op0.sizes = ([32768], [2048])
primals_3_layout = FixedLayout('cuda', torch.float16, size=[1024, 256, 16, 16], stride=[65536, 256, 16, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
class op0_loop_body:
    var_ranges = {z0: 32768, z1: 2048}
    index0 = 2048*z0 + z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_3', get_index)
        to_dtype = ops.to_dtype(load, torch.float32, src_dtype = torch.float16)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', to_dtype)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf0', get_index_1, getitem)
        return store_reduction
op0 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 2048],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=132), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'DECCFF780DB6236B5007BFE678ACB0D7841A3C7004B5A35A8B575CC067912A0D', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 2048
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        tmp3_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        tmp3_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        tmp3_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (r1 + (2048*x0)), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
            tmp1 = tmp0.to(tl.float32)
            tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp3_mean_next, tmp3_m2_next, tmp3_weight_next = triton_helpers.welford_reduce(
                tmp2, tmp3_mean, tmp3_m2, tmp3_weight, roffset == 0
            )
            tmp3_mean = tl.where(rmask, tmp3_mean_next, tmp3_mean)
            tmp3_m2 = tl.where(rmask, tmp3_m2_next, tmp3_m2)
            tmp3_weight = tl.where(rmask, tmp3_weight_next, tmp3_weight)
        tmp3_tmp, tmp4_tmp, tmp5_tmp = triton_helpers.welford(
            tmp3_mean, tmp3_m2, tmp3_weight, 1
        )
        tmp3 = tmp3_tmp[:, None]
        tmp4 = tmp4_tmp[:, None]
        tmp5 = tmp5_tmp[:, None]
        tl.store(out_ptr0 + (x0), tmp3, None)
op0_op1_op4_op5.snodes[1] =
op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 32768}, None)]
op1.unmet_dependencies = []
op1.met_dependencies = [MemoryDep('primals_3', c0, {c0: 67108864}, None)]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf1.users = [
        NodeUser(node=SchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op5'), can_inplace=True, is_weak=False),
    ]
]
op1.group.device = cuda:0
op1.group.iteration = (32768, 2048)
op1.sizes = ([32768], [2048])
primals_3_layout = FixedLayout('cuda', torch.float16, size=[1024, 256, 16, 16], stride=[65536, 256, 16, 1])
buf1_layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
class op1_loop_body:
    var_ranges = {z0: 32768, z1: 2048}
    index0 = 2048*z0 + z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_3', get_index)
        to_dtype = ops.to_dtype(load, torch.float32, src_dtype = torch.float16)
        reduction = ops.reduction(torch.float32, torch.float32, 'welford_reduce', to_dtype)
        getitem = reduction[0]
        getitem_1 = reduction[1]
        getitem_2 = reduction[2]
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf1', get_index_1, getitem_1)
        return store_reduction
op1 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 2048],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=132), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 1, 'backend_hash': 'DECCFF780DB6236B5007BFE678ACB0D7841A3C7004B5A35A8B575CC067912A0D', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 2048
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        tmp3_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        tmp3_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        tmp3_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (r1 + (2048*x0)), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
            tmp1 = tmp0.to(tl.float32)
            tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp3_mean_next, tmp3_m2_next, tmp3_weight_next = triton_helpers.welford_reduce(
                tmp2, tmp3_mean, tmp3_m2, tmp3_weight, roffset == 0
            )
            tmp3_mean = tl.where(rmask, tmp3_mean_next, tmp3_mean)
            tmp3_m2 = tl.where(rmask, tmp3_m2_next, tmp3_m2)
            tmp3_weight = tl.where(rmask, tmp3_weight_next, tmp3_weight)
        tmp3_tmp, tmp4_tmp, tmp5_tmp = triton_helpers.welford(
            tmp3_mean, tmp3_m2, tmp3_weight, 1
        )
        tmp3 = tmp3_tmp[:, None]
        tmp4 = tmp4_tmp[:, None]
        tmp5 = tmp5_tmp[:, None]
        tl.store(out_ptr0 + (x0), tmp4, None)
op0_op1_op4_op5.snodes[2] =
op4: SchedulerNode(ComputedBuffer)
op4.writes = [MemoryDep('buf4', c0, {c0: 32768}, None)]
op4.unmet_dependencies = [MemoryDep('buf0', c0, {c0: 32768}, None)]
op4.met_dependencies = []
op4.outputs = [
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cuda', torch.float16, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf4.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op4.group.device = cuda:0
op4.group.iteration = (32768, 1)
op4.sizes = ([32768], [])
buf0_layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
buf4_layout = FixedLayout('cuda', torch.float16, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
class op4_loop_body:
    var_ranges = {z0: 32768}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf0', get_index)
        to_dtype = ops.to_dtype(load, torch.float16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf4', get_index_1, to_dtype, None)
        return store
op4 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[32768], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp16', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=132), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'DECCFF780DB6236B5007BFE678ACB0D7841A3C7004B5A35A8B575CC067912A0D', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 32768
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), None)
        tmp1 = tmp0.to(tl.float32)
        tl.store(out_ptr0 + (x0), tmp1, None)
op0_op1_op4_op5.snodes[3] =
op5: SchedulerNode(ComputedBuffer)
op5.writes = [MemoryDep('buf5', c0, {c0: 32768}, None)]
op5.unmet_dependencies = [MemoryDep('buf1', c0, {c0: 32768}, None)]
op5.met_dependencies = []
op5.outputs = [
    buf5: ComputedBuffer
    buf5.layout = FixedLayout('cuda', torch.float16, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
    buf5.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op5.group.device = cuda:0
op5.group.iteration = (32768, 1)
op5.sizes = ([32768], [])
buf1_layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
buf5_layout = FixedLayout('cuda', torch.float16, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
class op5_loop_body:
    var_ranges = {z0: 32768}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        constant = ops.constant(2048.0, torch.float32)
        truediv = ops.truediv(load, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        to_dtype = ops.to_dtype(rsqrt, torch.float16, src_dtype = torch.float32)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf5', get_index_1, to_dtype, None)
        return store
op5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[32768], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp32', 1: '*fp16', 2: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=132), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 0, 'backend_hash': 'DECCFF780DB6236B5007BFE678ACB0D7841A3C7004B5A35A8B575CC067912A0D', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 32768
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x0 = xindex
        tmp0 = tl.load(in_ptr0 + (x0), None)
        tmp1 = 2048.0
        tmp2 = tmp0 / tmp1
        tmp3 = 1e-05
        tmp4 = tmp2 + tmp3
        tmp5 = libdevice.rsqrt(tmp4)
        tmp6 = tmp5.to(tl.float32)
        tl.store(out_ptr0 + (x0), tmp6, None)
op0_op1_op4_op5 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.reduction(
        size_hints=[32768, 2048],
        reduction_hint=ReductionHint.INNER,
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: '*fp32', 3: '*fp16', 4: '*fp16', 5: 'i32', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=132), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 1, 'num_reduction': 2, 'backend_hash': 'DECCFF780DB6236B5007BFE678ACB0D7841A3C7004B5A35A8B575CC067912A0D', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False}
    )
    @triton.jit
    def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
        xnumel = 32768
        rnumel = 2048
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
        xmask = tl.full([XBLOCK, RBLOCK], True, tl.int1)
        rbase = tl.arange(0, RBLOCK)[None, :]
        x0 = xindex
        tmp3_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        tmp3_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        tmp3_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)
        for roffset in range(0, rnumel, RBLOCK):
            rindex = roffset + rbase
            rmask = rindex < rnumel
            r1 = rindex
            tmp0 = tl.load(in_ptr0 + (r1 + (2048*x0)), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
            tmp1 = tmp0.to(tl.float32)
            tmp2 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])
            tmp3_mean_next, tmp3_m2_next, tmp3_weight_next = triton_helpers.welford_reduce(
                tmp2, tmp3_mean, tmp3_m2, tmp3_weight, roffset == 0
            )
            tmp3_mean = tl.where(rmask, tmp3_mean_next, tmp3_mean)
            tmp3_m2 = tl.where(rmask, tmp3_m2_next, tmp3_m2)
            tmp3_weight = tl.where(rmask, tmp3_weight_next, tmp3_weight)
        tmp3_tmp, tmp4_tmp, tmp5_tmp = triton_helpers.welford(
            tmp3_mean, tmp3_m2, tmp3_weight, 1
        )
        tmp3 = tmp3_tmp[:, None]
        tmp4 = tmp4_tmp[:, None]
        tmp5 = tmp5_tmp[:, None]
        tl.store(out_ptr0 + (x0), tmp3, None)
        tl.store(out_ptr1 + (x0), tmp4, None)
        tmp6 = tmp3.to(tl.float32)
        tmp7 = 2048.0
        tmp8 = tmp4 / tmp7
        tmp9 = 1e-05
        tmp10 = tmp8 + tmp9
        tmp11 = libdevice.rsqrt(tmp10)
        tmp12 = tmp11.to(tl.float32)
        tl.store(out_ptr2 + (x0), tmp6, None)
        tl.store(out_ptr3 + (x0), tmp12, None)


op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: 67108864}, None)]
op3.unmet_dependencies = 
    [   MemoryDep('buf0', 32*c0 + (c1//8), {c0: 1024, c1: 256}, None),
        MemoryDep('buf1', 32*c0 + (c1//8), {c0: 1024, c1: 256}, None)]
op3.met_dependencies = 
    [   MemoryDep('primals_1', c1, {c0: 1024, c1: 256}, None),
        MemoryDep('primals_2', c1, {c0: 1024, c1: 256}, None),
        MemoryDep('primals_3', c0, {c0: 67108864}, None)]
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda', torch.float16, size=[1024, 256, 16, 16], stride=[65536, 256, 16, 1])
    buf3.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op3.group.device = cuda:0
op3.group.iteration = (67108864, 1)
op3.sizes = ([1024, 256, 256], [])
primals_1_layout = FixedLayout('cuda', torch.float16, size=[256], stride=[1])
primals_3_layout = FixedLayout('cuda', torch.float16, size=[1024, 256, 16, 16], stride=[65536, 256, 16, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
buf1_layout = FixedLayout('cuda', torch.float32, size=[1024, 32, 1, 1], stride=[32, 1, 32768, 32768])
primals_2_layout = FixedLayout('cuda', torch.float16, size=[256], stride=[1])
buf3_layout = FixedLayout('cuda', torch.float16, size=[1024, 256, 16, 16], stride=[65536, 256, 16, 1])
class op3_loop_body:
    var_ranges = {z0: 1024, z1: 256, z2: 256}
    index0 = 65536*z0 + 256*z1 + z2
    index1 = 32*z0 + (z1//8)
    index2 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('primals_3', get_index)
        to_dtype = ops.to_dtype(load, torch.float32, src_dtype = torch.float16)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf0', get_index_1)
        sub = ops.sub(to_dtype, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf1', get_index_2)
        constant = ops.constant(2048.0, torch.float32)
        truediv = ops.truediv(load_2, constant)
        constant_1 = ops.constant(1e-05, torch.float32)
        add = ops.add(truediv, constant_1)
        rsqrt = ops.rsqrt(add)
        mul = ops.mul(sub, rsqrt)
        get_index_3 = self.get_index('index2')
        load_3 = ops.load('primals_2', get_index_3)
        to_dtype_1 = ops.to_dtype(load_3, torch.float32, src_dtype = torch.float16)
        mul_1 = ops.mul(mul, to_dtype_1)
        get_index_4 = self.get_index('index2')
        load_4 = ops.load('primals_1', get_index_4)
        to_dtype_2 = ops.to_dtype(load_4, torch.float32, src_dtype = torch.float16)
        add_1 = ops.add(mul_1, to_dtype_2)
        to_dtype_3 = ops.to_dtype(add_1, torch.float16, src_dtype = torch.float32)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf3', get_index_5, to_dtype_3, None)
        return store
op3 Triton code:
    import triton
    import triton.language as tl
    from triton.compiler.compiler import AttrsDescriptor

    from torch._inductor.runtime import triton_helpers, triton_heuristics
    from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
    from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, instance_descriptor, DeviceProperties

    @triton_heuristics.pointwise(
        size_hints=[67108864], 
        filename=__file__,
        triton_meta={'signature': {0: '*fp16', 1: '*fp32', 2: '*fp32', 3: '*fp16', 4: '*fp16', 5: '*fp16', 6: 'i32'}, 'device': DeviceProperties(type='cuda', index=0, cc=90, major=9, regs_per_multiprocessor=65536, max_threads_per_multi_processor=2048, multi_processor_count=132), 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=())]},
        inductor_meta={'autotune_hints': set(), 'kernel_name': 'Placeholder.DESCRIPTIVE_NAME', 'mutated_arg_names': [], 'no_x_dim': False, 'num_load': 5, 'num_reduction': 0, 'backend_hash': 'DECCFF780DB6236B5007BFE678ACB0D7841A3C7004B5A35A8B575CC067912A0D', 'are_deterministic_algorithms_enabled': False, 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': False, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False},
        min_elem_per_thread=0
    )
    @triton.jit
    def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):
        xnumel = 67108864
        xoffset = tl.program_id(0) * XBLOCK
        xindex = xoffset + tl.arange(0, XBLOCK)[:]
        xmask = tl.full([XBLOCK], True, tl.int1)
        x3 = xindex
        x4 = (xindex // 256)
        x1 = (xindex // 256) % 256
        tmp0 = tl.load(in_ptr0 + (x3), None).to(tl.float32)
        tmp2 = tl.load(in_ptr1 + ((x4 // 8)), None, eviction_policy='evict_last')
        tmp4 = tl.load(in_ptr2 + ((x4 // 8)), None, eviction_policy='evict_last')
        tmp11 = tl.load(in_ptr3 + (x1), None, eviction_policy='evict_last').to(tl.float32)
        tmp14 = tl.load(in_ptr4 + (x1), None, eviction_policy='evict_last').to(tl.float32)
        tmp1 = tmp0.to(tl.float32)
        tmp3 = tmp1 - tmp2
        tmp5 = 2048.0
        tmp6 = tmp4 / tmp5
        tmp7 = 1e-05
        tmp8 = tmp6 + tmp7
        tmp9 = libdevice.rsqrt(tmp8)
        tmp10 = tmp3 * tmp9
        tmp12 = tmp11.to(tl.float32)
        tmp13 = tmp10 * tmp12
        tmp15 = tmp14.to(tl.float32)
        tmp16 = tmp13 + tmp15
        tmp17 = tmp16.to(tl.float32)
        tl.store(out_ptr0 + (x3), tmp17, None)


